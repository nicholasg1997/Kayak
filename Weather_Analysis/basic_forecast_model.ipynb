{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:07.501307Z",
     "end_time": "2023-06-07T13:49:07.517684Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "from meteostat import Stations, Daily\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torcheval.metrics import R2Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "path = \"RawData\"\n",
    "\n",
    "\n",
    "def extract_date_time(filename):\n",
    "    \"\"\"\n",
    "    extract the date and time from the filename\n",
    "    :param filename:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    parts = filename.split('.')\n",
    "    date = parts[1]\n",
    "    time = parts[2]\n",
    "    return date, time\n",
    "\n",
    "\n",
    "def get_date(df, file):\n",
    "    \"\"\"get the date from the dataframe and the time from the filename and combine them into a datetime object\n",
    "    :param df: dataframe containing the date\n",
    "    :param file: filename containing the time\n",
    "    :return: datetime object\n",
    "    \"\"\"\n",
    "    #date_str = df[df.iloc[:, 2] == 1].iloc[0]['Date']\n",
    "    date_str = str(file.split('.')[1])\n",
    "    time_str = str(file.split('.')[2])\n",
    "    #date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    date = datetime.strptime(date_str, '%Y%m%d')\n",
    "    time_value = time(int(time_str), 0)\n",
    "    combined_datetime = datetime.combine(date.date(), time_value)\n",
    "    return combined_datetime\n",
    "\n",
    "\n",
    "degree_days = 'gw_hdd'\n",
    "ecmwf_files = glob.glob(path + f'/ecmwf.*.[01][02].{degree_days}.csv')\n",
    "ecmwf_sorted_files = sorted(ecmwf_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[3:]\n",
    "\n",
    "ecmwf_eps_files = glob.glob(path + f'/ecmwf-eps.*.[01][02].{degree_days}.csv')\n",
    "ecmwf_eps_sorted_files = sorted(ecmwf_eps_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "\n",
    "gfs_ens_bc_files = glob.glob(path + f'/gfs-ens-bc.*.[01][02].{degree_days}.csv')\n",
    "gfs_ens_bc_sorted_files = sorted(gfs_ens_bc_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "\n",
    "cmc_ens_files = glob.glob(path + f'/cmc-ens.*.[01][02].{degree_days}.csv')\n",
    "cmc_ens_sorted_files = sorted(cmc_ens_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "for _ in range(2):\n",
    "    set1 = set((extract_date_time(filename) for filename in ecmwf_sorted_files))\n",
    "    set2 = set((extract_date_time(filename) for filename in ecmwf_eps_sorted_files))\n",
    "\n",
    "    ecmwf_sorted_files = [filename for filename in ecmwf_sorted_files if extract_date_time(filename) in set2]\n",
    "    ecmwf_eps_sorted_files = [filename for filename in ecmwf_eps_sorted_files if extract_date_time(filename) in set1]\n",
    "    cmc_ens_sorted_files = [filename for filename in cmc_ens_sorted_files if extract_date_time(filename) in set1]\n",
    "\n",
    "    master_set = set((extract_date_time(filename) for filename in cmc_ens_sorted_files))\n",
    "    gfs_ens_bc_sorted_files = [filename for filename in gfs_ens_bc_sorted_files if\n",
    "                               extract_date_time(filename) in master_set]\n",
    "\n",
    "    master_set = set((extract_date_time(filename) for filename in gfs_ens_bc_sorted_files))\n",
    "\n",
    "    ecmwf_sorted_files = [filename for filename in ecmwf_sorted_files if extract_date_time(filename) in master_set]\n",
    "    ecmwf_eps_sorted_files = [filename for filename in ecmwf_eps_sorted_files if\n",
    "                              extract_date_time(filename) in master_set]\n",
    "    gfs_ens_bc_sorted_files = [filename for filename in gfs_ens_bc_sorted_files if\n",
    "                               extract_date_time(filename) in master_set]\n",
    "    cmc_ens_sorted_files = [filename for filename in cmc_ens_sorted_files if extract_date_time(filename) in master_set]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:07.725168Z",
     "end_time": "2023-06-07T13:49:08.590691Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on 2020-08-15 12:00:00\n",
      "error on 2020-08-16 00:00:00\n",
      "error on 2020-08-16 12:00:00\n",
      "error on 2020-08-17 00:00:00\n"
     ]
    }
   ],
   "source": [
    "ecmwf_eps_change_df = pd.DataFrame(columns=['ecmwf-eps_9', 'ecmwf-eps_10', 'ecmwf-eps_11', 'ecmwf-eps_12',\n",
    "                                  'ecmwf-eps_13', 'ecmwf-eps_14'])\n",
    "passed_rows = []\n",
    "for i in range(1, len(ecmwf_eps_sorted_files)):\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i])\n",
    "    ecmwf_eps_df = ecmwf_eps_df[ecmwf_eps_df[ecmwf_eps_df.columns[2]] >= 1]\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "    prev_ecmwf_eps_df = prev_ecmwf_eps_df[prev_ecmwf_eps_df[prev_ecmwf_eps_df.columns[2]] >= 1]\n",
    "\n",
    "    date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i])\n",
    "    prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    changes = []\n",
    "    try:\n",
    "        for day in range(8, 14):\n",
    "            changes.append(ecmwf_eps_df.iloc[day - offset]['Value'] - prev_ecmwf_eps_df.iloc[day]['Value'])\n",
    "        new_row = pd.DataFrame([changes], columns=ecmwf_eps_change_df.columns, index=[date])\n",
    "        ecmwf_eps_change_df = pd.concat([ecmwf_eps_change_df, new_row])\n",
    "    except IndexError:\n",
    "        print(f\"error on {date}\")\n",
    "        passed_rows.append(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:08.594067Z",
     "end_time": "2023-06-07T13:49:20.376981Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "[1494, 1495, 1496, 1497]"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passed_rows"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:20.378934Z",
     "end_time": "2023-06-07T13:49:20.382602Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:20.383786Z",
     "end_time": "2023-06-07T13:49:20.385562Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on row: 1494\n",
      "error on row: 1495\n",
      "error on row: 1496\n",
      "error on row: 1497\n"
     ]
    }
   ],
   "source": [
    "ecmwf_change_df = pd.DataFrame(columns=['ecmwf_diff_8', 'ecmwf_diff_9',])\n",
    "passed_rows = []\n",
    "for i in range(1, len(ecmwf_sorted_files)):\n",
    "    ecmwf_df = pd.read_csv(ecmwf_sorted_files[i])\n",
    "    ecmwf_df = ecmwf_df[ecmwf_df[ecmwf_df.columns[2]] >= 1]\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "    ecmwf_eps_df = ecmwf_eps_df[ecmwf_eps_df[ecmwf_eps_df.columns[2]] >= 1]\n",
    "\n",
    "    try:\n",
    "        ecmwf = ecmwf_df.iloc[8]\n",
    "        ecmwf_eps = ecmwf_eps_df.iloc[9]\n",
    "    except IndexError:\n",
    "        print(f\"error on row: {i}\")\n",
    "        passed_rows.append(i)\n",
    "        continue\n",
    "\n",
    "    date = get_date(ecmwf_df, ecmwf_sorted_files[i])\n",
    "    prev_date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    changes = []\n",
    "    try:\n",
    "        for day in range(8,10):\n",
    "            changes.append(ecmwf_df.iloc[day - offset]['Value'] - ecmwf_eps_df.iloc[day]['Value'])\n",
    "        new_row = pd.DataFrame([changes], columns=ecmwf_change_df.columns, index=[date])\n",
    "        ecmwf_change_df = pd.concat([ecmwf_change_df, new_row])\n",
    "    except IndexError:\n",
    "        print(f\"error on {date}\")\n",
    "        passed_rows.append(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:20.391080Z",
     "end_time": "2023-06-07T13:49:29.579966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "[1494, 1495, 1496, 1497]"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passed_rows"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:29.581233Z",
     "end_time": "2023-06-07T13:49:29.584755Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:29.584000Z",
     "end_time": "2023-06-07T13:49:29.586802Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:29.586727Z",
     "end_time": "2023-06-07T13:49:29.588871Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on 2020-08-15 12:00:00\n",
      "error on 2020-08-16 00:00:00\n",
      "error on 2020-08-16 12:00:00\n",
      "error on 2020-08-17 00:00:00\n"
     ]
    }
   ],
   "source": [
    "gfs_ens_bc_change_df = pd.DataFrame(columns=['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12',\n",
    "                                  'gfs-ens-bc_13', 'gfs-ens-bc_14'])\n",
    "passed_rows = []\n",
    "for i in range(1, len(gfs_ens_bc_sorted_files)):\n",
    "    gfs_ens_bc_df = pd.read_csv(gfs_ens_bc_sorted_files[i])\n",
    "    gfs_ens_bc_df = gfs_ens_bc_df[gfs_ens_bc_df[gfs_ens_bc_df.columns[2]] >= 1]\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "    prev_ecmwf_eps_df = prev_ecmwf_eps_df[prev_ecmwf_eps_df[prev_ecmwf_eps_df.columns[2]] >= 1]\n",
    "\n",
    "    try:\n",
    "        date = get_date(gfs_ens_bc_df, gfs_ens_bc_sorted_files[i])\n",
    "        prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    except IndexError:\n",
    "        print(f\"error on row: {i}\")\n",
    "        passed_rows.append(i)\n",
    "        continue\n",
    "\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    changes = []\n",
    "    try:\n",
    "        for day in range(8, 14):\n",
    "            changes.append(gfs_ens_bc_df.iloc[day - offset]['Value'] - prev_ecmwf_eps_df.iloc[day]['Value'])\n",
    "        new_row = pd.DataFrame([changes], columns=gfs_ens_bc_change_df.columns, index=[date])\n",
    "        gfs_ens_bc_change_df = pd.concat([gfs_ens_bc_change_df, new_row])\n",
    "    except IndexError:\n",
    "        print(f\"error on {date}\")\n",
    "        passed_rows.append(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:29.589096Z",
     "end_time": "2023-06-07T13:49:39.447947Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "[1494, 1495, 1496, 1497]"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passed_rows"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:39.450472Z",
     "end_time": "2023-06-07T13:49:39.454202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on 2020-08-15 12:00:00\n",
      "error on 2020-08-16 12:00:00\n"
     ]
    }
   ],
   "source": [
    "cmc_ens_change_df = pd.DataFrame(columns=['cmc-ens_9', 'cmc-ens_10', 'cmc-ens_11', 'cmc-ens_12',\n",
    "                                  'cmc-ens_13', 'cmc-ens_14'])\n",
    "passed_rows = []\n",
    "\n",
    "for i in range(1, len(cmc_ens_sorted_files)):\n",
    "    cmc_ens_df = pd.read_csv(cmc_ens_sorted_files[i])\n",
    "    cmc_ens_df = cmc_ens_df[cmc_ens_df[cmc_ens_df.columns[2]] >= 1]\n",
    "    gfs_ens_bc_df = pd.read_csv(gfs_ens_bc_sorted_files[i])\n",
    "    gfs_ens_bc_df = gfs_ens_bc_df[gfs_ens_bc_df[gfs_ens_bc_df.columns[2]] >= 1]\n",
    "    date = get_date(cmc_ens_df, cmc_ens_sorted_files[i])\n",
    "\n",
    "    changes = []\n",
    "    try:\n",
    "        for day in range(8, 14):\n",
    "            changes.append(cmc_ens_df.iloc[day]['Value'] - gfs_ens_bc_df.iloc[day]['Value'])\n",
    "        new_row = pd.DataFrame([changes], columns=cmc_ens_change_df.columns, index=[date])\n",
    "        cmc_ens_change_df = pd.concat([cmc_ens_change_df, new_row])\n",
    "    except IndexError:\n",
    "        print(f\"error on {date}\")\n",
    "        passed_rows.append(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:39.457477Z",
     "end_time": "2023-06-07T13:49:50.049615Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "[1494, 1496]"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passed_rows"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:50.052815Z",
     "end_time": "2023-06-07T13:49:50.057677Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on 2020-08-15 12:00:00\n",
      "error on 2020-08-16 00:00:00\n",
      "error on 2020-08-16 12:00:00\n",
      "error on 2020-08-17 00:00:00\n"
     ]
    }
   ],
   "source": [
    "day_8_error = pd.DataFrame(columns=['day_8_error'])\n",
    "passed_rows = []\n",
    "\n",
    "for i in range(1, len(ecmwf_eps_sorted_files)):\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i])\n",
    "    ecmwf_eps_df = ecmwf_eps_df[ecmwf_eps_df[ecmwf_eps_df.columns[2]] >= 1]\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "    prev_ecmwf_eps_df = prev_ecmwf_eps_df[prev_ecmwf_eps_df[prev_ecmwf_eps_df.columns[2]] >= 1]\n",
    "\n",
    "    date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i])\n",
    "    prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "    day = 7\n",
    "    changes = []\n",
    "    try:\n",
    "        changes.append(ecmwf_eps_df.iloc[day]['Value'] - prev_ecmwf_eps_df.iloc[day + offset]['Value'])\n",
    "        new_row = pd.DataFrame([changes], columns=day_8_error.columns, index=[date])\n",
    "        day_8_error = pd.concat([day_8_error, new_row])\n",
    "    except IndexError:\n",
    "        print(f\"error on {date}\")\n",
    "        passed_rows.append(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:50.062626Z",
     "end_time": "2023-06-07T13:49:58.112642Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on 2020-08-16 00:00:00\n",
      "error on 2020-08-16 12:00:00\n",
      "error on 2020-08-17 00:00:00\n",
      "error on 2020-08-17 12:00:00\n"
     ]
    }
   ],
   "source": [
    "errors_df = pd.DataFrame(columns=['error_9', 'error_10', 'error_11', 'error_12', 'error_13', 'error_14'])\n",
    "passed_rows = []\n",
    "\n",
    "for i in range(2, len(ecmwf_eps_sorted_files)):\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "    ecmwf_eps_df = ecmwf_eps_df[ecmwf_eps_df[ecmwf_eps_df.columns[2]] >= 1]\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-2])\n",
    "    prev_ecmwf_eps_df = prev_ecmwf_eps_df[prev_ecmwf_eps_df[prev_ecmwf_eps_df.columns[2]] >= 1]\n",
    "\n",
    "    date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i])\n",
    "    prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    errors = []\n",
    "    try:\n",
    "        for day in range(8, 14):\n",
    "            errors.append(ecmwf_eps_df.iloc[day - offset]['Value'] - prev_ecmwf_eps_df.iloc[day]['Value'])\n",
    "        new_row = pd.DataFrame([errors], columns=errors_df.columns, index=[date])\n",
    "        errors_df = pd.concat([errors_df, new_row])\n",
    "    except IndexError:\n",
    "        print(f\"error on {date}\")\n",
    "        passed_rows.append(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:49:58.087580Z",
     "end_time": "2023-06-07T13:50:09.818703Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "new features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "#add if noon"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:50:09.801460Z",
     "end_time": "2023-06-07T13:50:09.818907Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:56:47.053239Z",
     "end_time": "2023-06-07T13:56:47.059298Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:59:56.197036Z",
     "end_time": "2023-06-07T13:59:56.203931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "errors_df['noon'] = errors_df.index.hour\n",
    "errors_df['noon'] = errors_df['noon'].apply(lambda x: 1 if x == 12 else 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:00:48.238736Z",
     "end_time": "2023-06-07T14:00:48.824360Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:01:00.169985Z",
     "end_time": "2023-06-07T14:01:00.177099Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:01:00.442648Z",
     "end_time": "2023-06-07T14:01:00.457198Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:01:00.795647Z",
     "end_time": "2023-06-07T14:01:00.808653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:01:00.970606Z",
     "end_time": "2023-06-07T14:01:00.979310Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "                     gfs-ens-bc_9  gfs-ens-bc_10  gfs-ens-bc_11  \\\n2023-05-15 00:00:00         1.370          0.961          0.180   \n2023-05-15 12:00:00        -1.058         -0.058          0.440   \n2023-05-16 00:00:00        -0.018         -0.324         -0.084   \n2023-05-16 12:00:00        -0.719         -0.732         -0.481   \n2023-05-17 00:00:00        -0.135         -0.121         -0.083   \n\n                     gfs-ens-bc_12  gfs-ens-bc_13  gfs-ens-bc_14  cmc-ens_9  \\\n2023-05-15 00:00:00          0.107          0.123          0.015     -0.752   \n2023-05-15 12:00:00          0.334          0.098         -0.206     -0.139   \n2023-05-16 00:00:00          0.108          0.380          0.401      0.330   \n2023-05-16 12:00:00         -0.186          0.040          0.155     -0.360   \n2023-05-17 00:00:00         -0.034         -0.196         -0.119      0.325   \n\n                     cmc-ens_10  cmc-ens_11  cmc-ens_12  ...  error_13  \\\n2023-05-15 00:00:00      -0.071      -0.003       0.156  ...    -0.137   \n2023-05-15 12:00:00      -0.626      -0.916      -0.714  ...    -0.300   \n2023-05-16 00:00:00      -0.207      -0.039       0.085  ...     0.165   \n2023-05-16 12:00:00      -0.185      -0.309      -0.252  ...     0.082   \n2023-05-17 00:00:00       0.155       0.067      -0.282  ...     0.174   \n\n                     error_14  noon  day_8_error  ecmwf-eps_9  ecmwf-eps_10  \\\n2023-05-15 00:00:00    -0.039   0.0        0.985        0.985         0.827   \n2023-05-15 12:00:00    -0.210   1.0       -0.607       -0.310         0.312   \n2023-05-16 00:00:00    -0.251   0.0        0.375        0.375         0.181   \n2023-05-16 12:00:00     0.179   1.0       -0.624       -0.647        -0.716   \n2023-05-17 00:00:00     0.379   0.0        0.482        0.482         0.299   \n\n                     ecmwf-eps_11  ecmwf-eps_12  ecmwf-eps_13  ecmwf-eps_14  \n2023-05-15 00:00:00         0.163        -0.005        -0.099        -0.262  \n2023-05-15 12:00:00         0.240        -0.036        -0.199        -0.433  \n2023-05-16 00:00:00         0.348         0.421         0.353         0.264  \n2023-05-16 12:00:00        -0.510        -0.097         0.294         0.225  \n2023-05-17 00:00:00         0.191        -0.095        -0.359        -0.209  \n\n[5 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gfs-ens-bc_9</th>\n      <th>gfs-ens-bc_10</th>\n      <th>gfs-ens-bc_11</th>\n      <th>gfs-ens-bc_12</th>\n      <th>gfs-ens-bc_13</th>\n      <th>gfs-ens-bc_14</th>\n      <th>cmc-ens_9</th>\n      <th>cmc-ens_10</th>\n      <th>cmc-ens_11</th>\n      <th>cmc-ens_12</th>\n      <th>...</th>\n      <th>error_13</th>\n      <th>error_14</th>\n      <th>noon</th>\n      <th>day_8_error</th>\n      <th>ecmwf-eps_9</th>\n      <th>ecmwf-eps_10</th>\n      <th>ecmwf-eps_11</th>\n      <th>ecmwf-eps_12</th>\n      <th>ecmwf-eps_13</th>\n      <th>ecmwf-eps_14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-05-15 00:00:00</th>\n      <td>1.370</td>\n      <td>0.961</td>\n      <td>0.180</td>\n      <td>0.107</td>\n      <td>0.123</td>\n      <td>0.015</td>\n      <td>-0.752</td>\n      <td>-0.071</td>\n      <td>-0.003</td>\n      <td>0.156</td>\n      <td>...</td>\n      <td>-0.137</td>\n      <td>-0.039</td>\n      <td>0.0</td>\n      <td>0.985</td>\n      <td>0.985</td>\n      <td>0.827</td>\n      <td>0.163</td>\n      <td>-0.005</td>\n      <td>-0.099</td>\n      <td>-0.262</td>\n    </tr>\n    <tr>\n      <th>2023-05-15 12:00:00</th>\n      <td>-1.058</td>\n      <td>-0.058</td>\n      <td>0.440</td>\n      <td>0.334</td>\n      <td>0.098</td>\n      <td>-0.206</td>\n      <td>-0.139</td>\n      <td>-0.626</td>\n      <td>-0.916</td>\n      <td>-0.714</td>\n      <td>...</td>\n      <td>-0.300</td>\n      <td>-0.210</td>\n      <td>1.0</td>\n      <td>-0.607</td>\n      <td>-0.310</td>\n      <td>0.312</td>\n      <td>0.240</td>\n      <td>-0.036</td>\n      <td>-0.199</td>\n      <td>-0.433</td>\n    </tr>\n    <tr>\n      <th>2023-05-16 00:00:00</th>\n      <td>-0.018</td>\n      <td>-0.324</td>\n      <td>-0.084</td>\n      <td>0.108</td>\n      <td>0.380</td>\n      <td>0.401</td>\n      <td>0.330</td>\n      <td>-0.207</td>\n      <td>-0.039</td>\n      <td>0.085</td>\n      <td>...</td>\n      <td>0.165</td>\n      <td>-0.251</td>\n      <td>0.0</td>\n      <td>0.375</td>\n      <td>0.375</td>\n      <td>0.181</td>\n      <td>0.348</td>\n      <td>0.421</td>\n      <td>0.353</td>\n      <td>0.264</td>\n    </tr>\n    <tr>\n      <th>2023-05-16 12:00:00</th>\n      <td>-0.719</td>\n      <td>-0.732</td>\n      <td>-0.481</td>\n      <td>-0.186</td>\n      <td>0.040</td>\n      <td>0.155</td>\n      <td>-0.360</td>\n      <td>-0.185</td>\n      <td>-0.309</td>\n      <td>-0.252</td>\n      <td>...</td>\n      <td>0.082</td>\n      <td>0.179</td>\n      <td>1.0</td>\n      <td>-0.624</td>\n      <td>-0.647</td>\n      <td>-0.716</td>\n      <td>-0.510</td>\n      <td>-0.097</td>\n      <td>0.294</td>\n      <td>0.225</td>\n    </tr>\n    <tr>\n      <th>2023-05-17 00:00:00</th>\n      <td>-0.135</td>\n      <td>-0.121</td>\n      <td>-0.083</td>\n      <td>-0.034</td>\n      <td>-0.196</td>\n      <td>-0.119</td>\n      <td>0.325</td>\n      <td>0.155</td>\n      <td>0.067</td>\n      <td>-0.282</td>\n      <td>...</td>\n      <td>0.174</td>\n      <td>0.379</td>\n      <td>0.0</td>\n      <td>0.482</td>\n      <td>0.482</td>\n      <td>0.299</td>\n      <td>0.191</td>\n      <td>-0.095</td>\n      <td>-0.359</td>\n      <td>-0.209</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master_df = pd.concat([gfs_ens_bc_change_df, cmc_ens_change_df, ecmwf_change_df, errors_df, day_8_error, ecmwf_eps_change_df], axis=1)\n",
    "master_df.fillna(0, inplace=True)\n",
    "display(master_df[-5:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:01:01.821740Z",
     "end_time": "2023-06-07T14:01:01.843628Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "master_df.to_pickle('master_df.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T10:51:11.363027Z",
     "end_time": "2023-06-07T10:51:11.377615Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "random forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "master_df = pd.read_pickle('master_df.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T12:27:06.881484Z",
     "end_time": "2023-06-07T12:27:06.888623Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T10:51:13.732847Z",
     "end_time": "2023-06-07T10:51:13.735675Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = master_df.iloc[:, :-6]\n",
    "y = master_df.iloc[:, -6:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T10:51:14.008246Z",
     "end_time": "2023-06-07T10:51:14.013047Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T10:51:14.671726Z",
     "end_time": "2023-06-07T10:51:14.674477Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_model = RandomForestRegressor(n_estimators=1000, max_depth=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T10:51:14.851932Z",
     "end_time": "2023-06-07T10:52:01.639354Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T10:52:01.641000Z",
     "end_time": "2023-06-07T10:52:02.138638Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_features = master_df.iloc[:, :-6].values ** 2\n",
    "target_variables = master_df.iloc[:, -6:].values\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input_features, target_variables, test_size=0.2, shuffle=False)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Scale the input features based on the training data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the validation and test data based on the training data\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert the scaled data to PyTorch tensors\n",
    "\n",
    "X_train_tensor = torch.Tensor(X_train_scaled)\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "X_val_tensor = torch.Tensor(X_val_scaled)\n",
    "y_val_tensor = torch.Tensor(y_val)\n",
    "X_test_tensor = torch.Tensor(X_test_scaled)\n",
    "y_test_tensor = torch.Tensor(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T11:57:17.393078Z",
     "end_time": "2023-06-07T11:57:17.402574Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#benchmark error\n",
    "total_mse = 0\n",
    "c = 0\n",
    "for i in range(1, len(y_test_tensor)):\n",
    "    #mse = mean_squared_error(y_test_tensor[i], y_test_tensor[i-1])\n",
    "    mse = mean_squared_error(y_test_tensor[i], [0,0,0,0,0,0])\n",
    "    total_mse += mse\n",
    "    c += 1\n",
    "\n",
    "total_mse/c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T11:57:17.571212Z",
     "end_time": "2023-06-07T11:57:17.642334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, 64)  # Dense layer with 64 units\n",
    "        self.fc2 = nn.Linear(64, output_size)  # Final output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = F.relu(out)  # Apply ReLU activation between LSTM and first dense layer\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = F.relu(out)  # Apply ReLU activation to the output of the first dense layer\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T11:57:18.215284Z",
     "end_time": "2023-06-07T11:57:18.221355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_size = X_train_tensor.shape[1]\n",
    "output_size = y_train_tensor.shape[1]\n",
    "hidden_size = 256\n",
    "num_layers = 3\n",
    "dropout = 0.3\n",
    "lr = 0.01\n",
    "mps_device = torch.device(\"mps\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T11:58:01.427352Z",
     "end_time": "2023-06-07T11:58:01.432498Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = RNN(input_size, hidden_size, output_size, num_layers, dropout)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T11:04:37.978958Z",
     "end_time": "2023-06-07T11:04:37.991726Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "sequence_length = 10  # Number of previous days to consider\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    # Loop through each sequence in the training data\n",
    "    for i in range(sequence_length, X_train_tensor.shape[0]):\n",
    "        # Extract the current sequence and target\n",
    "        input_seq = X_train_tensor[i - sequence_length:i].view(1, sequence_length, -1)\n",
    "        target_seq = y_train_tensor[i]\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output, target_seq.unsqueeze(0))\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / (X_train_tensor.shape[0] - sequence_length)\n",
    "    train_losses.append(average_loss)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {average_loss}')\n",
    "\n",
    "    # Validation stage\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "\n",
    "        for i in range(sequence_length, X_val_tensor.shape[0]):\n",
    "            input_seq = X_val_tensor[i - sequence_length:i].view(1, sequence_length, -1)\n",
    "            target_seq = y_val_tensor[i]\n",
    "\n",
    "            output = model(input_seq)\n",
    "            val_loss = criterion(output, target_seq.unsqueeze(0))\n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "        average_val_loss = total_val_loss / (X_val_tensor.shape[0] - sequence_length)\n",
    "        val_losses.append(average_val_loss)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {average_val_loss}')\n",
    "\n",
    "        # Check if current model is the best based on validation loss\n",
    "        if average_val_loss < best_loss:\n",
    "            best_loss = average_val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "# After training, use the best model for testing\n",
    "model = best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T10:52:26.272553Z",
     "end_time": "2023-06-07T10:59:06.610026Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(train_losses, label='Training Loss')\n",
    "    ax.plot(val_losses, label='Validation Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "plot_losses(train_losses, val_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T11:29:40.798333Z",
     "end_time": "2023-06-07T11:29:40.955675Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(sequence_length, X_test_tensor.shape[0]):\n",
    "        input_seq = X_test_tensor[i - sequence_length:i].view(1, sequence_length, -1)\n",
    "        target_seq = y_test_tensor[i]\n",
    "\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output, target_seq.unsqueeze(0))\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Extract the scalar value from the tensor and append it to predictions\n",
    "        predictions.append(output.squeeze().tolist())\n",
    "\n",
    "    average_test_loss = test_loss / (X_test_tensor.shape[0] - sequence_length)\n",
    "    print(f'Test Loss: {average_test_loss}')\n",
    "\n",
    "    # Convert the predictions and target values to numpy arrays\n",
    "    predictions = np.array(predictions)\n",
    "    targets = y_test_tensor[sequence_length:].numpy()\n",
    "\n",
    "    # Evaluate the performance using appropriate metrics\n",
    "    # For example, calculate mean squared error (MSE)\n",
    "    mse = mean_squared_error(targets, predictions)\n",
    "    metric = R2Score()\n",
    "    r2 = metric.update(torch.tensor(predictions), torch.tensor(targets)).compute()\n",
    "    print(f'Mean Squared Error (MSE): {mse}')\n",
    "    print(f'R2 Score: {r2}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T11:29:42.167101Z",
     "end_time": "2023-06-07T11:29:44.081810Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T11:29:50.774388Z",
     "end_time": "2023-06-07T11:29:50.781270Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prediction(input):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_seq = torch.tensor(input).view(1, sequence_length, -1)\n",
    "        output = model(input_seq)\n",
    "        return output.squeeze().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T11:29:50.970175Z",
     "end_time": "2023-06-07T11:29:50.974005Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = prediction(X_test_tensor[-sequence_length:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T11:30:05.822139Z",
     "end_time": "2023-06-07T11:30:05.837688Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T11:30:06.606259Z",
     "end_time": "2023-06-07T11:30:06.609147Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test_tensor[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T11:30:07.257100Z",
     "end_time": "2023-06-07T11:30:07.266004Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T12:13:04.741373Z",
     "end_time": "2023-06-07T12:13:04.749586Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Autogloun"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n",
    "import os.path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:50:59.991969Z",
     "end_time": "2023-06-07T13:51:00.003513Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:51:00.246111Z",
     "end_time": "2023-06-07T13:51:00.270725Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "#y = master_df.iloc[:, -6:].copy()\n",
    "#y = y.reset_index(drop=True)\n",
    "#X = master_df.iloc[:, :-6].copy()\n",
    "#X['Date'] = X.index\n",
    "#X = X.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:51:00.493886Z",
     "end_time": "2023-06-07T13:51:00.507322Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "#auto_ml_pipeline_feature_generator = AutoMLPipelineFeatureGenerator()\n",
    "#X = auto_ml_pipeline_feature_generator.fit_transform(X=X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:51:00.953663Z",
     "end_time": "2023-06-07T13:51:00.961745Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:51:01.439805Z",
     "end_time": "2023-06-07T13:51:01.496326Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "#df = pd.concat([X, y], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:51:02.490127Z",
     "end_time": "2023-06-07T13:51:02.501989Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:51:02.770094Z",
     "end_time": "2023-06-07T13:51:02.778149Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "train_len = 0.8\n",
    "train_data = TabularDataset(master_df[:int(len(master_df)*train_len)])\n",
    "test_data = TabularDataset(master_df[int(len(master_df)*train_len):])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:02:13.736542Z",
     "end_time": "2023-06-07T14:02:13.747935Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "labels = ['ecmwf-eps_9', 'ecmwf-eps_10', 'ecmwf-eps_11', 'ecmwf-eps_12', 'ecmwf-eps_13',\n",
    "          'ecmwf-eps_14']\n",
    "save_path = 'models'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:02:14.817431Z",
     "end_time": "2023-06-07T14:02:14.829191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "2018-07-11 00:00:00    0.0\n2018-07-11 12:00:00    1.0\n2018-07-12 00:00:00    0.0\n2018-07-12 12:00:00    1.0\n2018-07-13 00:00:00    0.0\nName: noon, dtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:02:25.972054Z",
     "end_time": "2023-06-07T14:02:25.977144Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "class MultilabelPredictor():\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def feature_imp(self,data, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating feature importance for label: {label} ...\")\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:51:11.800700Z",
     "end_time": "2023-06-07T13:51:11.822593Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/Predictor_ecmwf-eps_9\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/Predictor_ecmwf-eps_10\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/Predictor_ecmwf-eps_11\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/Predictor_ecmwf-eps_12\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/Predictor_ecmwf-eps_13\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/Predictor_ecmwf-eps_14\"\n"
     ]
    }
   ],
   "source": [
    "multi_predictor = MultilabelPredictor(labels=labels, path=save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:51:14.137531Z",
     "end_time": "2023-06-07T13:51:14.160433Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/Predictor_ecmwf-eps_9/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2785\n",
      "Train Data Columns: 22\n",
      "Label Column: ecmwf-eps_9\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (7.132000000000005, -7.687000000000005, 0.01289, 1.61633)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1346.74 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 22 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 22 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t22 features in original data used to generate 22 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.17953321364452424, Train Rows: 2285, Val Rows: 500\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.9155\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.9131\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ecmwf-eps_9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.6952\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.64s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.6952\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.9s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.6895\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.7262\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.73s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.7197\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.7206\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.6699\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 15.96s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/Predictor_ecmwf-eps_9/\")\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/Predictor_ecmwf-eps_10/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2785\n",
      "Train Data Columns: 23\n",
      "Label Column: ecmwf-eps_10\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (6.731999999999999, -7.844000000000001, 0.01838, 1.49726)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1354.44 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.51 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 23 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 23 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t23 features in original data used to generate 23 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.51 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.17953321364452424, Train Rows: 2285, Val Rows: 500\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-1.0463\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1.0434\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ecmwf-eps_10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.8937\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.19s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.787\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.8916\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.7497\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.8509\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.73\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.7196\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 21.64s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/Predictor_ecmwf-eps_10/\")\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/Predictor_ecmwf-eps_11/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2785\n",
      "Train Data Columns: 24\n",
      "Label Column: ecmwf-eps_11\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (7.802, -7.863000000000003, 0.02167, 1.37127)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1353.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.53 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 24 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 24 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t24 features in original data used to generate 24 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.53 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.17953321364452424, Train Rows: 2285, Val Rows: 500\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-1.1044\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1.1007\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ecmwf-eps_11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.8508\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.75s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.7884\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.8645\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.675\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.26s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.8459\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.7115\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.84s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.6658\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 15.41s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/Predictor_ecmwf-eps_11/\")\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/Predictor_ecmwf-eps_12/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2785\n",
      "Train Data Columns: 25\n",
      "Label Column: ecmwf-eps_12\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5.904999999999994, -6.439, 0.02074, 1.25962)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1362.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 25 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 25 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t25 features in original data used to generate 25 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.56 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.17953321364452424, Train Rows: 2285, Val Rows: 500\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-1.0595\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1.056\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ecmwf-eps_12 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.7894\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.707\t = Validation score   (-root_mean_squared_error)\n",
      "\t53.71s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.7784\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.6177\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.6s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.7435\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.6522\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.6155\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 65.24s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/Predictor_ecmwf-eps_12/\")\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/Predictor_ecmwf-eps_13/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2785\n",
      "Train Data Columns: 26\n",
      "Label Column: ecmwf-eps_13\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5.749000000000002, -5.777999999999995, 0.01271, 1.17099)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1366.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.58 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 26 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 26 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t26 features in original data used to generate 26 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.58 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.17953321364452424, Train Rows: 2285, Val Rows: 500\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.988\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.9847\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ecmwf-eps_13 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.7154\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.39s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.6187\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.6971\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.5701\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.6662\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.54s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.5631\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.63s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.5524\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 13.28s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/Predictor_ecmwf-eps_13/\")\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/Predictor_ecmwf-eps_14/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2785\n",
      "Train Data Columns: 27\n",
      "Label Column: ecmwf-eps_14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (4.6739999999999995, -5.354000000000003, 0.00665, 1.08207)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1367.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.6 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 27 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 27 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t27 features in original data used to generate 27 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.6 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.17953321364452424, Train Rows: 2285, Val Rows: 500\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.9793\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.9762\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ecmwf-eps_14 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.6606\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.6s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.5961\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.672\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.5603\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.34s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.6337\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.5662\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.58s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.5506\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 24.36s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/Predictor_ecmwf-eps_14/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('models/')\n"
     ]
    }
   ],
   "source": [
    "multi_predictor.fit(train_data) # add presets='best_quality' for better results, but longer runtime"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:51:14.724324Z",
     "end_time": "2023-06-07T13:53:51.194873Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "                     gfs-ens-bc_9  gfs-ens-bc_10  gfs-ens-bc_11  \\\n2022-06-03 00:00:00        -0.324         -0.276         -0.110   \n2022-06-03 12:00:00        -0.233         -0.238         -0.207   \n2022-06-04 00:00:00        -0.164         -0.103         -0.039   \n2022-06-04 12:00:00        -0.224         -0.029         -0.032   \n2022-06-05 00:00:00         0.238          0.247          0.328   \n\n                     gfs-ens-bc_12  gfs-ens-bc_13  gfs-ens-bc_14  cmc-ens_9  \\\n2022-06-03 00:00:00         -0.182         -0.039          0.143      0.272   \n2022-06-03 12:00:00         -0.074          0.055          0.106     -0.070   \n2022-06-04 00:00:00          0.044          0.033          0.025      0.201   \n2022-06-04 12:00:00         -0.087         -0.065          0.020     -0.119   \n2022-06-05 00:00:00          0.372          0.151         -0.013     -0.160   \n\n                     cmc-ens_10  cmc-ens_11  cmc-ens_12  ...  month  \\\n2022-06-03 00:00:00       0.178       0.121       0.060  ...    1.0   \n2022-06-03 12:00:00      -0.170      -0.144      -0.096  ...    1.0   \n2022-06-04 00:00:00      -0.113      -0.270      -0.269  ...    1.0   \n2022-06-04 12:00:00      -0.236      -0.202      -0.056  ...    1.0   \n2022-06-05 00:00:00      -0.389      -0.462      -0.334  ...    1.0   \n\n                     ecmwf_diff_8  ecmwf_diff_9  error_9  error_10  error_11  \\\n2022-06-03 00:00:00        -0.456        -0.438   -0.122     0.004     0.088   \n2022-06-03 12:00:00        -0.433        -0.322   -0.128    -0.068     0.026   \n2022-06-04 00:00:00        -0.194         0.044   -0.064    -0.042    -0.085   \n2022-06-04 12:00:00        -0.554        -0.198    0.032     0.000     0.036   \n2022-06-05 00:00:00         0.011        -0.020   -0.189    -0.179    -0.218   \n\n                     error_12  error_13  error_14  day_8_error  \n2022-06-03 00:00:00     0.016    -0.049    -0.072       -0.137  \n2022-06-03 12:00:00     0.021     0.002     0.007       -0.055  \n2022-06-04 00:00:00    -0.028     0.021     0.030        0.034  \n2022-06-04 12:00:00     0.072     0.047     0.033       -0.191  \n2022-06-05 00:00:00    -0.228    -0.159    -0.049        0.387  \n\n[5 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gfs-ens-bc_9</th>\n      <th>gfs-ens-bc_10</th>\n      <th>gfs-ens-bc_11</th>\n      <th>gfs-ens-bc_12</th>\n      <th>gfs-ens-bc_13</th>\n      <th>gfs-ens-bc_14</th>\n      <th>cmc-ens_9</th>\n      <th>cmc-ens_10</th>\n      <th>cmc-ens_11</th>\n      <th>cmc-ens_12</th>\n      <th>...</th>\n      <th>month</th>\n      <th>ecmwf_diff_8</th>\n      <th>ecmwf_diff_9</th>\n      <th>error_9</th>\n      <th>error_10</th>\n      <th>error_11</th>\n      <th>error_12</th>\n      <th>error_13</th>\n      <th>error_14</th>\n      <th>day_8_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-06-03 00:00:00</th>\n      <td>-0.324</td>\n      <td>-0.276</td>\n      <td>-0.110</td>\n      <td>-0.182</td>\n      <td>-0.039</td>\n      <td>0.143</td>\n      <td>0.272</td>\n      <td>0.178</td>\n      <td>0.121</td>\n      <td>0.060</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-0.456</td>\n      <td>-0.438</td>\n      <td>-0.122</td>\n      <td>0.004</td>\n      <td>0.088</td>\n      <td>0.016</td>\n      <td>-0.049</td>\n      <td>-0.072</td>\n      <td>-0.137</td>\n    </tr>\n    <tr>\n      <th>2022-06-03 12:00:00</th>\n      <td>-0.233</td>\n      <td>-0.238</td>\n      <td>-0.207</td>\n      <td>-0.074</td>\n      <td>0.055</td>\n      <td>0.106</td>\n      <td>-0.070</td>\n      <td>-0.170</td>\n      <td>-0.144</td>\n      <td>-0.096</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-0.433</td>\n      <td>-0.322</td>\n      <td>-0.128</td>\n      <td>-0.068</td>\n      <td>0.026</td>\n      <td>0.021</td>\n      <td>0.002</td>\n      <td>0.007</td>\n      <td>-0.055</td>\n    </tr>\n    <tr>\n      <th>2022-06-04 00:00:00</th>\n      <td>-0.164</td>\n      <td>-0.103</td>\n      <td>-0.039</td>\n      <td>0.044</td>\n      <td>0.033</td>\n      <td>0.025</td>\n      <td>0.201</td>\n      <td>-0.113</td>\n      <td>-0.270</td>\n      <td>-0.269</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-0.194</td>\n      <td>0.044</td>\n      <td>-0.064</td>\n      <td>-0.042</td>\n      <td>-0.085</td>\n      <td>-0.028</td>\n      <td>0.021</td>\n      <td>0.030</td>\n      <td>0.034</td>\n    </tr>\n    <tr>\n      <th>2022-06-04 12:00:00</th>\n      <td>-0.224</td>\n      <td>-0.029</td>\n      <td>-0.032</td>\n      <td>-0.087</td>\n      <td>-0.065</td>\n      <td>0.020</td>\n      <td>-0.119</td>\n      <td>-0.236</td>\n      <td>-0.202</td>\n      <td>-0.056</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-0.554</td>\n      <td>-0.198</td>\n      <td>0.032</td>\n      <td>0.000</td>\n      <td>0.036</td>\n      <td>0.072</td>\n      <td>0.047</td>\n      <td>0.033</td>\n      <td>-0.191</td>\n    </tr>\n    <tr>\n      <th>2022-06-05 00:00:00</th>\n      <td>0.238</td>\n      <td>0.247</td>\n      <td>0.328</td>\n      <td>0.372</td>\n      <td>0.151</td>\n      <td>-0.013</td>\n      <td>-0.160</td>\n      <td>-0.389</td>\n      <td>-0.462</td>\n      <td>-0.334</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.011</td>\n      <td>-0.020</td>\n      <td>-0.189</td>\n      <td>-0.179</td>\n      <td>-0.218</td>\n      <td>-0.228</td>\n      <td>-0.159</td>\n      <td>-0.049</td>\n      <td>0.387</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_predictor = MultilabelPredictor.load(save_path)\n",
    "test_data_nolab = test_data.drop(columns=labels)\n",
    "test_data_nolab.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:53:50.720359Z",
     "end_time": "2023-06-07T13:53:51.195126Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with TabularPredictor for label: ecmwf-eps_9 ...\n",
      "Predicting with TabularPredictor for label: ecmwf-eps_10 ...\n",
      "Predicting with TabularPredictor for label: ecmwf-eps_11 ...\n",
      "Predicting with TabularPredictor for label: ecmwf-eps_12 ...\n",
      "Predicting with TabularPredictor for label: ecmwf-eps_13 ...\n",
      "Predicting with TabularPredictor for label: ecmwf-eps_14 ...\n",
      "Predictions:  \n",
      "                      ecmwf-eps_9  ecmwf-eps_10  ecmwf-eps_11  ecmwf-eps_12  \\\n",
      "2022-06-03 00:00:00    -0.153279     -0.101186     -0.045180     -0.044340   \n",
      "2022-06-03 12:00:00    -0.127652     -0.121036     -0.081766      0.037684   \n",
      "2022-06-04 00:00:00    -0.017125     -0.003698     -0.051792     -0.057574   \n",
      "2022-06-04 12:00:00    -0.200583     -0.070566     -0.066036     -0.028122   \n",
      "2022-06-05 00:00:00     0.284712      0.092995     -0.036777     -0.003194   \n",
      "...                          ...           ...           ...           ...   \n",
      "2023-05-15 00:00:00     1.085515      0.974927      0.640173      0.622165   \n",
      "2023-05-15 12:00:00    -0.519545     -0.041843      0.005066     -0.257312   \n",
      "2023-05-16 00:00:00     0.297869      0.057573      0.186729      0.485888   \n",
      "2023-05-16 12:00:00    -0.569510     -0.404500     -0.260601     -0.153149   \n",
      "2023-05-17 00:00:00     0.337411      0.107750     -0.078613     -0.272118   \n",
      "\n",
      "                     ecmwf-eps_13  ecmwf-eps_14  \n",
      "2022-06-03 00:00:00      0.006574      0.035017  \n",
      "2022-06-03 12:00:00      0.049881      0.000137  \n",
      "2022-06-04 00:00:00     -0.038581     -0.047281  \n",
      "2022-06-04 12:00:00      0.016702      0.032175  \n",
      "2022-06-05 00:00:00     -0.034599     -0.060555  \n",
      "...                           ...           ...  \n",
      "2023-05-15 00:00:00      0.515361      0.295572  \n",
      "2023-05-15 12:00:00     -0.165178     -0.127552  \n",
      "2023-05-16 00:00:00      0.383707      0.181622  \n",
      "2023-05-16 12:00:00      0.035522      0.078130  \n",
      "2023-05-17 00:00:00     -0.316007     -0.198288  \n",
      "\n",
      "[697 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions = multi_predictor.predict(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:53:50.735951Z",
     "end_time": "2023-06-07T13:53:51.298132Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "ecmwf-eps_9     0.337411\necmwf-eps_10    0.107750\necmwf-eps_11   -0.078613\necmwf-eps_12   -0.272118\necmwf-eps_13   -0.316007\necmwf-eps_14   -0.198288\nName: 2023-05-17 00:00:00, dtype: float32"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictions.iloc[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:53:51.244352Z",
     "end_time": "2023-06-07T13:53:51.313428Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "ecmwf-eps_9     0.482\necmwf-eps_10    0.299\necmwf-eps_11    0.191\necmwf-eps_12   -0.095\necmwf-eps_13   -0.359\necmwf-eps_14   -0.209\nName: 2023-05-17 00:00:00, dtype: float64"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[labels].iloc[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:53:51.251067Z",
     "end_time": "2023-06-07T13:53:51.313639Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "Evaluation: root_mean_squared_error on test data: -0.6147391501458047\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.6147391501458047,\n",
      "    \"mean_squared_error\": -0.3779042227219862,\n",
      "    \"mean_absolute_error\": -0.3769219317902945,\n",
      "    \"r2\": 0.8466743279176888,\n",
      "    \"pearsonr\": 0.9215847340977754,\n",
      "    \"median_absolute_error\": -0.1803798375129695\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: ecmwf-eps_9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "Evaluation: root_mean_squared_error on test data: -0.8552817630958501\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.8552817630958501,\n",
      "    \"mean_squared_error\": -0.7315068942843459,\n",
      "    \"mean_absolute_error\": -0.5720550260655141,\n",
      "    \"r2\": 0.6744420658097334,\n",
      "    \"pearsonr\": 0.8218383052001562,\n",
      "    \"median_absolute_error\": -0.33790985298156784\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: ecmwf-eps_10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "Evaluation: root_mean_squared_error on test data: -1.0065495797414432\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -1.0065495797414432,\n",
      "    \"mean_squared_error\": -1.0131420564776759,\n",
      "    \"mean_absolute_error\": -0.6927580759331607,\n",
      "    \"r2\": 0.4557150101595919,\n",
      "    \"pearsonr\": 0.685727037302492,\n",
      "    \"median_absolute_error\": -0.430783279418943\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: ecmwf-eps_11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "Evaluation: root_mean_squared_error on test data: -1.0185292849452052\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -1.0185292849452052,\n",
      "    \"mean_squared_error\": -1.0374019042909912,\n",
      "    \"mean_absolute_error\": -0.7054282702972104,\n",
      "    \"r2\": 0.3290480039262397,\n",
      "    \"pearsonr\": 0.5935811014811108,\n",
      "    \"median_absolute_error\": -0.418890541791916\n",
      "}\n",
      "FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "Evaluation: root_mean_squared_error on test data: -0.9607006970238793\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.9607006970238793,\n",
      "    \"mean_squared_error\": -0.9229458292621674,\n",
      "    \"mean_absolute_error\": -0.647874110972947,\n",
      "    \"r2\": 0.2735946178272949,\n",
      "    \"pearsonr\": 0.538270222668043,\n",
      "    \"median_absolute_error\": -0.38652839136123696\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: ecmwf-eps_12 ...\n",
      "Evaluating TabularPredictor for label: ecmwf-eps_13 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "Evaluation: root_mean_squared_error on test data: -0.9055861282926653\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.9055861282926653,\n",
      "    \"mean_squared_error\": -0.8200862357560996,\n",
      "    \"mean_absolute_error\": -0.61550115025409,\n",
      "    \"r2\": 0.24746387245334445,\n",
      "    \"pearsonr\": 0.5154545186103214,\n",
      "    \"median_absolute_error\": -0.373869423866271\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: ecmwf-eps_14 ...\n",
      "Evaluated using metrics: {'ecmwf-eps_9': root_mean_squared_error, 'ecmwf-eps_10': root_mean_squared_error, 'ecmwf-eps_11': root_mean_squared_error, 'ecmwf-eps_12': root_mean_squared_error, 'ecmwf-eps_13': root_mean_squared_error, 'ecmwf-eps_14': root_mean_squared_error}\n"
     ]
    }
   ],
   "source": [
    "evaluations = multi_predictor.evaluate(test_data)\n",
    "#print(evaluations)\n",
    "print(\"Evaluated using metrics:\", multi_predictor.eval_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:53:51.255391Z",
     "end_time": "2023-06-07T13:53:52.519817Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "{'ecmwf-eps_9': {'root_mean_squared_error': -0.6147391501458047,\n  'mean_squared_error': -0.3779042227219862,\n  'mean_absolute_error': -0.3769219317902945,\n  'r2': 0.8466743279176888,\n  'pearsonr': 0.9215847340977754,\n  'median_absolute_error': -0.1803798375129695},\n 'ecmwf-eps_10': {'root_mean_squared_error': -0.8552817630958501,\n  'mean_squared_error': -0.7315068942843459,\n  'mean_absolute_error': -0.5720550260655141,\n  'r2': 0.6744420658097334,\n  'pearsonr': 0.8218383052001562,\n  'median_absolute_error': -0.33790985298156784},\n 'ecmwf-eps_11': {'root_mean_squared_error': -1.0065495797414432,\n  'mean_squared_error': -1.0131420564776759,\n  'mean_absolute_error': -0.6927580759331607,\n  'r2': 0.4557150101595919,\n  'pearsonr': 0.685727037302492,\n  'median_absolute_error': -0.430783279418943},\n 'ecmwf-eps_12': {'root_mean_squared_error': -1.0185292849452052,\n  'mean_squared_error': -1.0374019042909912,\n  'mean_absolute_error': -0.7054282702972104,\n  'r2': 0.3290480039262397,\n  'pearsonr': 0.5935811014811108,\n  'median_absolute_error': -0.418890541791916},\n 'ecmwf-eps_13': {'root_mean_squared_error': -0.9607006970238793,\n  'mean_squared_error': -0.9229458292621674,\n  'mean_absolute_error': -0.647874110972947,\n  'r2': 0.2735946178272949,\n  'pearsonr': 0.538270222668043,\n  'median_absolute_error': -0.38652839136123696},\n 'ecmwf-eps_14': {'root_mean_squared_error': -0.9055861282926653,\n  'mean_squared_error': -0.8200862357560996,\n  'mean_absolute_error': -0.61550115025409,\n  'r2': 0.24746387245334445,\n  'pearsonr': 0.5154545186103214,\n  'median_absolute_error': -0.373869423866271}}"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:53:52.525839Z",
     "end_time": "2023-06-07T13:53:52.532366Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "                 model  score_val  pred_time_val   fit_time  \\\n0  WeightedEnsemble_L2  -0.552432       0.014438  10.016679   \n1       NeuralNetTorch  -0.563092       0.003184   3.626709   \n2      NeuralNetFastAI  -0.570123       0.006074   1.660152   \n3             CatBoost  -0.618672       0.001589   3.061709   \n4              XGBoost  -0.666193       0.003298   1.536326   \n5        ExtraTreesMSE  -0.697116       0.026784   0.591878   \n6      RandomForestMSE  -0.715398       0.027213   2.391321   \n7       KNeighborsDist  -0.984747       0.005549   0.006869   \n8       KNeighborsUnif  -0.988035       0.004825   0.005643   \n\n   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                0.000293           0.131783            2       True   \n1                0.003184           3.626709            1       True   \n2                0.006074           1.660152            1       True   \n3                0.001589           3.061709            1       True   \n4                0.003298           1.536326            1       True   \n5                0.026784           0.591878            1       True   \n6                0.027213           2.391321            1       True   \n7                0.005549           0.006869            1       True   \n8                0.004825           0.005643            1       True   \n\n   fit_order  \n0          9  \n1          8  \n2          6  \n3          4  \n4          7  \n5          5  \n6          3  \n7          2  \n8          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_val</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>-0.552432</td>\n      <td>0.014438</td>\n      <td>10.016679</td>\n      <td>0.000293</td>\n      <td>0.131783</td>\n      <td>2</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NeuralNetTorch</td>\n      <td>-0.563092</td>\n      <td>0.003184</td>\n      <td>3.626709</td>\n      <td>0.003184</td>\n      <td>3.626709</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NeuralNetFastAI</td>\n      <td>-0.570123</td>\n      <td>0.006074</td>\n      <td>1.660152</td>\n      <td>0.006074</td>\n      <td>1.660152</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CatBoost</td>\n      <td>-0.618672</td>\n      <td>0.001589</td>\n      <td>3.061709</td>\n      <td>0.001589</td>\n      <td>3.061709</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>XGBoost</td>\n      <td>-0.666193</td>\n      <td>0.003298</td>\n      <td>1.536326</td>\n      <td>0.003298</td>\n      <td>1.536326</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ExtraTreesMSE</td>\n      <td>-0.697116</td>\n      <td>0.026784</td>\n      <td>0.591878</td>\n      <td>0.026784</td>\n      <td>0.591878</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RandomForestMSE</td>\n      <td>-0.715398</td>\n      <td>0.027213</td>\n      <td>2.391321</td>\n      <td>0.027213</td>\n      <td>2.391321</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>KNeighborsDist</td>\n      <td>-0.984747</td>\n      <td>0.005549</td>\n      <td>0.006869</td>\n      <td>0.005549</td>\n      <td>0.006869</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>KNeighborsUnif</td>\n      <td>-0.988035</td>\n      <td>0.004825</td>\n      <td>0.005643</td>\n      <td>0.004825</td>\n      <td>0.005643</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_class = multi_predictor.get_predictor('ecmwf-eps_13')\n",
    "predictor_class.leaderboard(silent=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T13:53:52.531107Z",
     "end_time": "2023-06-07T13:53:52.584137Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# feature importance / training models for individual days"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "day = 0\n",
    "train_df = train_data.iloc[:, :-5+day]\n",
    "test_df = test_data.iloc[:, :-5+day]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:08:09.241954Z",
     "end_time": "2023-06-07T14:08:09.251644Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "                     gfs-ens-bc_9  gfs-ens-bc_10  gfs-ens-bc_11  \\\n2018-07-11 00:00:00         0.012          0.009          0.006   \n2018-07-11 12:00:00         0.001          0.001          0.004   \n2018-07-12 00:00:00         0.010          0.007          0.011   \n2018-07-12 12:00:00         0.006          0.009          0.010   \n2018-07-13 00:00:00         0.012          0.007          0.008   \n\n                     gfs-ens-bc_12  gfs-ens-bc_13  gfs-ens-bc_14  cmc-ens_9  \\\n2018-07-11 00:00:00          0.002          0.004          0.011     -0.008   \n2018-07-11 12:00:00          0.009          0.011          0.013     -0.003   \n2018-07-12 00:00:00          0.013          0.011          0.008     -0.007   \n2018-07-12 12:00:00          0.009          0.009          0.009     -0.008   \n2018-07-13 00:00:00          0.007          0.009          0.009     -0.007   \n\n                     cmc-ens_10  cmc-ens_11  cmc-ens_12  ...  ecmwf_diff_9  \\\n2018-07-11 00:00:00      -0.005      -0.001      -0.003  ...         0.082   \n2018-07-11 12:00:00      -0.002      -0.004      -0.008  ...         0.063   \n2018-07-12 00:00:00      -0.011      -0.013      -0.011  ...         0.025   \n2018-07-12 12:00:00      -0.009      -0.009      -0.010  ...         0.039   \n2018-07-13 00:00:00      -0.009      -0.009      -0.010  ...         0.003   \n\n                     error_9  error_10  error_11  error_12  error_13  \\\n2018-07-11 00:00:00    0.000     0.000     0.000     0.000     0.000   \n2018-07-11 12:00:00    0.002     0.000     0.000     0.000     0.001   \n2018-07-12 00:00:00    0.003     0.003     0.001     0.000    -0.001   \n2018-07-12 12:00:00    0.000     0.000     0.000     0.001     0.001   \n2018-07-13 00:00:00   -0.002     0.000     0.000     0.000     0.001   \n\n                     error_14  noon  day_8_error  ecmwf-eps_9  \n2018-07-11 00:00:00     0.000   0.0        0.000        0.000  \n2018-07-11 12:00:00    -0.001   1.0        0.005        0.001  \n2018-07-12 00:00:00     0.000   0.0        0.000        0.000  \n2018-07-12 12:00:00    -0.001   1.0       -0.002       -0.003  \n2018-07-13 00:00:00     0.001   0.0        0.000        0.000  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gfs-ens-bc_9</th>\n      <th>gfs-ens-bc_10</th>\n      <th>gfs-ens-bc_11</th>\n      <th>gfs-ens-bc_12</th>\n      <th>gfs-ens-bc_13</th>\n      <th>gfs-ens-bc_14</th>\n      <th>cmc-ens_9</th>\n      <th>cmc-ens_10</th>\n      <th>cmc-ens_11</th>\n      <th>cmc-ens_12</th>\n      <th>...</th>\n      <th>ecmwf_diff_9</th>\n      <th>error_9</th>\n      <th>error_10</th>\n      <th>error_11</th>\n      <th>error_12</th>\n      <th>error_13</th>\n      <th>error_14</th>\n      <th>noon</th>\n      <th>day_8_error</th>\n      <th>ecmwf-eps_9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-07-11 00:00:00</th>\n      <td>0.012</td>\n      <td>0.009</td>\n      <td>0.006</td>\n      <td>0.002</td>\n      <td>0.004</td>\n      <td>0.011</td>\n      <td>-0.008</td>\n      <td>-0.005</td>\n      <td>-0.001</td>\n      <td>-0.003</td>\n      <td>...</td>\n      <td>0.082</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2018-07-11 12:00:00</th>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>0.004</td>\n      <td>0.009</td>\n      <td>0.011</td>\n      <td>0.013</td>\n      <td>-0.003</td>\n      <td>-0.002</td>\n      <td>-0.004</td>\n      <td>-0.008</td>\n      <td>...</td>\n      <td>0.063</td>\n      <td>0.002</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.001</td>\n      <td>-0.001</td>\n      <td>1.0</td>\n      <td>0.005</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>2018-07-12 00:00:00</th>\n      <td>0.010</td>\n      <td>0.007</td>\n      <td>0.011</td>\n      <td>0.013</td>\n      <td>0.011</td>\n      <td>0.008</td>\n      <td>-0.007</td>\n      <td>-0.011</td>\n      <td>-0.013</td>\n      <td>-0.011</td>\n      <td>...</td>\n      <td>0.025</td>\n      <td>0.003</td>\n      <td>0.003</td>\n      <td>0.001</td>\n      <td>0.000</td>\n      <td>-0.001</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2018-07-12 12:00:00</th>\n      <td>0.006</td>\n      <td>0.009</td>\n      <td>0.010</td>\n      <td>0.009</td>\n      <td>0.009</td>\n      <td>0.009</td>\n      <td>-0.008</td>\n      <td>-0.009</td>\n      <td>-0.009</td>\n      <td>-0.010</td>\n      <td>...</td>\n      <td>0.039</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>-0.001</td>\n      <td>1.0</td>\n      <td>-0.002</td>\n      <td>-0.003</td>\n    </tr>\n    <tr>\n      <th>2018-07-13 00:00:00</th>\n      <td>0.012</td>\n      <td>0.007</td>\n      <td>0.008</td>\n      <td>0.007</td>\n      <td>0.009</td>\n      <td>0.009</td>\n      <td>-0.007</td>\n      <td>-0.009</td>\n      <td>-0.009</td>\n      <td>-0.010</td>\n      <td>...</td>\n      <td>0.003</td>\n      <td>-0.002</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:02:41.536877Z",
     "end_time": "2023-06-07T14:02:41.550329Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "label = f\"ecmwf-eps_{day+9}\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:02:41.874587Z",
     "end_time": "2023-06-07T14:02:41.877293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230607_200242/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230607_200242/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2785\n",
      "Train Data Columns: 23\n",
      "Label Column: ecmwf-eps_9\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (7.132000000000005, -7.687000000000005, 0.01289, 1.61633)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1347.42 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.51 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 23 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 22 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['noon']\n",
      "\t0.0s = Fit runtime\n",
      "\t23 features in original data used to generate 23 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.17953321364452424, Train Rows: 2285, Val Rows: 500\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.9155\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.9131\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.6745\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.4s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.6332\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.6469\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.6057\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.23s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.6768\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.646\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.65s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.5896\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.08s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230607_200242/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:02:42.433269Z",
     "end_time": "2023-06-07T14:03:01.552347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "y_test = test_df[label]\n",
    "test_data_nolab = test_df.drop(columns=[label])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:09:19.737158Z",
     "end_time": "2023-06-07T14:09:19.753640Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: root_mean_squared_error on test data: -0.5026550725008505\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.5026550725008505,\n",
      "    \"mean_squared_error\": -0.2526621219108353,\n",
      "    \"mean_absolute_error\": -0.29319657492146317,\n",
      "    \"r2\": 0.8974883387841334,\n",
      "    \"pearsonr\": 0.9483040638861256,\n",
      "    \"median_absolute_error\": -0.12170523291826252\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for ecmwf-eps_9\n"
     ]
    }
   ],
   "source": [
    "print(f\"results for {label}\")\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:11:19.062601Z",
     "end_time": "2023-06-07T14:11:19.169821Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['ecmwf-eps_10', 'ecmwf-eps_11', 'ecmwf-eps_12', 'ecmwf-eps_13', 'ecmwf-eps_14']\n",
      "Computing feature importance via permutation shuffling for 23 features using 697 rows with 5 shuffle sets...\n",
      "\t10.16s\t= Expected runtime (2.03s per shuffle set)\n",
      "\t1.68s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    }
   ],
   "source": [
    "shap_values = predictor.feature_importance(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:03:01.527689Z",
     "end_time": "2023-06-07T14:03:03.756670Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "               importance    stddev       p_value  n  p99_high   p99_low\nday_8_error      0.793485  0.024949  1.171358e-07  5  0.844857  0.742114\ngfs-ens-bc_9     0.434945  0.022716  8.896256e-07  5  0.481718  0.388172\necmwf_diff_8     0.314502  0.023413  3.658877e-06  5  0.362711  0.266293\nnoon             0.214596  0.020989  1.084370e-05  5  0.257813  0.171378\ncmc-ens_9        0.110671  0.015849  4.912572e-05  5  0.143305  0.078037\ngfs-ens-bc_11    0.082918  0.005148  1.773224e-06  5  0.093517  0.072319\ngfs-ens-bc_10    0.028948  0.002902  1.195742e-05  5  0.034924  0.022973\nerror_10         0.023882  0.006694  6.688770e-04  5  0.037664  0.010100\necmwf_diff_9     0.017084  0.005529  1.150623e-03  5  0.028467  0.005701\nerror_9          0.014618  0.006939  4.618663e-03  5  0.028906  0.000330\ncmc-ens_14       0.011008  0.003074  6.592076e-04  5  0.017337  0.004680\nerror_11         0.007955  0.000899  1.921822e-05  5  0.009805  0.006104\ncmc-ens_13       0.007910  0.002296  7.643031e-04  5  0.012638  0.003182\nmonth            0.007359  0.003553  4.895232e-03  5  0.014674  0.000045\nerror_14         0.007053  0.002057  7.778068e-04  5  0.011288  0.002818\ngfs-ens-bc_13    0.004787  0.007148  1.043242e-01  5  0.019506 -0.009932\ngfs-ens-bc_14    0.004717  0.004445  3.828741e-02  5  0.013870 -0.004436\ncmc-ens_11       0.004413  0.001698  2.180449e-03  5  0.007908  0.000917\nerror_13         0.002737  0.002398  3.157734e-02  5  0.007675 -0.002201\nerror_12         0.001823  0.002219  7.000059e-02  5  0.006392 -0.002745\ncmc-ens_12       0.000622  0.003085  3.376951e-01  5  0.006974 -0.005729\ngfs-ens-bc_12    0.000428  0.003546  4.002175e-01  5  0.007731 -0.006874\ncmc-ens_10      -0.001333  0.001026  9.780221e-01  5  0.000781 -0.003446",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance</th>\n      <th>stddev</th>\n      <th>p_value</th>\n      <th>n</th>\n      <th>p99_high</th>\n      <th>p99_low</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>day_8_error</th>\n      <td>0.793485</td>\n      <td>0.024949</td>\n      <td>1.171358e-07</td>\n      <td>5</td>\n      <td>0.844857</td>\n      <td>0.742114</td>\n    </tr>\n    <tr>\n      <th>gfs-ens-bc_9</th>\n      <td>0.434945</td>\n      <td>0.022716</td>\n      <td>8.896256e-07</td>\n      <td>5</td>\n      <td>0.481718</td>\n      <td>0.388172</td>\n    </tr>\n    <tr>\n      <th>ecmwf_diff_8</th>\n      <td>0.314502</td>\n      <td>0.023413</td>\n      <td>3.658877e-06</td>\n      <td>5</td>\n      <td>0.362711</td>\n      <td>0.266293</td>\n    </tr>\n    <tr>\n      <th>noon</th>\n      <td>0.214596</td>\n      <td>0.020989</td>\n      <td>1.084370e-05</td>\n      <td>5</td>\n      <td>0.257813</td>\n      <td>0.171378</td>\n    </tr>\n    <tr>\n      <th>cmc-ens_9</th>\n      <td>0.110671</td>\n      <td>0.015849</td>\n      <td>4.912572e-05</td>\n      <td>5</td>\n      <td>0.143305</td>\n      <td>0.078037</td>\n    </tr>\n    <tr>\n      <th>gfs-ens-bc_11</th>\n      <td>0.082918</td>\n      <td>0.005148</td>\n      <td>1.773224e-06</td>\n      <td>5</td>\n      <td>0.093517</td>\n      <td>0.072319</td>\n    </tr>\n    <tr>\n      <th>gfs-ens-bc_10</th>\n      <td>0.028948</td>\n      <td>0.002902</td>\n      <td>1.195742e-05</td>\n      <td>5</td>\n      <td>0.034924</td>\n      <td>0.022973</td>\n    </tr>\n    <tr>\n      <th>error_10</th>\n      <td>0.023882</td>\n      <td>0.006694</td>\n      <td>6.688770e-04</td>\n      <td>5</td>\n      <td>0.037664</td>\n      <td>0.010100</td>\n    </tr>\n    <tr>\n      <th>ecmwf_diff_9</th>\n      <td>0.017084</td>\n      <td>0.005529</td>\n      <td>1.150623e-03</td>\n      <td>5</td>\n      <td>0.028467</td>\n      <td>0.005701</td>\n    </tr>\n    <tr>\n      <th>error_9</th>\n      <td>0.014618</td>\n      <td>0.006939</td>\n      <td>4.618663e-03</td>\n      <td>5</td>\n      <td>0.028906</td>\n      <td>0.000330</td>\n    </tr>\n    <tr>\n      <th>cmc-ens_14</th>\n      <td>0.011008</td>\n      <td>0.003074</td>\n      <td>6.592076e-04</td>\n      <td>5</td>\n      <td>0.017337</td>\n      <td>0.004680</td>\n    </tr>\n    <tr>\n      <th>error_11</th>\n      <td>0.007955</td>\n      <td>0.000899</td>\n      <td>1.921822e-05</td>\n      <td>5</td>\n      <td>0.009805</td>\n      <td>0.006104</td>\n    </tr>\n    <tr>\n      <th>cmc-ens_13</th>\n      <td>0.007910</td>\n      <td>0.002296</td>\n      <td>7.643031e-04</td>\n      <td>5</td>\n      <td>0.012638</td>\n      <td>0.003182</td>\n    </tr>\n    <tr>\n      <th>month</th>\n      <td>0.007359</td>\n      <td>0.003553</td>\n      <td>4.895232e-03</td>\n      <td>5</td>\n      <td>0.014674</td>\n      <td>0.000045</td>\n    </tr>\n    <tr>\n      <th>error_14</th>\n      <td>0.007053</td>\n      <td>0.002057</td>\n      <td>7.778068e-04</td>\n      <td>5</td>\n      <td>0.011288</td>\n      <td>0.002818</td>\n    </tr>\n    <tr>\n      <th>gfs-ens-bc_13</th>\n      <td>0.004787</td>\n      <td>0.007148</td>\n      <td>1.043242e-01</td>\n      <td>5</td>\n      <td>0.019506</td>\n      <td>-0.009932</td>\n    </tr>\n    <tr>\n      <th>gfs-ens-bc_14</th>\n      <td>0.004717</td>\n      <td>0.004445</td>\n      <td>3.828741e-02</td>\n      <td>5</td>\n      <td>0.013870</td>\n      <td>-0.004436</td>\n    </tr>\n    <tr>\n      <th>cmc-ens_11</th>\n      <td>0.004413</td>\n      <td>0.001698</td>\n      <td>2.180449e-03</td>\n      <td>5</td>\n      <td>0.007908</td>\n      <td>0.000917</td>\n    </tr>\n    <tr>\n      <th>error_13</th>\n      <td>0.002737</td>\n      <td>0.002398</td>\n      <td>3.157734e-02</td>\n      <td>5</td>\n      <td>0.007675</td>\n      <td>-0.002201</td>\n    </tr>\n    <tr>\n      <th>error_12</th>\n      <td>0.001823</td>\n      <td>0.002219</td>\n      <td>7.000059e-02</td>\n      <td>5</td>\n      <td>0.006392</td>\n      <td>-0.002745</td>\n    </tr>\n    <tr>\n      <th>cmc-ens_12</th>\n      <td>0.000622</td>\n      <td>0.003085</td>\n      <td>3.376951e-01</td>\n      <td>5</td>\n      <td>0.006974</td>\n      <td>-0.005729</td>\n    </tr>\n    <tr>\n      <th>gfs-ens-bc_12</th>\n      <td>0.000428</td>\n      <td>0.003546</td>\n      <td>4.002175e-01</td>\n      <td>5</td>\n      <td>0.007731</td>\n      <td>-0.006874</td>\n    </tr>\n    <tr>\n      <th>cmc-ens_10</th>\n      <td>-0.001333</td>\n      <td>0.001026</td>\n      <td>9.780221e-01</td>\n      <td>5</td>\n      <td>0.000781</td>\n      <td>-0.003446</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T14:03:03.236403Z",
     "end_time": "2023-06-07T14:03:03.756799Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
