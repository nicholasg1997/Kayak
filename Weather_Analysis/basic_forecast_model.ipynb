{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:47:40.717350Z",
     "end_time": "2023-06-06T11:48:05.981383Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "from meteostat import Stations, Daily\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path = \"RawData\"\n",
    "\n",
    "\n",
    "def extract_date_time(filename):\n",
    "    \"\"\"\n",
    "    extract the date and time from the filename\n",
    "    :param filename:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    parts = filename.split('.')\n",
    "    date = parts[1]\n",
    "    time = parts[2]\n",
    "    return date, time\n",
    "\n",
    "\n",
    "def get_date(df, file):\n",
    "    \"\"\"get the date from the dataframe and the time from the filename and combine them into a datetime object\n",
    "    :param df: dataframe containing the date\n",
    "    :param file: filename containing the time\n",
    "    :return: datetime object\n",
    "    \"\"\"\n",
    "    #date_str = df[df.iloc[:, 2] == 1].iloc[0]['Date']\n",
    "    date_str = str(file.split('.')[1])\n",
    "    time_str = str(file.split('.')[2])\n",
    "    #date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    date = datetime.strptime(date_str, '%Y%m%d')\n",
    "    time_value = time(int(time_str), 0)\n",
    "    combined_datetime = datetime.combine(date.date(), time_value)\n",
    "    return combined_datetime\n",
    "\n",
    "\n",
    "degree_days = 'gw_hdd'\n",
    "ecmwf_files = glob.glob(path + f'/ecmwf.*.[01][02].{degree_days}.csv')\n",
    "ecmwf_sorted_files = sorted(ecmwf_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[3:]\n",
    "\n",
    "ecmwf_eps_files = glob.glob(path + f'/ecmwf-eps.*.[01][02].{degree_days}.csv')\n",
    "ecmwf_eps_sorted_files = sorted(ecmwf_eps_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "\n",
    "gfs_ens_bc_files = glob.glob(path + f'/gfs-ens-bc.*.[01][02].{degree_days}.csv')\n",
    "gfs_ens_bc_sorted_files = sorted(gfs_ens_bc_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "\n",
    "cmc_ens_files = glob.glob(path + f'/cmc-ens.*.[01][02].{degree_days}.csv')\n",
    "cmc_ens_sorted_files = sorted(cmc_ens_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "for _ in range(2):\n",
    "    set1 = set((extract_date_time(filename) for filename in ecmwf_sorted_files))\n",
    "    set2 = set((extract_date_time(filename) for filename in ecmwf_eps_sorted_files))\n",
    "\n",
    "    ecmwf_sorted_files = [filename for filename in ecmwf_sorted_files if extract_date_time(filename) in set2]\n",
    "    ecmwf_eps_sorted_files = [filename for filename in ecmwf_eps_sorted_files if extract_date_time(filename) in set1]\n",
    "    cmc_ens_sorted_files = [filename for filename in cmc_ens_sorted_files if extract_date_time(filename) in set1]\n",
    "\n",
    "    master_set = set((extract_date_time(filename) for filename in cmc_ens_sorted_files))\n",
    "    gfs_ens_bc_sorted_files = [filename for filename in gfs_ens_bc_sorted_files if\n",
    "                               extract_date_time(filename) in master_set]\n",
    "\n",
    "    master_set = set((extract_date_time(filename) for filename in gfs_ens_bc_sorted_files))\n",
    "\n",
    "    ecmwf_sorted_files = [filename for filename in ecmwf_sorted_files if extract_date_time(filename) in master_set]\n",
    "    ecmwf_eps_sorted_files = [filename for filename in ecmwf_eps_sorted_files if\n",
    "                              extract_date_time(filename) in master_set]\n",
    "    gfs_ens_bc_sorted_files = [filename for filename in gfs_ens_bc_sorted_files if\n",
    "                               extract_date_time(filename) in master_set]\n",
    "    cmc_ens_sorted_files = [filename for filename in cmc_ens_sorted_files if extract_date_time(filename) in master_set]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:48:05.980674Z",
     "end_time": "2023-06-06T11:48:06.540679Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "ecmwf_eps_change_df = pd.DataFrame(columns=['ecmwf-eps_9', 'ecmwf-eps_10', 'ecmwf-eps_11', 'ecmwf-eps_12',\n",
    "                                  'ecmwf-eps_13', 'ecmwf-eps_14'])\n",
    "\n",
    "for i in range(1, len(ecmwf_eps_sorted_files)):\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i])\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "    date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i])\n",
    "    prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    changes = []\n",
    "    for day in range(8, 14):\n",
    "        changes.append(ecmwf_eps_df.iloc[day - offset]['Value'] - prev_ecmwf_eps_df.iloc[day]['Value'])\n",
    "    new_row = pd.DataFrame([changes], columns=ecmwf_eps_change_df.columns, index=[date])\n",
    "    ecmwf_eps_change_df = pd.concat([ecmwf_eps_change_df, new_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:48:06.548995Z",
     "end_time": "2023-06-06T11:48:15.335289Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "ecmwf_change_df = pd.DataFrame(columns=['ecmwf_diff_8', 'ecmwf_diff_9',])\n",
    "for i in range(1, len(ecmwf_sorted_files)):\n",
    "    ecmwf_df = pd.read_csv(ecmwf_sorted_files[i])\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1]) #one day behind\n",
    "\n",
    "    ecmwf = ecmwf_df.iloc[8]\n",
    "    ecmwf_eps = ecmwf_eps_df.iloc[9]\n",
    "\n",
    "    date = get_date(ecmwf_df, ecmwf_sorted_files[i])\n",
    "    prev_date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    changes = []\n",
    "    for day in range(8,10):\n",
    "        changes.append(ecmwf_df.iloc[day - offset]['Value'] - ecmwf_eps_df.iloc[day]['Value'])\n",
    "    new_row = pd.DataFrame([changes], columns=ecmwf_change_df.columns, index=[date])\n",
    "    ecmwf_change_df = pd.concat([ecmwf_change_df, new_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:48:15.339823Z",
     "end_time": "2023-06-06T11:48:23.205350Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "gfs_ens_bc_change_df = pd.DataFrame(columns=['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12',\n",
    "                                  'gfs-ens-bc_13', 'gfs-ens-bc_14'])\n",
    "\n",
    "for i in range(1, len(gfs_ens_bc_sorted_files)):\n",
    "    gfs_ens_bc_df = pd.read_csv(gfs_ens_bc_sorted_files[i])\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "\n",
    "    date = get_date(gfs_ens_bc_df, gfs_ens_bc_sorted_files[i])\n",
    "    prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    changes = []\n",
    "    for day in range(8, 14):\n",
    "        changes.append(gfs_ens_bc_df.iloc[day - offset]['Value'] - prev_ecmwf_eps_df.iloc[day]['Value'])\n",
    "    new_row = pd.DataFrame([changes], columns=gfs_ens_bc_change_df.columns, index=[date])\n",
    "    gfs_ens_bc_change_df = pd.concat([gfs_ens_bc_change_df, new_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:48:23.210692Z",
     "end_time": "2023-06-06T11:48:33.441615Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "cmc_ens_change_df = pd.DataFrame(columns=['cmc-ens_9', 'cmc-ens_10', 'cmc-ens_11', 'cmc-ens_12',\n",
    "                                  'cmc-ens_13', 'cmc-ens_14'])\n",
    "\n",
    "for i in range(1, len(cmc_ens_sorted_files)):\n",
    "    cmc_ens_df = pd.read_csv(cmc_ens_sorted_files[i])\n",
    "    gfs_ens_bc_df = pd.read_csv(gfs_ens_bc_sorted_files[i])\n",
    "    date = get_date(cmc_ens_df, cmc_ens_sorted_files[i])\n",
    "\n",
    "    changes = []\n",
    "    for day in range(8, 14):\n",
    "        changes.append(cmc_ens_df.iloc[day]['Value'] - gfs_ens_bc_df.iloc[day]['Value'])\n",
    "    new_row = pd.DataFrame([changes], columns=cmc_ens_change_df.columns, index=[date])\n",
    "    cmc_ens_change_df = pd.concat([cmc_ens_change_df, new_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:48:33.445901Z",
     "end_time": "2023-06-06T11:48:41.590440Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "day_8_error = pd.DataFrame(columns=['day_8_error'])\n",
    "for i in range(1, len(ecmwf_eps_sorted_files)):\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i])\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "    date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i])\n",
    "    prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "    day = 7\n",
    "    changes = []\n",
    "    changes.append(ecmwf_eps_df.iloc[day]['Value'] - prev_ecmwf_eps_df.iloc[day + offset]['Value'])\n",
    "    new_row = pd.DataFrame([changes], columns=day_8_error.columns, index=[date])\n",
    "    day_8_error = pd.concat([day_8_error, new_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:48:41.594400Z",
     "end_time": "2023-06-06T11:48:47.666957Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "errors_df = pd.DataFrame(columns=['error_9', 'error_10', 'error_11', 'error_12', 'error_13', 'error_14'])\n",
    "\n",
    "for i in range(2, len(ecmwf_eps_sorted_files)):\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-2])\n",
    "    date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i])\n",
    "    prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    errors = []\n",
    "    for day in range(8, 14):\n",
    "        errors.append(ecmwf_eps_df.iloc[day - offset]['Value'] - prev_ecmwf_eps_df.iloc[day]['Value'])\n",
    "    new_row = pd.DataFrame([errors], columns=errors_df.columns, index=[date])\n",
    "    errors_df = pd.concat([errors_df, new_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:48:47.670896Z",
     "end_time": "2023-06-06T11:48:55.638348Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                     gfs-ens-bc_9  gfs-ens-bc_10  gfs-ens-bc_11  \\\n2018-07-11 00:00:00         0.009          0.006          0.002   \n2018-07-11 12:00:00         0.004          0.001          0.000   \n2018-07-12 00:00:00         0.003          0.002          0.002   \n2018-07-12 12:00:00         0.001          0.002          0.004   \n2018-07-13 00:00:00         0.001          0.002          0.002   \n\n                     gfs-ens-bc_12  gfs-ens-bc_13  gfs-ens-bc_14  cmc-ens_9  \\\n2018-07-11 00:00:00          0.001          0.013          0.013     -0.006   \n2018-07-11 12:00:00          0.005          0.008          0.018     -0.003   \n2018-07-12 00:00:00          0.006          0.009          0.020     -0.004   \n2018-07-12 12:00:00          0.009          0.021          0.015     -0.002   \n2018-07-13 00:00:00          0.007          0.019          0.021     -0.001   \n\n                     cmc-ens_10  cmc-ens_11  cmc-ens_12  ...  error_12  \\\n2018-07-11 00:00:00      -0.003      -0.001      -0.013  ...     0.000   \n2018-07-11 12:00:00      -0.002      -0.001      -0.005  ...    -0.002   \n2018-07-12 00:00:00      -0.002      -0.006      -0.009  ...     0.001   \n2018-07-12 12:00:00      -0.002      -0.004      -0.008  ...     0.001   \n2018-07-13 00:00:00      -0.003      -0.008      -0.022  ...     0.000   \n\n                     error_13  error_14  day_8_error  ecmwf-eps_9  \\\n2018-07-11 00:00:00     0.000     0.000        0.001        0.001   \n2018-07-11 12:00:00     0.002    -0.002        0.005        0.001   \n2018-07-12 00:00:00    -0.003     0.001       -0.001       -0.001   \n2018-07-12 12:00:00    -0.001     0.003        0.003        0.000   \n2018-07-13 00:00:00     0.001     0.004        0.000        0.000   \n\n                     ecmwf-eps_10  ecmwf-eps_11  ecmwf-eps_12  ecmwf-eps_13  \\\n2018-07-11 00:00:00        -0.001         0.000         0.000         0.000   \n2018-07-11 12:00:00         0.000        -0.001        -0.001        -0.001   \n2018-07-12 00:00:00        -0.001         0.000         0.000        -0.001   \n2018-07-12 12:00:00        -0.001         0.001         0.001         0.006   \n2018-07-13 00:00:00        -0.001        -0.001        -0.002         0.000   \n\n                     ecmwf-eps_14  \n2018-07-11 00:00:00         0.000  \n2018-07-11 12:00:00        -0.001  \n2018-07-12 00:00:00         0.001  \n2018-07-12 12:00:00         0.003  \n2018-07-13 00:00:00        -0.001  \n\n[5 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gfs-ens-bc_9</th>\n      <th>gfs-ens-bc_10</th>\n      <th>gfs-ens-bc_11</th>\n      <th>gfs-ens-bc_12</th>\n      <th>gfs-ens-bc_13</th>\n      <th>gfs-ens-bc_14</th>\n      <th>cmc-ens_9</th>\n      <th>cmc-ens_10</th>\n      <th>cmc-ens_11</th>\n      <th>cmc-ens_12</th>\n      <th>...</th>\n      <th>error_12</th>\n      <th>error_13</th>\n      <th>error_14</th>\n      <th>day_8_error</th>\n      <th>ecmwf-eps_9</th>\n      <th>ecmwf-eps_10</th>\n      <th>ecmwf-eps_11</th>\n      <th>ecmwf-eps_12</th>\n      <th>ecmwf-eps_13</th>\n      <th>ecmwf-eps_14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-07-11 00:00:00</th>\n      <td>0.009</td>\n      <td>0.006</td>\n      <td>0.002</td>\n      <td>0.001</td>\n      <td>0.013</td>\n      <td>0.013</td>\n      <td>-0.006</td>\n      <td>-0.003</td>\n      <td>-0.001</td>\n      <td>-0.013</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>-0.001</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2018-07-11 12:00:00</th>\n      <td>0.004</td>\n      <td>0.001</td>\n      <td>0.000</td>\n      <td>0.005</td>\n      <td>0.008</td>\n      <td>0.018</td>\n      <td>-0.003</td>\n      <td>-0.002</td>\n      <td>-0.001</td>\n      <td>-0.005</td>\n      <td>...</td>\n      <td>-0.002</td>\n      <td>0.002</td>\n      <td>-0.002</td>\n      <td>0.005</td>\n      <td>0.001</td>\n      <td>0.000</td>\n      <td>-0.001</td>\n      <td>-0.001</td>\n      <td>-0.001</td>\n      <td>-0.001</td>\n    </tr>\n    <tr>\n      <th>2018-07-12 00:00:00</th>\n      <td>0.003</td>\n      <td>0.002</td>\n      <td>0.002</td>\n      <td>0.006</td>\n      <td>0.009</td>\n      <td>0.020</td>\n      <td>-0.004</td>\n      <td>-0.002</td>\n      <td>-0.006</td>\n      <td>-0.009</td>\n      <td>...</td>\n      <td>0.001</td>\n      <td>-0.003</td>\n      <td>0.001</td>\n      <td>-0.001</td>\n      <td>-0.001</td>\n      <td>-0.001</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>-0.001</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>2018-07-12 12:00:00</th>\n      <td>0.001</td>\n      <td>0.002</td>\n      <td>0.004</td>\n      <td>0.009</td>\n      <td>0.021</td>\n      <td>0.015</td>\n      <td>-0.002</td>\n      <td>-0.002</td>\n      <td>-0.004</td>\n      <td>-0.008</td>\n      <td>...</td>\n      <td>0.001</td>\n      <td>-0.001</td>\n      <td>0.003</td>\n      <td>0.003</td>\n      <td>0.000</td>\n      <td>-0.001</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>0.006</td>\n      <td>0.003</td>\n    </tr>\n    <tr>\n      <th>2018-07-13 00:00:00</th>\n      <td>0.001</td>\n      <td>0.002</td>\n      <td>0.002</td>\n      <td>0.007</td>\n      <td>0.019</td>\n      <td>0.021</td>\n      <td>-0.001</td>\n      <td>-0.003</td>\n      <td>-0.008</td>\n      <td>-0.022</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.001</td>\n      <td>0.004</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>-0.001</td>\n      <td>-0.001</td>\n      <td>-0.002</td>\n      <td>0.000</td>\n      <td>-0.001</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master_df = pd.concat([gfs_ens_bc_change_df, cmc_ens_change_df, ecmwf_change_df, errors_df, day_8_error, ecmwf_eps_change_df], axis=1)\n",
    "master_df.fillna(0, inplace=True)\n",
    "display(master_df[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:48:55.645175Z",
     "end_time": "2023-06-06T11:48:55.662187Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "random forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X = master_df.iloc[:, :-6]\n",
    "y = master_df.iloc[:, -6:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:48:55.664139Z",
     "end_time": "2023-06-06T11:48:55.667857Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:48:55.667563Z",
     "end_time": "2023-06-06T11:48:55.696374Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestRegressor(max_depth=100, n_estimators=1000, random_state=42)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=100, n_estimators=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=100, n_estimators=1000, random_state=42)</pre></div></div></div></div></div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_model = RandomForestRegressor(n_estimators=1000, max_depth=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:48:55.680203Z",
     "end_time": "2023-06-06T11:49:59.598339Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.1854454979319896\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:49:59.601113Z",
     "end_time": "2023-06-06T11:49:59.801538Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "input_features = master_df.iloc[:, :-6].values ** 2\n",
    "target_variables = master_df.iloc[:, -6:].values\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input_features, target_variables, test_size=0.2, shuffle=False)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Scale the input features based on the training data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the validation and test data based on the training data\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert the scaled data to PyTorch tensors\n",
    "\n",
    "X_train_tensor = torch.Tensor(X_train_scaled)\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "X_val_tensor = torch.Tensor(X_val_scaled)\n",
    "y_val_tensor = torch.Tensor(y_val)\n",
    "X_test_tensor = torch.Tensor(X_test_scaled)\n",
    "y_test_tensor = torch.Tensor(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:49:59.805073Z",
     "end_time": "2023-06-06T11:49:59.811015Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.16695826363327243"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#benchmark error\n",
    "total_mse = 0\n",
    "c = 0\n",
    "for i in range(1, len(y_test_tensor)):\n",
    "    #mse = mean_squared_error(y_test_tensor[i], y_test_tensor[i-1])\n",
    "    mse = mean_squared_error(y_test_tensor[i], [0,0,0,0,0,0])\n",
    "    total_mse += mse\n",
    "    c += 1\n",
    "\n",
    "total_mse/c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:49:59.815325Z",
     "end_time": "2023-06-06T11:49:59.897205Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, 64)  # Dense layer with 64 units\n",
    "        self.fc2 = nn.Linear(64, output_size)  # Final output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = F.relu(out)  # Apply ReLU activation between LSTM and first dense layer\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = F.relu(out)  # Apply ReLU activation to the output of the first dense layer\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:49:59.896628Z",
     "end_time": "2023-06-06T11:49:59.904045Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "input_size = X_train_tensor.shape[1]\n",
    "output_size = y_train_tensor.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "dropout = 0.3\n",
    "lr = 0.01"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:49:59.906461Z",
     "end_time": "2023-06-06T11:49:59.908483Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n"
     ]
    }
   ],
   "source": [
    "model = RNN(input_size, hidden_size, output_size, num_layers, dropout)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:49:59.912922Z",
     "end_time": "2023-06-06T11:49:59.933003Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 0.1871006441203223\n",
      "Epoch [1/100], Validation Loss: 0.18947593587361003\n",
      "Epoch [2/100], Training Loss: 0.18674874982800432\n",
      "Epoch [2/100], Validation Loss: 0.18964706866258407\n",
      "Epoch [3/100], Training Loss: 0.18637060701821423\n",
      "Epoch [3/100], Validation Loss: 0.18965568341450365\n",
      "Epoch [4/100], Training Loss: 0.1867384647969386\n",
      "Epoch [4/100], Validation Loss: 0.18956347593957024\n",
      "Epoch [5/100], Training Loss: 0.1867511325163515\n",
      "Epoch [5/100], Validation Loss: 0.18975623835830369\n",
      "Epoch [6/100], Training Loss: 0.1862885603395183\n",
      "Epoch [6/100], Validation Loss: 0.1896915113302154\n",
      "Epoch [7/100], Training Loss: 0.18674163050103712\n",
      "Epoch [7/100], Validation Loss: 0.18961945383861714\n",
      "Epoch [8/100], Training Loss: 0.18652984291430924\n",
      "Epoch [8/100], Validation Loss: 0.1896238616482118\n",
      "Epoch [9/100], Training Loss: 0.18669914157364173\n",
      "Epoch [9/100], Validation Loss: 0.18961980781134993\n",
      "Epoch [10/100], Training Loss: 0.18725305032235326\n",
      "Epoch [10/100], Validation Loss: 0.1895622082441859\n",
      "Epoch [11/100], Training Loss: 0.18627125066354566\n",
      "Epoch [11/100], Validation Loss: 0.18961387820303766\n",
      "Epoch [12/100], Training Loss: 0.18695623990707505\n",
      "Epoch [12/100], Validation Loss: 0.18961403390221512\n",
      "Epoch [13/100], Training Loss: 0.1863107858356153\n",
      "Epoch [13/100], Validation Loss: 0.18967150212794998\n",
      "Epoch [14/100], Training Loss: 0.18697786650234208\n",
      "Epoch [14/100], Validation Loss: 0.18961381662670046\n",
      "Epoch [15/100], Training Loss: 0.18648624529115462\n",
      "Epoch [15/100], Validation Loss: 0.18963135977152096\n",
      "Epoch [16/100], Training Loss: 0.18685167760232407\n",
      "Epoch [16/100], Validation Loss: 0.18965945302351517\n",
      "Epoch [17/100], Training Loss: 0.186298495338364\n",
      "Epoch [17/100], Validation Loss: 0.18964137677599047\n",
      "Epoch [18/100], Training Loss: 0.18648674425205156\n",
      "Epoch [18/100], Validation Loss: 0.1896831354911664\n",
      "Epoch [19/100], Training Loss: 0.1865463730835939\n",
      "Epoch [19/100], Validation Loss: 0.18963629217044944\n",
      "Epoch [20/100], Training Loss: 0.1863739404369894\n",
      "Epoch [20/100], Validation Loss: 0.18951775111989783\n",
      "Epoch [21/100], Training Loss: 0.18659987620704924\n",
      "Epoch [21/100], Validation Loss: 0.18974412522865222\n",
      "Epoch [22/100], Training Loss: 0.18647560060407664\n",
      "Epoch [22/100], Validation Loss: 0.18961354993856563\n",
      "Epoch [23/100], Training Loss: 0.18628763254431713\n",
      "Epoch [23/100], Validation Loss: 0.18953590339562723\n",
      "Epoch [24/100], Training Loss: 0.18683534185234102\n",
      "Epoch [24/100], Validation Loss: 0.18961587971966642\n",
      "Epoch [25/100], Training Loss: 0.18670023338421504\n",
      "Epoch [25/100], Validation Loss: 0.1896162491723214\n",
      "Epoch [26/100], Training Loss: 0.1867726414907384\n",
      "Epoch [26/100], Validation Loss: 0.18963703859523132\n",
      "Epoch [27/100], Training Loss: 0.18641045130812448\n",
      "Epoch [27/100], Validation Loss: 0.18965357157004287\n",
      "Epoch [28/100], Training Loss: 0.18650022421556978\n",
      "Epoch [28/100], Validation Loss: 0.189609835565835\n",
      "Epoch [29/100], Training Loss: 0.18683834853506995\n",
      "Epoch [29/100], Validation Loss: 0.18962561185389612\n",
      "Epoch [30/100], Training Loss: 0.18653167132465828\n",
      "Epoch [30/100], Validation Loss: 0.18966021279621892\n",
      "Epoch [31/100], Training Loss: 0.18678745257619223\n",
      "Epoch [31/100], Validation Loss: 0.18961309871114673\n",
      "Epoch [32/100], Training Loss: 0.18666735509950108\n",
      "Epoch [32/100], Validation Loss: 0.1897167811424629\n",
      "Epoch [33/100], Training Loss: 0.1866255872831534\n",
      "Epoch [33/100], Validation Loss: 0.18961921017277003\n",
      "Epoch [34/100], Training Loss: 0.18655479621397797\n",
      "Epoch [34/100], Validation Loss: 0.18961416295870412\n",
      "Epoch [35/100], Training Loss: 0.18659707623286015\n",
      "Epoch [35/100], Validation Loss: 0.18956724985263304\n",
      "Epoch [36/100], Training Loss: 0.18647452557889466\n",
      "Epoch [36/100], Validation Loss: 0.18955283115116273\n",
      "Epoch [37/100], Training Loss: 0.18666138564674087\n",
      "Epoch [37/100], Validation Loss: 0.18962373382597783\n",
      "Epoch [38/100], Training Loss: 0.1871930247930417\n",
      "Epoch [38/100], Validation Loss: 0.18979230238181358\n",
      "Epoch [39/100], Training Loss: 0.18661872776233498\n",
      "Epoch [39/100], Validation Loss: 0.18934421751247787\n",
      "Epoch [40/100], Training Loss: 0.18668565948838883\n",
      "Epoch [40/100], Validation Loss: 0.1896537808183211\n",
      "Epoch [41/100], Training Loss: 0.18660837911247938\n",
      "Epoch [41/100], Validation Loss: 0.1896297652008594\n",
      "Epoch [42/100], Training Loss: 0.18661409013077881\n",
      "Epoch [42/100], Validation Loss: 0.18970564809988025\n",
      "Epoch [43/100], Training Loss: 0.1867989178210389\n",
      "Epoch [43/100], Validation Loss: 0.18978193267965376\n",
      "Epoch [44/100], Training Loss: 0.1867823212994832\n",
      "Epoch [44/100], Validation Loss: 0.18961791451002563\n",
      "Epoch [45/100], Training Loss: 0.18634454199206751\n",
      "Epoch [45/100], Validation Loss: 0.18959719680105908\n",
      "Epoch [46/100], Training Loss: 0.18678374683969426\n",
      "Epoch [46/100], Validation Loss: 0.18955996338016806\n",
      "Epoch [47/100], Training Loss: 0.1865276274737217\n",
      "Epoch [47/100], Validation Loss: 0.1895994591972665\n",
      "Epoch [48/100], Training Loss: 0.18718731673673908\n",
      "Epoch [48/100], Validation Loss: 0.18961885787984928\n",
      "Epoch [49/100], Training Loss: 0.18634395297596779\n",
      "Epoch [49/100], Validation Loss: 0.18962186313822452\n",
      "Epoch [50/100], Training Loss: 0.1870049601554218\n",
      "Epoch [50/100], Validation Loss: 0.18961744190860627\n",
      "Epoch [51/100], Training Loss: 0.18632549459015127\n",
      "Epoch [51/100], Validation Loss: 0.1896214133379985\n",
      "Epoch [52/100], Training Loss: 0.18669544969261206\n",
      "Epoch [52/100], Validation Loss: 0.18978718508882902\n",
      "Epoch [53/100], Training Loss: 0.1864191375492521\n",
      "Epoch [53/100], Validation Loss: 0.18963160455768135\n",
      "Epoch [54/100], Training Loss: 0.1864357250714626\n",
      "Epoch [54/100], Validation Loss: 0.18967184394522854\n",
      "Epoch [55/100], Training Loss: 0.18651028604853453\n",
      "Epoch [55/100], Validation Loss: 0.18964440736996058\n",
      "Epoch [56/100], Training Loss: 0.18656960887935084\n",
      "Epoch [56/100], Validation Loss: 0.18960747915999224\n",
      "Epoch [57/100], Training Loss: 0.1865341424761797\n",
      "Epoch [57/100], Validation Loss: 0.18959665585558308\n",
      "Epoch [58/100], Training Loss: 0.18654335083795023\n",
      "Epoch [58/100], Validation Loss: 0.1896284300592689\n",
      "Epoch [59/100], Training Loss: 0.18683545696332904\n",
      "Epoch [59/100], Validation Loss: 0.18959930135882594\n",
      "Epoch [60/100], Training Loss: 0.18648974710977764\n",
      "Epoch [60/100], Validation Loss: 0.18949002727556083\n",
      "Epoch [61/100], Training Loss: 0.18690353584327146\n",
      "Epoch [61/100], Validation Loss: 0.18961834752828827\n",
      "Epoch [62/100], Training Loss: 0.18648121905449583\n",
      "Epoch [62/100], Validation Loss: 0.18961523208102155\n",
      "Epoch [63/100], Training Loss: 0.18710182500148786\n",
      "Epoch [63/100], Validation Loss: 0.1897704332568965\n",
      "Epoch [64/100], Training Loss: 0.18639201328362523\n",
      "Epoch [64/100], Validation Loss: 0.18954988393708802\n",
      "Epoch [65/100], Training Loss: 0.1867760188549896\n",
      "Epoch [65/100], Validation Loss: 0.1896144481702429\n",
      "Epoch [66/100], Training Loss: 0.18650706519711802\n",
      "Epoch [66/100], Validation Loss: 0.18956578795912432\n",
      "Epoch [67/100], Training Loss: 0.1869592662532054\n",
      "Epoch [67/100], Validation Loss: 0.18970051533076282\n",
      "Epoch [68/100], Training Loss: 0.18630475676221886\n",
      "Epoch [68/100], Validation Loss: 0.18955543348905682\n",
      "Epoch [69/100], Training Loss: 0.18690020961530213\n",
      "Epoch [69/100], Validation Loss: 0.18970194432110177\n",
      "Epoch [70/100], Training Loss: 0.1869697193755649\n",
      "Epoch [70/100], Validation Loss: 0.18962572583223267\n",
      "Epoch [71/100], Training Loss: 0.18671324060317837\n",
      "Epoch [71/100], Validation Loss: 0.18962656500650138\n",
      "Epoch [72/100], Training Loss: 0.18655972899512932\n",
      "Epoch [72/100], Validation Loss: 0.18960910248913285\n",
      "Epoch [73/100], Training Loss: 0.1869575449233399\n",
      "Epoch [73/100], Validation Loss: 0.18961946250287484\n",
      "Epoch [74/100], Training Loss: 0.18636264261605917\n",
      "Epoch [74/100], Validation Loss: 0.1896238830103181\n",
      "Epoch [75/100], Training Loss: 0.18650508388344036\n",
      "Epoch [75/100], Validation Loss: 0.18956170209310233\n",
      "Epoch [76/100], Training Loss: 0.18678494954007613\n",
      "Epoch [76/100], Validation Loss: 0.18973379654284175\n",
      "Epoch [77/100], Training Loss: 0.18664181761459153\n",
      "Epoch [77/100], Validation Loss: 0.18955239324924572\n",
      "Epoch [78/100], Training Loss: 0.1864185551046769\n",
      "Epoch [78/100], Validation Loss: 0.18962735438795808\n",
      "Epoch [79/100], Training Loss: 0.18668269288371528\n",
      "Epoch [79/100], Validation Loss: 0.18963906105725006\n",
      "Epoch [80/100], Training Loss: 0.1866239915847757\n",
      "Epoch [80/100], Validation Loss: 0.18964554607537895\n",
      "Epoch [81/100], Training Loss: 0.18665614269500236\n",
      "Epoch [81/100], Validation Loss: 0.18967874541390936\n",
      "Epoch [82/100], Training Loss: 0.1863429260657285\n",
      "Epoch [82/100], Validation Loss: 0.18964064790744958\n",
      "Epoch [83/100], Training Loss: 0.18675508112212363\n",
      "Epoch [83/100], Validation Loss: 0.18958964916255586\n",
      "Epoch [84/100], Training Loss: 0.18659306201049097\n",
      "Epoch [84/100], Validation Loss: 0.18962705013767234\n",
      "Epoch [85/100], Training Loss: 0.186475270827116\n",
      "Epoch [85/100], Validation Loss: 0.18974559044052391\n",
      "Epoch [86/100], Training Loss: 0.1870327284441783\n",
      "Epoch [86/100], Validation Loss: 0.18961799264949483\n",
      "Epoch [87/100], Training Loss: 0.18696211129490123\n",
      "Epoch [87/100], Validation Loss: 0.1896314908182278\n",
      "Epoch [88/100], Training Loss: 0.1862542670926342\n",
      "Epoch [88/100], Validation Loss: 0.18967360799017893\n",
      "Epoch [89/100], Training Loss: 0.1867807350877574\n",
      "Epoch [89/100], Validation Loss: 0.18965661303500417\n",
      "Epoch [90/100], Training Loss: 0.18661991743317588\n",
      "Epoch [90/100], Validation Loss: 0.18969268658609764\n",
      "Epoch [91/100], Training Loss: 0.18733911273621023\n",
      "Epoch [91/100], Validation Loss: 0.18961489128237707\n",
      "Epoch [92/100], Training Loss: 0.1862680770119532\n",
      "Epoch [92/100], Validation Loss: 0.18956421697267017\n",
      "Epoch [93/100], Training Loss: 0.1870479433306383\n",
      "Epoch [93/100], Validation Loss: 0.1894352483660173\n",
      "Epoch [94/100], Training Loss: 0.1862989099773983\n",
      "Epoch [94/100], Validation Loss: 0.18961888433712581\n",
      "Epoch [95/100], Training Loss: 0.18642369190942498\n",
      "Epoch [95/100], Validation Loss: 0.18972968542690483\n",
      "Epoch [96/100], Training Loss: 0.18663871063245394\n",
      "Epoch [96/100], Validation Loss: 0.1895704537596504\n",
      "Epoch [97/100], Training Loss: 0.18679453062599224\n",
      "Epoch [97/100], Validation Loss: 0.18962824066053988\n",
      "Epoch [98/100], Training Loss: 0.18669084968199665\n",
      "Epoch [98/100], Validation Loss: 0.18961609666582885\n",
      "Epoch [99/100], Training Loss: 0.18647073577340167\n",
      "Epoch [99/100], Validation Loss: 0.1896213006599664\n",
      "Epoch [100/100], Training Loss: 0.1865781368706377\n",
      "Epoch [100/100], Validation Loss: 0.18964426947916962\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "sequence_length = 5  # Number of previous days to consider\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    # Loop through each sequence in the training data\n",
    "    for i in range(sequence_length, X_train_tensor.shape[0]):\n",
    "        # Extract the current sequence and target\n",
    "        input_seq = X_train_tensor[i - sequence_length:i].view(1, sequence_length, -1)\n",
    "        target_seq = y_train_tensor[i]\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output, target_seq.unsqueeze(0))\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / (X_train_tensor.shape[0] - sequence_length)\n",
    "    train_losses.append(average_loss)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {average_loss}')\n",
    "\n",
    "    # Validation stage\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "\n",
    "        for i in range(sequence_length, X_val_tensor.shape[0]):\n",
    "            input_seq = X_val_tensor[i - sequence_length:i].view(1, sequence_length, -1)\n",
    "            target_seq = y_val_tensor[i]\n",
    "\n",
    "            output = model(input_seq)\n",
    "            val_loss = criterion(output, target_seq.unsqueeze(0))\n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "        average_val_loss = total_val_loss / (X_val_tensor.shape[0] - sequence_length)\n",
    "        val_losses.append(average_val_loss)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {average_val_loss}')\n",
    "\n",
    "        # Check if current model is the best based on validation loss\n",
    "        if average_val_loss < best_loss:\n",
    "            best_loss = average_val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "# After training, use the best model for testing\n",
    "model = best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:50:07.386236Z",
     "end_time": "2023-06-01T12:57:09.192598Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(train_losses, label='Training Loss')\n",
    "    ax.plot(val_losses, label='Validation Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "plot_losses(train_losses, val_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:57:09.219917Z",
     "end_time": "2023-06-01T12:57:09.330564Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.16782047505148642\n",
      "Mean Squared Error (MSE): 0.16782047588214263\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(sequence_length, X_test_tensor.shape[0]):\n",
    "        input_seq = X_test_tensor[i - sequence_length:i].view(1, sequence_length, -1)\n",
    "        target_seq = y_test_tensor[i]\n",
    "\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output, target_seq.unsqueeze(0))\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Extract the scalar value from the tensor and append it to predictions\n",
    "        predictions.append(output.squeeze().tolist())\n",
    "\n",
    "    average_test_loss = test_loss / (X_test_tensor.shape[0] - sequence_length)\n",
    "    print(f'Test Loss: {average_test_loss}')\n",
    "\n",
    "    # Convert the predictions and target values to numpy arrays\n",
    "    predictions = np.array(predictions)\n",
    "    targets = y_test_tensor[sequence_length:].numpy()\n",
    "\n",
    "    # Evaluate the performance using appropriate metrics\n",
    "    # For example, calculate mean squared error (MSE)\n",
    "    mse = mean_squared_error(targets, predictions)\n",
    "    print(f'Mean Squared Error (MSE): {mse}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:57:09.332633Z",
     "end_time": "2023-06-01T12:57:09.760812Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def prediction(input):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_seq = torch.tensor(input).view(1, sequence_length, -1)\n",
    "        output = model(input_seq)\n",
    "        return output.squeeze().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:57:09.763079Z",
     "end_time": "2023-06-01T12:57:09.765094Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "pred = prediction(X_test_tensor[-5:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:57:09.766375Z",
     "end_time": "2023-06-01T12:57:09.769971Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "[-0.00606852862983942,\n -0.0033341646194458008,\n -0.004950466100126505,\n 0.0020900126546621323,\n -0.000896872952580452,\n 0.00398428738117218]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:57:09.771177Z",
     "end_time": "2023-06-01T12:57:09.774145Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.0000, -0.1690, -0.2710,  0.0250, -0.0080, -0.0780])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_tensor[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:57:09.775978Z",
     "end_time": "2023-06-01T12:57:09.796432Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Autogloun"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:50:44.601069Z",
     "end_time": "2023-06-06T11:50:45.027717Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train_len = 0.8\n",
    "train_data = TabularDataset(master_df[:int(len(master_df)*train_len)])\n",
    "test_data = TabularDataset(master_df[int(len(master_df)*train_len):])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:52:42.665982Z",
     "end_time": "2023-06-06T11:52:42.668971Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "labels = ['ecmwf-eps_9', 'ecmwf-eps_10', 'ecmwf-eps_11', 'ecmwf-eps_12', 'ecmwf-eps_13',\n",
    "          'ecmwf-eps_14']\n",
    "save_path = 'models'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:56:08.028838Z",
     "end_time": "2023-06-06T11:56:08.034349Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                     gfs-ens-bc_9  gfs-ens-bc_10  gfs-ens-bc_11  \\\n2018-07-11 00:00:00         0.009          0.006          0.002   \n2018-07-11 12:00:00         0.004          0.001          0.000   \n2018-07-12 00:00:00         0.003          0.002          0.002   \n2018-07-12 12:00:00         0.001          0.002          0.004   \n2018-07-13 00:00:00         0.001          0.002          0.002   \n\n                     gfs-ens-bc_12  gfs-ens-bc_13  gfs-ens-bc_14  cmc-ens_9  \\\n2018-07-11 00:00:00          0.001          0.013          0.013     -0.006   \n2018-07-11 12:00:00          0.005          0.008          0.018     -0.003   \n2018-07-12 00:00:00          0.006          0.009          0.020     -0.004   \n2018-07-12 12:00:00          0.009          0.021          0.015     -0.002   \n2018-07-13 00:00:00          0.007          0.019          0.021     -0.001   \n\n                     cmc-ens_10  cmc-ens_11  cmc-ens_12  ...  error_12  \\\n2018-07-11 00:00:00      -0.003      -0.001      -0.013  ...     0.000   \n2018-07-11 12:00:00      -0.002      -0.001      -0.005  ...    -0.002   \n2018-07-12 00:00:00      -0.002      -0.006      -0.009  ...     0.001   \n2018-07-12 12:00:00      -0.002      -0.004      -0.008  ...     0.001   \n2018-07-13 00:00:00      -0.003      -0.008      -0.022  ...     0.000   \n\n                     error_13  error_14  day_8_error  ecmwf-eps_9  \\\n2018-07-11 00:00:00     0.000     0.000        0.001        0.001   \n2018-07-11 12:00:00     0.002    -0.002        0.005        0.001   \n2018-07-12 00:00:00    -0.003     0.001       -0.001       -0.001   \n2018-07-12 12:00:00    -0.001     0.003        0.003        0.000   \n2018-07-13 00:00:00     0.001     0.004        0.000        0.000   \n\n                     ecmwf-eps_10  ecmwf-eps_11  ecmwf-eps_12  ecmwf-eps_13  \\\n2018-07-11 00:00:00        -0.001         0.000         0.000         0.000   \n2018-07-11 12:00:00         0.000        -0.001        -0.001        -0.001   \n2018-07-12 00:00:00        -0.001         0.000         0.000        -0.001   \n2018-07-12 12:00:00        -0.001         0.001         0.001         0.006   \n2018-07-13 00:00:00        -0.001        -0.001        -0.002         0.000   \n\n                     ecmwf-eps_14  \n2018-07-11 00:00:00         0.000  \n2018-07-11 12:00:00        -0.001  \n2018-07-12 00:00:00         0.001  \n2018-07-12 12:00:00         0.003  \n2018-07-13 00:00:00        -0.001  \n\n[5 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gfs-ens-bc_9</th>\n      <th>gfs-ens-bc_10</th>\n      <th>gfs-ens-bc_11</th>\n      <th>gfs-ens-bc_12</th>\n      <th>gfs-ens-bc_13</th>\n      <th>gfs-ens-bc_14</th>\n      <th>cmc-ens_9</th>\n      <th>cmc-ens_10</th>\n      <th>cmc-ens_11</th>\n      <th>cmc-ens_12</th>\n      <th>...</th>\n      <th>error_12</th>\n      <th>error_13</th>\n      <th>error_14</th>\n      <th>day_8_error</th>\n      <th>ecmwf-eps_9</th>\n      <th>ecmwf-eps_10</th>\n      <th>ecmwf-eps_11</th>\n      <th>ecmwf-eps_12</th>\n      <th>ecmwf-eps_13</th>\n      <th>ecmwf-eps_14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-07-11 00:00:00</th>\n      <td>0.009</td>\n      <td>0.006</td>\n      <td>0.002</td>\n      <td>0.001</td>\n      <td>0.013</td>\n      <td>0.013</td>\n      <td>-0.006</td>\n      <td>-0.003</td>\n      <td>-0.001</td>\n      <td>-0.013</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>-0.001</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2018-07-11 12:00:00</th>\n      <td>0.004</td>\n      <td>0.001</td>\n      <td>0.000</td>\n      <td>0.005</td>\n      <td>0.008</td>\n      <td>0.018</td>\n      <td>-0.003</td>\n      <td>-0.002</td>\n      <td>-0.001</td>\n      <td>-0.005</td>\n      <td>...</td>\n      <td>-0.002</td>\n      <td>0.002</td>\n      <td>-0.002</td>\n      <td>0.005</td>\n      <td>0.001</td>\n      <td>0.000</td>\n      <td>-0.001</td>\n      <td>-0.001</td>\n      <td>-0.001</td>\n      <td>-0.001</td>\n    </tr>\n    <tr>\n      <th>2018-07-12 00:00:00</th>\n      <td>0.003</td>\n      <td>0.002</td>\n      <td>0.002</td>\n      <td>0.006</td>\n      <td>0.009</td>\n      <td>0.020</td>\n      <td>-0.004</td>\n      <td>-0.002</td>\n      <td>-0.006</td>\n      <td>-0.009</td>\n      <td>...</td>\n      <td>0.001</td>\n      <td>-0.003</td>\n      <td>0.001</td>\n      <td>-0.001</td>\n      <td>-0.001</td>\n      <td>-0.001</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>-0.001</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>2018-07-12 12:00:00</th>\n      <td>0.001</td>\n      <td>0.002</td>\n      <td>0.004</td>\n      <td>0.009</td>\n      <td>0.021</td>\n      <td>0.015</td>\n      <td>-0.002</td>\n      <td>-0.002</td>\n      <td>-0.004</td>\n      <td>-0.008</td>\n      <td>...</td>\n      <td>0.001</td>\n      <td>-0.001</td>\n      <td>0.003</td>\n      <td>0.003</td>\n      <td>0.000</td>\n      <td>-0.001</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>0.006</td>\n      <td>0.003</td>\n    </tr>\n    <tr>\n      <th>2018-07-13 00:00:00</th>\n      <td>0.001</td>\n      <td>0.002</td>\n      <td>0.002</td>\n      <td>0.007</td>\n      <td>0.019</td>\n      <td>0.021</td>\n      <td>-0.001</td>\n      <td>-0.003</td>\n      <td>-0.008</td>\n      <td>-0.022</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.001</td>\n      <td>0.004</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>-0.001</td>\n      <td>-0.001</td>\n      <td>-0.002</td>\n      <td>0.000</td>\n      <td>-0.001</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:53:14.959857Z",
     "end_time": "2023-06-06T11:53:14.982874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class MultilabelPredictor():\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T11:55:18.285649Z",
     "end_time": "2023-06-06T11:55:18.317263Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/Predictor_ecmwf-eps_9\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/Predictor_ecmwf-eps_10\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/Predictor_ecmwf-eps_11\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/Predictor_ecmwf-eps_12\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/Predictor_ecmwf-eps_13\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/Predictor_ecmwf-eps_14\"\n"
     ]
    }
   ],
   "source": [
    "multi_predictor = MultilabelPredictor(labels=labels, path=save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T12:15:52.271034Z",
     "end_time": "2023-06-06T12:15:52.279753Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/Predictor_ecmwf-eps_9/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2786\n",
      "Train Data Columns: 21\n",
      "Label Column: ecmwf-eps_9\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.9200000000000017, -4.757999999999999, -0.02286, 0.21071)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1433.81 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.47 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 21 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 21 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t21 features in original data used to generate 21 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.47 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-0.2083\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-0.2083\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tWill use sequential fold fitting strategy because Darwin OS does not yet support parallel folding.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ecmwf-eps_9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-0.12\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.78s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1221\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.74s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-0.1187\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 8: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "\t-0.0972\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.46s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1284\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.59s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1239\t = Validation score   (-root_mean_squared_error)\n",
      "\t46.16s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.0958\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-0.1204\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.28s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1204\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.68s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-0.1187\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 7: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "\t-0.11\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.9s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1232\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.41s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1194\t = Validation score   (-root_mean_squared_error)\n",
      "\t41.65s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-0.1099\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 165.7s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/Predictor_ecmwf-eps_9/\")\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/Predictor_ecmwf-eps_10/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2786\n",
      "Train Data Columns: 22\n",
      "Label Column: ecmwf-eps_10\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2.093, -2.3280000000000003, -0.02034, 0.22917)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1397.2 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 22 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 22 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t22 features in original data used to generate 22 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-0.2269\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-0.2267\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ecmwf-eps_10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-0.1204\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.54s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1161\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-0.1202\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1115\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.68s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1204\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.25s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.115\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.17s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1091\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-0.1149\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.84s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1142\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.64s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-0.1137\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1135\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.93s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1188\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.62s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.1138\t = Validation score   (-root_mean_squared_error)\n",
      "\t23.96s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-0.1099\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 149.13s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/Predictor_ecmwf-eps_10/\")\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/Predictor_ecmwf-eps_11/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2786\n",
      "Train Data Columns: 23\n",
      "Label Column: ecmwf-eps_11\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1.940999999999999, -1.3810000000000002, -0.02038, 0.29086)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1393.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.51 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 23 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 23 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t23 features in original data used to generate 23 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.51 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-0.2904\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-0.2904\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ecmwf-eps_11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-0.2349\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.12s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.232\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.88s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-0.2336\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 7: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 6: early stopping\n",
      "\t-0.2301\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.04s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.2378\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.08s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.2259\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.223\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-0.2332\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.85s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.2282\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.52s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-0.23\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 7: early stopping\n",
      "\t-0.2312\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.79s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.2359\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.65s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.2269\t = Validation score   (-root_mean_squared_error)\n",
      "\t23.42s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-0.224\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 132.7s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/Predictor_ecmwf-eps_11/\")\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/Predictor_ecmwf-eps_12/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2786\n",
      "Train Data Columns: 24\n",
      "Label Column: ecmwf-eps_12\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2.5060000000000002, -2.542, -0.02672, 0.3959)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1379.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.54 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 24 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 24 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t24 features in original data used to generate 24 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.54 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-0.3962\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-0.3971\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ecmwf-eps_12 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-0.322\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.42s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.3174\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-0.3233\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 9: early stopping\n",
      "No improvement since epoch 8: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "\t-0.3194\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.68s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.3262\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.93s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.3093\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.64s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.3067\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-0.3171\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.12s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.3138\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.58s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-0.3142\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 6: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 7: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "\t-0.3185\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.91s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.3231\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.25s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.3119\t = Validation score   (-root_mean_squared_error)\n",
      "\t23.6s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-0.3096\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 127.01s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/Predictor_ecmwf-eps_12/\")\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/Predictor_ecmwf-eps_13/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2786\n",
      "Train Data Columns: 25\n",
      "Label Column: ecmwf-eps_13\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (3.385, -5.759999999999998, -0.01978, 0.54711)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1384.42 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 25 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 25 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t25 features in original data used to generate 25 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.56 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-0.5447\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ecmwf-eps_13 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5453\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-0.4387\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.12s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.4218\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.26s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-0.4303\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 8: early stopping\n",
      "No improvement since epoch 7: early stopping\n",
      "No improvement since epoch 7: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "\t-0.4155\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.94s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.4354\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.73s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.4113\t = Validation score   (-root_mean_squared_error)\n",
      "\t28.06s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.4022\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-0.4145\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.83s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.4116\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.41s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-0.414\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 6: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 0: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "\t-0.4129\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.17s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.4255\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.14s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.4058\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.61s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-0.3988\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 150.09s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/Predictor_ecmwf-eps_13/\")\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/Predictor_ecmwf-eps_14/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    2786\n",
      "Train Data Columns: 26\n",
      "Label Column: ecmwf-eps_14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (6.4190000000000005, -9.940999999999995, -0.00928, 0.68805)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1360.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.58 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 26 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 26 | ['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12', 'gfs-ens-bc_13', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t26 features in original data used to generate 26 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.58 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-0.6693\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-0.6692\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ecmwf-eps_14 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-0.5127\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.3s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.4983\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.47s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-0.5095\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "\t-0.4732\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.6s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.5378\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.11s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.476\t = Validation score   (-root_mean_squared_error)\n",
      "\t36.4s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.4605\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-0.4911\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.27s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.493\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.68s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-0.485\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 7: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 6: early stopping\n",
      "\t-0.4899\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.78s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.5079\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.91s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-0.485\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.19s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-0.4735\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 152.43s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/Predictor_ecmwf-eps_14/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('models/')\n"
     ]
    }
   ],
   "source": [
    "multi_predictor.fit(train_data, presets='best_quality')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T12:16:10.923596Z",
     "end_time": "2023-06-06T12:30:48.077668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "                     gfs-ens-bc_9  gfs-ens-bc_10  gfs-ens-bc_11  \\\n2022-06-03 00:00:00        -0.056          0.284          0.235   \n2022-06-03 12:00:00         0.245          0.149          0.015   \n2022-06-04 00:00:00         0.091          0.101         -0.160   \n2022-06-04 12:00:00         0.102         -0.112         -0.176   \n2022-06-05 00:00:00         0.016         -0.119         -0.257   \n\n                     gfs-ens-bc_12  gfs-ens-bc_13  gfs-ens-bc_14  cmc-ens_9  \\\n2022-06-03 00:00:00         -0.012         -0.186         -0.254     -0.062   \n2022-06-03 12:00:00         -0.177         -0.229         -0.307      0.023   \n2022-06-04 00:00:00         -0.319         -0.295         -0.112     -0.053   \n2022-06-04 12:00:00         -0.194         -0.116         -0.056     -0.052   \n2022-06-05 00:00:00         -0.154         -0.074          0.054      0.053   \n\n                     cmc-ens_10  cmc-ens_11  cmc-ens_12  ...  cmc-ens_14  \\\n2022-06-03 00:00:00      -0.088      -0.044       0.043  ...       0.115   \n2022-06-03 12:00:00      -0.067      -0.048       0.265  ...       0.162   \n2022-06-04 00:00:00       0.052       0.277       0.186  ...      -0.024   \n2022-06-04 12:00:00       0.000       0.228       0.071  ...      -0.171   \n2022-06-05 00:00:00       0.370       0.110      -0.109  ...       0.240   \n\n                     ecmwf_diff_8  ecmwf_diff_9  error_9  error_10  error_11  \\\n2022-06-03 00:00:00        -0.089        -0.174   -0.140    -0.468     0.275   \n2022-06-03 12:00:00        -0.023        -0.057    0.297    -0.509     0.013   \n2022-06-04 00:00:00        -0.017        -0.042   -0.233     0.392    -0.141   \n2022-06-04 12:00:00         0.030        -0.081   -0.512     0.007    -0.027   \n2022-06-05 00:00:00        -0.118        -0.117    0.628     0.018    -0.096   \n\n                     error_12  error_13  error_14  day_8_error  \n2022-06-03 00:00:00    -0.221    -0.289     0.201       -0.094  \n2022-06-03 12:00:00     0.016    -0.341    -0.200        0.158  \n2022-06-04 00:00:00    -0.121     0.137     0.011       -0.031  \n2022-06-04 12:00:00    -0.326    -0.303    -0.023        0.147  \n2022-06-05 00:00:00     0.174     0.147    -0.022       -0.065  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gfs-ens-bc_9</th>\n      <th>gfs-ens-bc_10</th>\n      <th>gfs-ens-bc_11</th>\n      <th>gfs-ens-bc_12</th>\n      <th>gfs-ens-bc_13</th>\n      <th>gfs-ens-bc_14</th>\n      <th>cmc-ens_9</th>\n      <th>cmc-ens_10</th>\n      <th>cmc-ens_11</th>\n      <th>cmc-ens_12</th>\n      <th>...</th>\n      <th>cmc-ens_14</th>\n      <th>ecmwf_diff_8</th>\n      <th>ecmwf_diff_9</th>\n      <th>error_9</th>\n      <th>error_10</th>\n      <th>error_11</th>\n      <th>error_12</th>\n      <th>error_13</th>\n      <th>error_14</th>\n      <th>day_8_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-06-03 00:00:00</th>\n      <td>-0.056</td>\n      <td>0.284</td>\n      <td>0.235</td>\n      <td>-0.012</td>\n      <td>-0.186</td>\n      <td>-0.254</td>\n      <td>-0.062</td>\n      <td>-0.088</td>\n      <td>-0.044</td>\n      <td>0.043</td>\n      <td>...</td>\n      <td>0.115</td>\n      <td>-0.089</td>\n      <td>-0.174</td>\n      <td>-0.140</td>\n      <td>-0.468</td>\n      <td>0.275</td>\n      <td>-0.221</td>\n      <td>-0.289</td>\n      <td>0.201</td>\n      <td>-0.094</td>\n    </tr>\n    <tr>\n      <th>2022-06-03 12:00:00</th>\n      <td>0.245</td>\n      <td>0.149</td>\n      <td>0.015</td>\n      <td>-0.177</td>\n      <td>-0.229</td>\n      <td>-0.307</td>\n      <td>0.023</td>\n      <td>-0.067</td>\n      <td>-0.048</td>\n      <td>0.265</td>\n      <td>...</td>\n      <td>0.162</td>\n      <td>-0.023</td>\n      <td>-0.057</td>\n      <td>0.297</td>\n      <td>-0.509</td>\n      <td>0.013</td>\n      <td>0.016</td>\n      <td>-0.341</td>\n      <td>-0.200</td>\n      <td>0.158</td>\n    </tr>\n    <tr>\n      <th>2022-06-04 00:00:00</th>\n      <td>0.091</td>\n      <td>0.101</td>\n      <td>-0.160</td>\n      <td>-0.319</td>\n      <td>-0.295</td>\n      <td>-0.112</td>\n      <td>-0.053</td>\n      <td>0.052</td>\n      <td>0.277</td>\n      <td>0.186</td>\n      <td>...</td>\n      <td>-0.024</td>\n      <td>-0.017</td>\n      <td>-0.042</td>\n      <td>-0.233</td>\n      <td>0.392</td>\n      <td>-0.141</td>\n      <td>-0.121</td>\n      <td>0.137</td>\n      <td>0.011</td>\n      <td>-0.031</td>\n    </tr>\n    <tr>\n      <th>2022-06-04 12:00:00</th>\n      <td>0.102</td>\n      <td>-0.112</td>\n      <td>-0.176</td>\n      <td>-0.194</td>\n      <td>-0.116</td>\n      <td>-0.056</td>\n      <td>-0.052</td>\n      <td>0.000</td>\n      <td>0.228</td>\n      <td>0.071</td>\n      <td>...</td>\n      <td>-0.171</td>\n      <td>0.030</td>\n      <td>-0.081</td>\n      <td>-0.512</td>\n      <td>0.007</td>\n      <td>-0.027</td>\n      <td>-0.326</td>\n      <td>-0.303</td>\n      <td>-0.023</td>\n      <td>0.147</td>\n    </tr>\n    <tr>\n      <th>2022-06-05 00:00:00</th>\n      <td>0.016</td>\n      <td>-0.119</td>\n      <td>-0.257</td>\n      <td>-0.154</td>\n      <td>-0.074</td>\n      <td>0.054</td>\n      <td>0.053</td>\n      <td>0.370</td>\n      <td>0.110</td>\n      <td>-0.109</td>\n      <td>...</td>\n      <td>0.240</td>\n      <td>-0.118</td>\n      <td>-0.117</td>\n      <td>0.628</td>\n      <td>0.018</td>\n      <td>-0.096</td>\n      <td>0.174</td>\n      <td>0.147</td>\n      <td>-0.022</td>\n      <td>-0.065</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_nolab = test_data.drop(columns=labels)\n",
    "test_data_nolab.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T12:30:48.092546Z",
     "end_time": "2023-06-06T12:30:48.102160Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with TabularPredictor for label: ecmwf-eps_9 ...\n",
      "Predicting with TabularPredictor for label: ecmwf-eps_10 ...\n",
      "Predicting with TabularPredictor for label: ecmwf-eps_11 ...\n",
      "Predicting with TabularPredictor for label: ecmwf-eps_12 ...\n",
      "Predicting with TabularPredictor for label: ecmwf-eps_13 ...\n",
      "Predicting with TabularPredictor for label: ecmwf-eps_14 ...\n",
      "Predictions:  \n",
      "                      ecmwf-eps_9  ecmwf-eps_10  ecmwf-eps_11  ecmwf-eps_12  \\\n",
      "2022-06-03 00:00:00    -0.070274     -0.054683     -0.014851     -0.040611   \n",
      "2022-06-03 12:00:00     0.019687      0.005112      0.005042     -0.007257   \n",
      "2022-06-04 00:00:00    -0.012484     -0.004831     -0.020349     -0.035969   \n",
      "2022-06-04 12:00:00     0.028655     -0.030362     -0.029364     -0.029605   \n",
      "2022-06-05 00:00:00    -0.070877     -0.065110     -0.076699     -0.045437   \n",
      "...                          ...           ...           ...           ...   \n",
      "2023-05-15 00:00:00     0.100431      0.041367     -0.120704     -0.264018   \n",
      "2023-05-15 12:00:00    -0.081939     -0.108349     -0.255811      0.007999   \n",
      "2023-05-16 00:00:00    -0.024271     -0.127283     -0.094130     -0.036875   \n",
      "2023-05-16 12:00:00     0.059725      0.194602      0.297363      0.002931   \n",
      "2023-05-17 00:00:00    -0.004628     -0.104407     -0.038733      0.074933   \n",
      "\n",
      "                     ecmwf-eps_13  ecmwf-eps_14  \n",
      "2022-06-03 00:00:00     -0.071666     -0.059891  \n",
      "2022-06-03 12:00:00     -0.004504      0.005896  \n",
      "2022-06-04 00:00:00     -0.052488     -0.039087  \n",
      "2022-06-04 12:00:00     -0.030316     -0.009782  \n",
      "2022-06-05 00:00:00     -0.031931      0.009311  \n",
      "...                           ...           ...  \n",
      "2023-05-15 00:00:00     -0.123066      0.190095  \n",
      "2023-05-15 12:00:00      0.010169     -0.016418  \n",
      "2023-05-16 00:00:00     -0.035306     -0.060014  \n",
      "2023-05-16 12:00:00     -0.175378     -0.194028  \n",
      "2023-05-17 00:00:00      0.110592     -0.084899  \n",
      "\n",
      "[697 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions = multi_predictor.predict(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T12:30:48.096131Z",
     "end_time": "2023-06-06T12:30:50.597479Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "ecmwf-eps_9     0.059725\necmwf-eps_10    0.194602\necmwf-eps_11    0.297363\necmwf-eps_12    0.002931\necmwf-eps_13   -0.175378\necmwf-eps_14   -0.194028\nName: 2023-05-16 12:00:00, dtype: float32"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictions.iloc[-2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T12:30:50.602460Z",
     "end_time": "2023-06-06T12:30:50.606606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "ecmwf-eps_9     0.261\necmwf-eps_10    0.335\necmwf-eps_11    0.252\necmwf-eps_12    0.221\necmwf-eps_13    0.176\necmwf-eps_14    0.538\nName: 2023-05-16 12:00:00, dtype: float64"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[labels].iloc[-2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T12:30:50.610497Z",
     "end_time": "2023-06-06T12:30:50.613694Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "Evaluation: root_mean_squared_error on test data: -0.08023007545311743\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.08023007545311743,\n",
      "    \"mean_squared_error\": -0.006436865007212917,\n",
      "    \"mean_absolute_error\": -0.05291710419293033,\n",
      "    \"r2\": 0.8108099725454907,\n",
      "    \"pearsonr\": 0.9010937094084588,\n",
      "    \"median_absolute_error\": -0.028835937261582956\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: ecmwf-eps_9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: ecmwf-eps_10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: root_mean_squared_error on test data: -0.11082954443475555\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.11082954443475555,\n",
      "    \"mean_squared_error\": -0.012283187919615454,\n",
      "    \"mean_absolute_error\": -0.07472288912346754,\n",
      "    \"r2\": 0.6756541939793443,\n",
      "    \"pearsonr\": 0.8232688610737003,\n",
      "    \"median_absolute_error\": -0.04603454846143684\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: ecmwf-eps_11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "Evaluation: root_mean_squared_error on test data: -0.21695129123551476\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.21695129123551476,\n",
      "    \"mean_squared_error\": -0.04706786276875714,\n",
      "    \"mean_absolute_error\": -0.14032097252547607,\n",
      "    \"r2\": 0.3058559574307328,\n",
      "    \"pearsonr\": 0.553666118289079,\n",
      "    \"median_absolute_error\": -0.07729820585250913\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: ecmwf-eps_12 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "Evaluation: root_mean_squared_error on test data: -0.358465200581571\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.358465200581571,\n",
      "    \"mean_squared_error\": -0.12849730002798593,\n",
      "    \"mean_absolute_error\": -0.2250503711142715,\n",
      "    \"r2\": 0.14844945212599936,\n",
      "    \"pearsonr\": 0.3869007581003848,\n",
      "    \"median_absolute_error\": -0.13130800652503893\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: ecmwf-eps_13 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "Evaluation: root_mean_squared_error on test data: -0.4945915091799656\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.4945915091799656,\n",
      "    \"mean_squared_error\": -0.24462076095291596,\n",
      "    \"mean_absolute_error\": -0.31190416122347253,\n",
      "    \"r2\": 0.12786390743800213,\n",
      "    \"pearsonr\": 0.3582405521096596,\n",
      "    \"median_absolute_error\": -0.17864633360505106\n",
      "}\n",
      "FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "Evaluation: root_mean_squared_error on test data: -0.6084669201391874\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.6084669201391874,\n",
      "    \"mean_squared_error\": -0.37023199290366826,\n",
      "    \"mean_absolute_error\": -0.39079344333281113,\n",
      "    \"r2\": 0.12233431197612399,\n",
      "    \"pearsonr\": 0.350831916172944,\n",
      "    \"median_absolute_error\": -0.22501058137416763\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: ecmwf-eps_14 ...\n",
      "Evaluated using metrics: {'ecmwf-eps_9': root_mean_squared_error, 'ecmwf-eps_10': root_mean_squared_error, 'ecmwf-eps_11': root_mean_squared_error, 'ecmwf-eps_12': root_mean_squared_error, 'ecmwf-eps_13': root_mean_squared_error, 'ecmwf-eps_14': root_mean_squared_error}\n"
     ]
    }
   ],
   "source": [
    "evaluations = multi_predictor.evaluate(test_data)\n",
    "#print(evaluations)\n",
    "print(\"Evaluated using metrics:\", multi_predictor.eval_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T12:30:50.614765Z",
     "end_time": "2023-06-06T12:30:54.571822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "{'ecmwf-eps_9': {'root_mean_squared_error': -0.08023007545311743,\n  'mean_squared_error': -0.006436865007212917,\n  'mean_absolute_error': -0.05291710419293033,\n  'r2': 0.8108099725454907,\n  'pearsonr': 0.9010937094084588,\n  'median_absolute_error': -0.028835937261582956},\n 'ecmwf-eps_10': {'root_mean_squared_error': -0.11082954443475555,\n  'mean_squared_error': -0.012283187919615454,\n  'mean_absolute_error': -0.07472288912346754,\n  'r2': 0.6756541939793443,\n  'pearsonr': 0.8232688610737003,\n  'median_absolute_error': -0.04603454846143684},\n 'ecmwf-eps_11': {'root_mean_squared_error': -0.21695129123551476,\n  'mean_squared_error': -0.04706786276875714,\n  'mean_absolute_error': -0.14032097252547607,\n  'r2': 0.3058559574307328,\n  'pearsonr': 0.553666118289079,\n  'median_absolute_error': -0.07729820585250913},\n 'ecmwf-eps_12': {'root_mean_squared_error': -0.358465200581571,\n  'mean_squared_error': -0.12849730002798593,\n  'mean_absolute_error': -0.2250503711142715,\n  'r2': 0.14844945212599936,\n  'pearsonr': 0.3869007581003848,\n  'median_absolute_error': -0.13130800652503893},\n 'ecmwf-eps_13': {'root_mean_squared_error': -0.4945915091799656,\n  'mean_squared_error': -0.24462076095291596,\n  'mean_absolute_error': -0.31190416122347253,\n  'r2': 0.12786390743800213,\n  'pearsonr': 0.3582405521096596,\n  'median_absolute_error': -0.17864633360505106},\n 'ecmwf-eps_14': {'root_mean_squared_error': -0.6084669201391874,\n  'mean_squared_error': -0.37023199290366826,\n  'mean_absolute_error': -0.39079344333281113,\n  'r2': 0.12233431197612399,\n  'pearsonr': 0.350831916172944,\n  'median_absolute_error': -0.22501058137416763}}"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T12:30:54.574678Z",
     "end_time": "2023-06-06T12:30:54.577383Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "                     model  score_val  pred_time_val    fit_time  \\\n0      WeightedEnsemble_L2  -0.095835       0.171864   18.375258   \n1   NeuralNetFastAI_BAG_L1  -0.097150       0.051237   15.458665   \n2      WeightedEnsemble_L3  -0.109854       0.597098   99.958364   \n3   NeuralNetFastAI_BAG_L2  -0.109971       0.472545   99.183259   \n4     ExtraTreesMSE_BAG_L2  -0.118655       0.547865   84.945735   \n5     ExtraTreesMSE_BAG_L1  -0.118742       0.118717    0.542624   \n6    NeuralNetTorch_BAG_L2  -0.119436       0.472646  125.935994   \n7   RandomForestMSE_BAG_L1  -0.120014       0.120338    2.784363   \n8   RandomForestMSE_BAG_L2  -0.120406       0.542214   87.558872   \n9          CatBoost_BAG_L2  -0.120425       0.437143   92.961455   \n10         CatBoost_BAG_L1  -0.122057       0.011891   10.737945   \n11          XGBoost_BAG_L2  -0.123194       0.444797   94.687571   \n12   NeuralNetTorch_BAG_L1  -0.123870       0.039287   46.160543   \n13          XGBoost_BAG_L1  -0.128428       0.020871    8.589265   \n14   KNeighborsDist_BAG_L1  -0.208289       0.030599    0.003912   \n15   KNeighborsUnif_BAG_L1  -0.208336       0.030677    0.004941   \n\n    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                 0.000289           0.132230            2       True   \n1                 0.051237          15.458665            1       True   \n2                 0.000304           0.111628            3       True   \n3                 0.048928          14.901001            2       True   \n4                 0.124248           0.663477            2       True   \n5                 0.118717           0.542624            1       True   \n6                 0.049029          41.653736            2       True   \n7                 0.120338           2.784363            1       True   \n8                 0.118597           3.276614            2       True   \n9                 0.013526           8.679197            2       True   \n10                0.011891          10.737945            1       True   \n11                0.021180          10.405313            2       True   \n12                0.039287          46.160543            1       True   \n13                0.020871           8.589265            1       True   \n14                0.030599           0.003912            1       True   \n15                0.030677           0.004941            1       True   \n\n    fit_order  \n0           9  \n1           6  \n2          16  \n3          13  \n4          12  \n5           5  \n6          15  \n7           3  \n8          10  \n9          11  \n10          4  \n11         14  \n12          8  \n13          7  \n14          2  \n15          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_val</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>-0.095835</td>\n      <td>0.171864</td>\n      <td>18.375258</td>\n      <td>0.000289</td>\n      <td>0.132230</td>\n      <td>2</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>-0.097150</td>\n      <td>0.051237</td>\n      <td>15.458665</td>\n      <td>0.051237</td>\n      <td>15.458665</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WeightedEnsemble_L3</td>\n      <td>-0.109854</td>\n      <td>0.597098</td>\n      <td>99.958364</td>\n      <td>0.000304</td>\n      <td>0.111628</td>\n      <td>3</td>\n      <td>True</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NeuralNetFastAI_BAG_L2</td>\n      <td>-0.109971</td>\n      <td>0.472545</td>\n      <td>99.183259</td>\n      <td>0.048928</td>\n      <td>14.901001</td>\n      <td>2</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ExtraTreesMSE_BAG_L2</td>\n      <td>-0.118655</td>\n      <td>0.547865</td>\n      <td>84.945735</td>\n      <td>0.124248</td>\n      <td>0.663477</td>\n      <td>2</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ExtraTreesMSE_BAG_L1</td>\n      <td>-0.118742</td>\n      <td>0.118717</td>\n      <td>0.542624</td>\n      <td>0.118717</td>\n      <td>0.542624</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NeuralNetTorch_BAG_L2</td>\n      <td>-0.119436</td>\n      <td>0.472646</td>\n      <td>125.935994</td>\n      <td>0.049029</td>\n      <td>41.653736</td>\n      <td>2</td>\n      <td>True</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RandomForestMSE_BAG_L1</td>\n      <td>-0.120014</td>\n      <td>0.120338</td>\n      <td>2.784363</td>\n      <td>0.120338</td>\n      <td>2.784363</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForestMSE_BAG_L2</td>\n      <td>-0.120406</td>\n      <td>0.542214</td>\n      <td>87.558872</td>\n      <td>0.118597</td>\n      <td>3.276614</td>\n      <td>2</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>CatBoost_BAG_L2</td>\n      <td>-0.120425</td>\n      <td>0.437143</td>\n      <td>92.961455</td>\n      <td>0.013526</td>\n      <td>8.679197</td>\n      <td>2</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>CatBoost_BAG_L1</td>\n      <td>-0.122057</td>\n      <td>0.011891</td>\n      <td>10.737945</td>\n      <td>0.011891</td>\n      <td>10.737945</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>XGBoost_BAG_L2</td>\n      <td>-0.123194</td>\n      <td>0.444797</td>\n      <td>94.687571</td>\n      <td>0.021180</td>\n      <td>10.405313</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>NeuralNetTorch_BAG_L1</td>\n      <td>-0.123870</td>\n      <td>0.039287</td>\n      <td>46.160543</td>\n      <td>0.039287</td>\n      <td>46.160543</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>XGBoost_BAG_L1</td>\n      <td>-0.128428</td>\n      <td>0.020871</td>\n      <td>8.589265</td>\n      <td>0.020871</td>\n      <td>8.589265</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>KNeighborsDist_BAG_L1</td>\n      <td>-0.208289</td>\n      <td>0.030599</td>\n      <td>0.003912</td>\n      <td>0.030599</td>\n      <td>0.003912</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>KNeighborsUnif_BAG_L1</td>\n      <td>-0.208336</td>\n      <td>0.030677</td>\n      <td>0.004941</td>\n      <td>0.030677</td>\n      <td>0.004941</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_class = multi_predictor.get_predictor('ecmwf-eps_9')\n",
    "predictor_class.leaderboard(silent=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T12:30:54.579287Z",
     "end_time": "2023-06-06T12:30:54.598478Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-06T12:30:54.593026Z",
     "end_time": "2023-06-06T12:30:54.598682Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
