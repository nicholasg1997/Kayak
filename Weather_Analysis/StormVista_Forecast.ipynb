{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:37:36.215859Z",
     "end_time": "2023-07-12T14:37:37.634242Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from datetime import datetime, time\n",
    "import glob\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm import tqdm\n",
    "from meteostat import Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def display_errors(y_true, y_pred, return_vals=False):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    print(f\"MSE: {round(mse, 3)}\")\n",
    "    rmse = mse ** 0.5\n",
    "    print(f\"RMSE: {round(rmse, 3)}\")\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"MAE: {round(mae, 3)}\")\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    print(f\"MAPE: {round(mape, 3)}\")\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"R2: {round(r2, 3)}\")\n",
    "\n",
    "    if return_vals:\n",
    "        return [mse, rmse, mae, mape, r2]\n",
    "\n",
    "def plot_errors(y_true, y_pred, name='N/A'):\n",
    "    plt.scatter(y_true, y_pred, color='blue', marker='o', label=f'error adjusted predictions ({name}) vs actual degree days')\n",
    "    plt.xlabel('actual degree days')\n",
    "    plt.ylabel('predicted degree days')\n",
    "    plt.title(f'Prediction vs Actual ({name})')\n",
    "\n",
    "    max_value = max(max(y_true[-225:]), max(y_true[-225:]))\n",
    "    min_value = min(min(y_true[-225:]), min(y_true[-225:]))\n",
    "    plt.plot([min_value, max_value], [min_value, max_value], color='red', linestyle='--', label='Line of Equality')\n",
    "\n",
    "    plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:37:37.638562Z",
     "end_time": "2023-07-12T14:37:37.640121Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class LinReg:\n",
    "    def __init__(self, train_data, test_data, target_col):\n",
    "        self.X_train = train_data.drop(columns=[target_col])\n",
    "        self.y_train = train_data[target_col]\n",
    "        self.X_test = test_data.drop(columns=[target_col])\n",
    "        self.y_test = test_data[target_col]\n",
    "        self.target_col = target_col\n",
    "        self.model = LinearRegression().fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "        self.evaluate()\n",
    "\n",
    "    def evaluate(self):\n",
    "        display_errors(self.y_test, self.y_pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:37:37.643437Z",
     "end_time": "2023-07-12T14:37:37.644838Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def extract_date_time(filename):\n",
    "    \"\"\"\n",
    "    extract the date and time from the filename\n",
    "    :param filename:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    parts = filename.split('.')\n",
    "    extracted_date = parts[1]\n",
    "    extracted_time = parts[2]\n",
    "    return extracted_date, extracted_time\n",
    "\n",
    "def get_date(file):\n",
    "        \"\"\"get the date from the dataframe and the time from the filename and combine them into a datetime object\n",
    "        :param file: filename containing the time\n",
    "        :return: datetime object\n",
    "        \"\"\"\n",
    "\n",
    "        date_str = str(file.split('.')[1])\n",
    "        time_str = str(file.split('.')[2])\n",
    "        date_value = datetime.strptime(date_str, '%Y%m%d')\n",
    "        time_value = time(int(time_str), 0)\n",
    "        combined_datetime = datetime.combine(date_value.date(), time_value)\n",
    "        return combined_datetime\n",
    "#give type hint on start_date that it should be a string\n",
    "def seasonal_train_test(data, start_date: str, end_date: str):\n",
    "    \"\"\"\n",
    "    split the data into train and test sets based on dates\n",
    "    :param data: dataframe containing the data\n",
    "    :param start_date: start date of the test set\n",
    "    :param end_date: end date of the test set\n",
    "    :return: train and test sets\n",
    "    \"\"\"\n",
    "\n",
    "    test_start = start_date\n",
    "    test_end = end_date\n",
    "    test_data = data.loc[test_start: test_end]\n",
    "\n",
    "    #remove X_test from dataframe to get X_train\n",
    "    mask = (data.index >= test_start) & (data.index <= test_end)\n",
    "    train_data = data.loc[~mask]\n",
    "\n",
    "    return train_data, test_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:37:37.648138Z",
     "end_time": "2023-07-12T14:37:37.649777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class RawDataProcess:\n",
    "    def __init__(self, degree_days='gw_hdd', path='RawData', time=None):\n",
    "        self.degree_days = degree_days\n",
    "        self.path = path\n",
    "        self.sort_files()\n",
    "        self.get_master_model()\n",
    "        if time is not None:\n",
    "            self.filter_time(time)\n",
    "\n",
    "\n",
    "    def filter_time(self, time):\n",
    "        data = self.master_data\n",
    "        data['hour'] = data.index.hour\n",
    "        data = data[data['hour'] == time]\n",
    "        data = data.drop('hour', axis=1)\n",
    "        self.master_data = data\n",
    "\n",
    "    def sort_files(self):\n",
    "        \"\"\"\n",
    "        sort the files in the directory by date and time\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        degree_days = self.degree_days\n",
    "        path = self.path\n",
    "\n",
    "        degree_days = degree_days\n",
    "        ecmwf_files = glob.glob(path + f'/ecmwf.*.[01][02].{degree_days}.csv')\n",
    "        ecmwf_sorted_files = sorted(ecmwf_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[3:]\n",
    "\n",
    "        ecmwf_ens_files = glob.glob(path + f'/ecmwf-eps.*.[01][02].{degree_days}.csv')\n",
    "        ecmwf_ens_sorted_files = sorted(ecmwf_ens_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "\n",
    "        gfs_ens_bc_files = glob.glob(path + f'/gfs-ens-bc.*.[01][02].{degree_days}.csv')\n",
    "        gfs_ens_bc_sorted_files = sorted(gfs_ens_bc_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "\n",
    "        cmc_ens_files = glob.glob(path + f'/cmc-ens.*.[01][02].{degree_days}.csv')\n",
    "        cmc_ens_sorted_files = sorted(cmc_ens_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "        for _ in range(2):\n",
    "            set1 = set((extract_date_time(filename) for filename in ecmwf_sorted_files))\n",
    "            set2 = set((extract_date_time(filename) for filename in ecmwf_ens_sorted_files))\n",
    "\n",
    "            ecmwf_sorted_files = [filename for filename in ecmwf_sorted_files if extract_date_time(filename) in set2]\n",
    "            ecmwf_ens_sorted_files = [filename for filename in ecmwf_ens_sorted_files if\n",
    "                                      extract_date_time(filename) in set1]\n",
    "            cmc_ens_sorted_files = [filename for filename in cmc_ens_sorted_files if extract_date_time(filename) in set1]\n",
    "\n",
    "            master_set = set((extract_date_time(filename) for filename in cmc_ens_sorted_files))\n",
    "            gfs_ens_bc_sorted_files = [filename for filename in gfs_ens_bc_sorted_files if\n",
    "                                       extract_date_time(filename) in master_set]\n",
    "\n",
    "            master_set = set((extract_date_time(filename) for filename in gfs_ens_bc_sorted_files))\n",
    "\n",
    "            ecmwf_sorted_files = [filename for filename in ecmwf_sorted_files if extract_date_time(filename) in master_set]\n",
    "            ecmwf_ens_sorted_files = [filename for filename in ecmwf_ens_sorted_files if\n",
    "                                      extract_date_time(filename) in master_set]\n",
    "            gfs_ens_bc_sorted_files = [filename for filename in gfs_ens_bc_sorted_files if\n",
    "                                       extract_date_time(filename) in master_set]\n",
    "            cmc_ens_sorted_files = [filename for filename in cmc_ens_sorted_files if\n",
    "                                    extract_date_time(filename) in master_set]\n",
    "\n",
    "        self.ecmwf_sorted_files = ecmwf_sorted_files\n",
    "        self.ecmwf_ens_sorted_files = ecmwf_ens_sorted_files\n",
    "        self.gfs_ens_bc_sorted_files = gfs_ens_bc_sorted_files\n",
    "        self.cmc_ens_sorted_files = cmc_ens_sorted_files\n",
    "\n",
    "    def y_value(self, start=8, end=14):\n",
    "        ecmwf_ens_9_14 = pd.DataFrame(columns=[f'ens({start+1},{end})'])\n",
    "\n",
    "        ecmwf_ens_sorted_files = self.ecmwf_ens_sorted_files\n",
    "\n",
    "        for i in range(1, len(ecmwf_ens_sorted_files)):\n",
    "            ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i])\n",
    "            ecmwf_ens_df = ecmwf_ens_df[ecmwf_ens_df[ecmwf_ens_df.columns[2]] >= 1]\n",
    "            prev_ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i - 1])\n",
    "            prev_ecmwf_ens_df = prev_ecmwf_ens_df[prev_ecmwf_ens_df[prev_ecmwf_ens_df.columns[2]] >= 1]\n",
    "\n",
    "            date = get_date(ecmwf_ens_sorted_files[i])\n",
    "            prev_date = get_date(ecmwf_ens_sorted_files[i - 1])\n",
    "            d2 = str(date)[:10]\n",
    "            d1 = str(prev_date)[:10]\n",
    "\n",
    "            if d2 == d1:\n",
    "                offset = 1\n",
    "            else:\n",
    "                offset = 0\n",
    "\n",
    "            cur = ecmwf_ens_df['Value'].iloc[start:end].sum()\n",
    "            prev = prev_ecmwf_ens_df['Value'].iloc[(start+offset):(end+offset)].sum()\n",
    "            change = cur - prev\n",
    "\n",
    "            new_row = pd.DataFrame(change, columns=ecmwf_ens_9_14.columns, index=[date])\n",
    "            ecmwf_ens_9_14 = pd.concat([ecmwf_ens_9_14, new_row])\n",
    "\n",
    "        self.y_values = ecmwf_ens_9_14\n",
    "\n",
    "    def ecmwf_ens(self, start=7, end=8):\n",
    "        ecmwf_ens_8 = pd.DataFrame(columns=[f'ens({end})'])\n",
    "        ecmwf_ens_sorted_files = self.ecmwf_ens_sorted_files\n",
    "\n",
    "        for i in range(1, len(ecmwf_ens_sorted_files)):\n",
    "            ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i])\n",
    "            ecmwf_ens_df = ecmwf_ens_df[ecmwf_ens_df[ecmwf_ens_df.columns[2]] >= 1]\n",
    "            prev_ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i - 1])\n",
    "            prev_ecmwf_ens_df = prev_ecmwf_ens_df[prev_ecmwf_ens_df[prev_ecmwf_ens_df.columns[2]] >= 1]\n",
    "\n",
    "            date = get_date(ecmwf_ens_sorted_files[i])\n",
    "            prev_date = get_date(ecmwf_ens_sorted_files[i - 1])\n",
    "            d2 = str(date)[:10]\n",
    "            d1 = str(prev_date)[:10]\n",
    "\n",
    "            if d2 == d1:\n",
    "                offset = 1\n",
    "            else:\n",
    "                offset = 0\n",
    "\n",
    "            cur = ecmwf_ens_df['Value'].iloc[start:end].sum() #7-8 benchmark, 7-8 best results\n",
    "            prev = prev_ecmwf_ens_df['Value'].iloc[(start+offset):(end+offset)].sum() #7-8 benchmark, 7-8 best results\n",
    "            change = cur - prev\n",
    "\n",
    "            new_row = pd.DataFrame(change, columns=ecmwf_ens_8.columns, index=[date])\n",
    "            ecmwf_ens_8 = pd.concat([ecmwf_ens_8, new_row])\n",
    "\n",
    "        self.ecmwf_ens_data = ecmwf_ens_8\n",
    "\n",
    "    def ecmwf(self, start=8, end=9):\n",
    "\n",
    "        ecmwf_9_10 = pd.DataFrame(columns=[f'ecmwf({end})'])\n",
    "\n",
    "        ecmwf_sorted_files = self.ecmwf_sorted_files\n",
    "        ecmwf_ens_sorted_files = self.ecmwf_ens_sorted_files\n",
    "\n",
    "\n",
    "        for i in range(1, len(ecmwf_sorted_files)):\n",
    "            ecmwf_df = pd.read_csv(ecmwf_sorted_files[i])\n",
    "            ecmwf_df = ecmwf_df[ecmwf_df[ecmwf_df.columns[2]] >= 1]\n",
    "            prev_ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i-1])\n",
    "            prev_ecmwf_ens_df = prev_ecmwf_ens_df[prev_ecmwf_ens_df[prev_ecmwf_ens_df.columns[2]] >= 1]\n",
    "\n",
    "            date = get_date(ecmwf_sorted_files[i])\n",
    "            prev_date = get_date(ecmwf_sorted_files[i - 1])\n",
    "            d2 = str(date)[:10]\n",
    "            d1 = str(prev_date)[:10]\n",
    "\n",
    "            if d2 == d1:\n",
    "                offset = 1\n",
    "            else:\n",
    "                offset = 0\n",
    "\n",
    "            cur = ecmwf_df['Value'].iloc[start:end].sum() #8-9 benchmark, 4-9 best results\n",
    "            prev = prev_ecmwf_ens_df['Value'].iloc[(start+offset):(end+offset)].sum() #8-9 benchmark, 4-9 best results\n",
    "\n",
    "            change = cur - prev\n",
    "\n",
    "            new_row = pd.DataFrame(change, columns=ecmwf_9_10.columns, index=[date])\n",
    "            ecmwf_9_10 = pd.concat([ecmwf_9_10, new_row])\n",
    "\n",
    "        self.ecmwf_data = ecmwf_9_10\n",
    "\n",
    "    def gfs(self, start=9, end=14):\n",
    "        gfs_11_14 = pd.DataFrame(columns=[f'gfs({start+1},{end})'])\n",
    "\n",
    "        ecmwf_ens_sorted_files = self.ecmwf_ens_sorted_files\n",
    "        gfs_ens_bc_sorted_files = self.gfs_ens_bc_sorted_files\n",
    "\n",
    "        for i in range(1, len(gfs_ens_bc_sorted_files)):\n",
    "            gfs_df = pd.read_csv(gfs_ens_bc_sorted_files[i])\n",
    "            gfs_df = gfs_df[gfs_df[gfs_df.columns[2]] >= 1]\n",
    "            prev_ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i-1])\n",
    "            prev_ecmwf_ens_df = prev_ecmwf_ens_df[prev_ecmwf_ens_df[prev_ecmwf_ens_df.columns[2]] >= 1]\n",
    "\n",
    "            date = get_date(gfs_ens_bc_sorted_files[i])\n",
    "            prev_date = get_date(ecmwf_ens_sorted_files[i - 1])\n",
    "            d2 = str(date)[:10]\n",
    "            d1 = str(prev_date)[:10]\n",
    "\n",
    "            if d2 == d1:\n",
    "                offset = 1\n",
    "            else:\n",
    "                offset = 0\n",
    "\n",
    "            cur = gfs_df['Value'].iloc[start:end].sum() # 9-14 benchmark, 9-16 best results\n",
    "            prev = prev_ecmwf_ens_df['Value'].iloc[(start+offset):(end+offset)].sum() # 9-14 benchmark, 9-16 best results\n",
    "\n",
    "            change = cur - prev\n",
    "\n",
    "            new_row = pd.DataFrame(change, columns=gfs_11_14.columns, index=[date])\n",
    "            gfs_11_14 = pd.concat([gfs_11_14, new_row])\n",
    "\n",
    "        self.gfs_data = gfs_11_14\n",
    "\n",
    "    def cmc(self, start=8, end=14):\n",
    "        cmc_9_14 = pd.DataFrame(columns=[f'cmc({start+1},{end})'])\n",
    "\n",
    "        cmc_ens_sorted_files = self.cmc_ens_sorted_files\n",
    "        gfs_ens_bc_sorted_files = self.gfs_ens_bc_sorted_files\n",
    "\n",
    "        for i in range(1, len(cmc_ens_sorted_files)):\n",
    "            cmc_df = pd.read_csv(cmc_ens_sorted_files[i])\n",
    "            cmc_df = cmc_df[cmc_df[cmc_df.columns[2]] >= 1]\n",
    "            gfs_df = pd.read_csv(gfs_ens_bc_sorted_files[i])\n",
    "            gfs_df = gfs_df[gfs_df[gfs_df.columns[2]] >= 1]\n",
    "\n",
    "            date = get_date(cmc_ens_sorted_files[i])\n",
    "\n",
    "            cmc = cmc_df['Value'].iloc[start:end].sum() #8-14 benchmark, 8-14 best results\n",
    "            gfs = gfs_df['Value'].iloc[start:end].sum() #8-14 benchmark, 8-14 best results\n",
    "            change = cmc - gfs\n",
    "\n",
    "            new_row = pd.DataFrame(change, columns=cmc_9_14.columns, index=[date])\n",
    "            cmc_9_14 = pd.concat([cmc_9_14, new_row])\n",
    "\n",
    "        self.cmc_data = cmc_9_14\n",
    "\n",
    "    def norm(self):\n",
    "        norms = pd.DataFrame(columns=['Date', 'Value'])\n",
    "        ecmwf_ens_sorted_files = self.ecmwf_ens_sorted_files\n",
    "\n",
    "        for i in range(1, len(ecmwf_ens_sorted_files), 2):\n",
    "            ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i])\n",
    "            v1 = ecmwf_ens_df[ecmwf_ens_df[ecmwf_ens_df.columns[2]] == 2].iloc[:, :2]\n",
    "            norms = pd.concat([norms, v1]).drop_duplicates('Date')\n",
    "\n",
    "        norms.reset_index(inplace=True)\n",
    "        norms.drop(columns=['index'], inplace=True)\n",
    "        norms['Date'] = pd.to_datetime(norms['Date']).dt.strftime('%Y-%m-%d 12:00:00')\n",
    "        norms.set_index('Date', inplace=True)\n",
    "        norms.rename_axis('', inplace=True)\n",
    "        norms.rename(columns={'Value': 'norm'}, inplace=True)\n",
    "\n",
    "        self.norms_data = norms\n",
    "\n",
    "    def run_all_models(self):\n",
    "        self.y_value()\n",
    "        self.ecmwf_ens()\n",
    "        self.ecmwf()\n",
    "        self.gfs()\n",
    "        self.cmc()\n",
    "        self.norm()\n",
    "\n",
    "    def get_master_model(self):\n",
    "        self.run_all_models()\n",
    "        master_data = pd.concat([self.ecmwf_ens_data, self.ecmwf_data,\n",
    "                                 self.gfs_data, self.cmc_data, self.y_values], axis=1)\n",
    "\n",
    "        self.master_data = master_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:44:20.737242Z",
     "end_time": "2023-07-12T14:44:20.755005Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "data = RawDataProcess(degree_days='gw_hdd', path='RawData', time=12)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:44:21.744229Z",
     "end_time": "2023-07-12T14:44:59.955909Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "master_data = data.master_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:38:36.508970Z",
     "end_time": "2023-07-12T14:38:36.511992Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class LoadWeatherData:\n",
    "    def __init__(self, start=datetime(2018, 7, 11), end=datetime(2023, 6, 16)):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.load_stations()\n",
    "\n",
    "    def load_stations(self, path='StormVistaData/station_df.csv'):\n",
    "        stations = pd.read_csv(path)\n",
    "        stations.rename(columns={'Unnamed: 0': 'id'}, inplace=True)\n",
    "        self.stations = stations['id'].tolist()\n",
    "\n",
    "    def process_weather_data(self, limited_cities=True):\n",
    "\n",
    "        if limited_cities:\n",
    "            citys = ['72278', '72295', '72565', '72508', 'H3GG0',\n",
    "                     '72405', '72206', 'KFTY0', '72681', '72530', '72438',\n",
    "                     '72546', '72451', '72435', '74754', '72606', '72406',\n",
    "                     '72509', '72635', '72644', '72235', '72446', '72773']\n",
    "        else:\n",
    "            citys = self.stations\n",
    "\n",
    "        weather_df = pd.DataFrame()\n",
    "        for i in tqdm(citys):\n",
    "            weather_data = Daily(i, self.start, self.end)\n",
    "            weather_data = weather_data.fetch()\n",
    "            weather_data = weather_data[['tavg', 'tmin', 'tmax', 'prcp', 'pres']]\n",
    "            weather_data = weather_data.add_suffix(f'_{i}')\n",
    "            weather_df = pd.concat([weather_df, weather_data], axis=1)\n",
    "        weather_df.reset_index(inplace=True)\n",
    "        weather_df['Date'] = pd.to_datetime(weather_df['time']).dt.strftime('%Y-%m-%d 12:00:00')\n",
    "        weather_df.drop(columns=['time'], inplace=True)\n",
    "        weather_df.set_index('Date', inplace=True)\n",
    "        weather_df.rename_axis('', inplace=True)\n",
    "        weather_df.index = pd.to_datetime(weather_df.index)\n",
    "\n",
    "        return weather_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:39:02.871944Z",
     "end_time": "2023-07-12T14:39:02.884143Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:17<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "weather_data = LoadWeatherData()\n",
    "weather_df = weather_data.process_weather_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:39:03.644076Z",
     "end_time": "2023-07-12T14:39:20.767127Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "common_dates = master_data.index.intersection(weather_df.index)\n",
    "master_data = pd.concat([master_data.loc[common_dates], weather_df.loc[common_dates]], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:39:23.820379Z",
     "end_time": "2023-07-12T14:39:23.849728Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                     ens(8)  ecmwf(9)  gfs(10,14)  cmc(9,14)  ens(9,14)  \\\n2018-07-11 12:00:00   0.003     0.024       0.039     -0.040      0.024   \n2018-07-12 12:00:00  -0.002     0.005       0.046     -0.053      0.023   \n2018-07-13 12:00:00   0.000     0.003       0.037     -0.048      0.029   \n2018-07-14 12:00:00  -0.001    -0.001       0.046     -0.053      0.027   \n2018-07-15 12:00:00   0.000     0.006       0.034     -0.039      0.033   \n\n                     tavg_72278  tmin_72278  tmax_72278  prcp_72278  \\\n2018-07-11 12:00:00        30.4        26.1        38.3         0.0   \n2018-07-12 12:00:00        30.7        25.6        38.9         0.0   \n2018-07-13 12:00:00        34.1        30.0        41.1         0.0   \n2018-07-14 12:00:00        34.6        30.6        39.4         0.0   \n2018-07-15 12:00:00        33.2        31.1        37.8         0.0   \n\n                     pres_72278  ...  tavg_72446  tmin_72446  tmax_72446  \\\n2018-07-11 12:00:00         NaN  ...        30.3        24.4        37.2   \n2018-07-12 12:00:00      1010.9  ...        30.6        24.4        37.8   \n2018-07-13 12:00:00      1010.8  ...        30.3        22.8        37.2   \n2018-07-14 12:00:00      1010.1  ...        26.8        22.2        31.7   \n2018-07-15 12:00:00      1010.1  ...        27.3        20.6        34.4   \n\n                     prcp_72446  pres_72446  tavg_72773  tmin_72773  \\\n2018-07-11 12:00:00         0.0      1016.2        19.2         8.9   \n2018-07-12 12:00:00         0.0      1016.2        20.1         9.4   \n2018-07-13 12:00:00         0.0      1015.4        22.1        11.1   \n2018-07-14 12:00:00         0.5      1015.1        23.2        12.2   \n2018-07-15 12:00:00         0.0      1014.5        22.8        12.8   \n\n                     tmax_72773  prcp_72773  pres_72773  \n2018-07-11 12:00:00        27.8         0.0      1018.6  \n2018-07-12 12:00:00        31.1         0.0      1017.7  \n2018-07-13 12:00:00        33.3         0.0      1016.3  \n2018-07-14 12:00:00        32.8         0.0      1015.7  \n2018-07-15 12:00:00        32.2         0.0      1016.9  \n\n[5 rows x 120 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ens(8)</th>\n      <th>ecmwf(9)</th>\n      <th>gfs(10,14)</th>\n      <th>cmc(9,14)</th>\n      <th>ens(9,14)</th>\n      <th>tavg_72278</th>\n      <th>tmin_72278</th>\n      <th>tmax_72278</th>\n      <th>prcp_72278</th>\n      <th>pres_72278</th>\n      <th>...</th>\n      <th>tavg_72446</th>\n      <th>tmin_72446</th>\n      <th>tmax_72446</th>\n      <th>prcp_72446</th>\n      <th>pres_72446</th>\n      <th>tavg_72773</th>\n      <th>tmin_72773</th>\n      <th>tmax_72773</th>\n      <th>prcp_72773</th>\n      <th>pres_72773</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-07-11 12:00:00</th>\n      <td>0.003</td>\n      <td>0.024</td>\n      <td>0.039</td>\n      <td>-0.040</td>\n      <td>0.024</td>\n      <td>30.4</td>\n      <td>26.1</td>\n      <td>38.3</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>30.3</td>\n      <td>24.4</td>\n      <td>37.2</td>\n      <td>0.0</td>\n      <td>1016.2</td>\n      <td>19.2</td>\n      <td>8.9</td>\n      <td>27.8</td>\n      <td>0.0</td>\n      <td>1018.6</td>\n    </tr>\n    <tr>\n      <th>2018-07-12 12:00:00</th>\n      <td>-0.002</td>\n      <td>0.005</td>\n      <td>0.046</td>\n      <td>-0.053</td>\n      <td>0.023</td>\n      <td>30.7</td>\n      <td>25.6</td>\n      <td>38.9</td>\n      <td>0.0</td>\n      <td>1010.9</td>\n      <td>...</td>\n      <td>30.6</td>\n      <td>24.4</td>\n      <td>37.8</td>\n      <td>0.0</td>\n      <td>1016.2</td>\n      <td>20.1</td>\n      <td>9.4</td>\n      <td>31.1</td>\n      <td>0.0</td>\n      <td>1017.7</td>\n    </tr>\n    <tr>\n      <th>2018-07-13 12:00:00</th>\n      <td>0.000</td>\n      <td>0.003</td>\n      <td>0.037</td>\n      <td>-0.048</td>\n      <td>0.029</td>\n      <td>34.1</td>\n      <td>30.0</td>\n      <td>41.1</td>\n      <td>0.0</td>\n      <td>1010.8</td>\n      <td>...</td>\n      <td>30.3</td>\n      <td>22.8</td>\n      <td>37.2</td>\n      <td>0.0</td>\n      <td>1015.4</td>\n      <td>22.1</td>\n      <td>11.1</td>\n      <td>33.3</td>\n      <td>0.0</td>\n      <td>1016.3</td>\n    </tr>\n    <tr>\n      <th>2018-07-14 12:00:00</th>\n      <td>-0.001</td>\n      <td>-0.001</td>\n      <td>0.046</td>\n      <td>-0.053</td>\n      <td>0.027</td>\n      <td>34.6</td>\n      <td>30.6</td>\n      <td>39.4</td>\n      <td>0.0</td>\n      <td>1010.1</td>\n      <td>...</td>\n      <td>26.8</td>\n      <td>22.2</td>\n      <td>31.7</td>\n      <td>0.5</td>\n      <td>1015.1</td>\n      <td>23.2</td>\n      <td>12.2</td>\n      <td>32.8</td>\n      <td>0.0</td>\n      <td>1015.7</td>\n    </tr>\n    <tr>\n      <th>2018-07-15 12:00:00</th>\n      <td>0.000</td>\n      <td>0.006</td>\n      <td>0.034</td>\n      <td>-0.039</td>\n      <td>0.033</td>\n      <td>33.2</td>\n      <td>31.1</td>\n      <td>37.8</td>\n      <td>0.0</td>\n      <td>1010.1</td>\n      <td>...</td>\n      <td>27.3</td>\n      <td>20.6</td>\n      <td>34.4</td>\n      <td>0.0</td>\n      <td>1014.5</td>\n      <td>22.8</td>\n      <td>12.8</td>\n      <td>32.2</td>\n      <td>0.0</td>\n      <td>1016.9</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 120 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(master_data.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:39:24.222859Z",
     "end_time": "2023-07-12T14:39:24.263536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "train_data, test_data = seasonal_train_test(master_data, '2022-10-04 12:00:00', '2023-5-16 12:00:00')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:39:51.639347Z",
     "end_time": "2023-07-12T14:39:51.661657Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "train_data = TabularDataset(train_data)\n",
    "test_data = TabularDataset(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:39:51.916623Z",
     "end_time": "2023-07-12T14:39:51.942296Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "label = 'ens(9,14)'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:39:52.201142Z",
     "end_time": "2023-07-12T14:39:52.221016Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "y_test = test_data[label]\n",
    "test_data_nolabel = test_data.drop(columns=[label])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:39:52.492616Z",
     "end_time": "2023-07-12T14:39:52.512542Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230712_203952/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230712_203952/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:19 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    1524\n",
      "Train Data Columns: 119\n",
      "Label Column: ens(9,14)\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (228.63299999999998, 0.0, 70.03885, 68.93051)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1287.28 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.45 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 119 | ['ens(8)', 'ecmwf(9)', 'gfs(10,14)', 'cmc(9,14)', 'tavg_72278', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 119 | ['ens(8)', 'ecmwf(9)', 'gfs(10,14)', 'cmc(9,14)', 'tavg_72278', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t119 features in original data used to generate 119 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1219, Val Rows: 305\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-27.5983\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-29.2184\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-17.7498\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.25s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-17.1622\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-17.6781\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-16.7096\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.49s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-17.6954\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-17.731\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-15.8025\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 21.44s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230712_203952/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data) # presets='best_quality'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:39:52.877378Z",
     "end_time": "2023-07-12T14:40:14.340737Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:40:14.341805Z",
     "end_time": "2023-07-12T14:40:14.343708Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "fi = predictor.feature_importance(test_data, silent=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:40:14.347132Z",
     "end_time": "2023-07-12T14:40:18.758679Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "            importance    stddev   p_value  n  p99_high   p99_low\ntavg_72278    3.112485  0.477146  0.000064  5  4.094935  2.130034\ntmax_72681    2.442742  0.266307  0.000017  5  2.991071  1.894412\ntmax_72773    2.199818  0.280980  0.000031  5  2.778360  1.621276\ntmax_72278    1.548230  0.150555  0.000011  5  1.858226  1.238235\ntavg_72681    1.124985  0.155303  0.000042  5  1.444757  0.805214\npres_72278    1.116491  0.272670  0.000395  5  1.677922  0.555061\ntmin_72278    1.103012  0.185832  0.000093  5  1.485642  0.720383\ntavg_72644    0.917157  0.119303  0.000034  5  1.162804  0.671510\ntavg_72773    0.621653  0.101464  0.000082  5  0.830568  0.412737\ntavg_72206    0.615980  0.195559  0.001071  5  1.018638  0.213322\ntmax_72606    0.613305  0.148220  0.000379  5  0.918493  0.308118\ntavg_72606    0.607169  0.194535  0.001108  5  1.007720  0.206618\ntmax_72546    0.586093  0.065920  0.000019  5  0.721823  0.450363\npres_72773    0.476761  0.154545  0.001158  5  0.794971  0.158551\ntmax_72644    0.463849  0.102765  0.000271  5  0.675443  0.252254\ntmin_72606    0.415303  0.100839  0.000386  5  0.622932  0.207674\ntmax_72451    0.412689  0.051594  0.000029  5  0.518922  0.306456\ntmax_KFTY0    0.384791  0.182834  0.004633  5  0.761248  0.008334\ntmax_72405    0.356315  0.085811  0.000374  5  0.533001  0.179628\ntmin_72546    0.318019  0.071334  0.000284  5  0.464896  0.171142",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance</th>\n      <th>stddev</th>\n      <th>p_value</th>\n      <th>n</th>\n      <th>p99_high</th>\n      <th>p99_low</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tavg_72278</th>\n      <td>3.112485</td>\n      <td>0.477146</td>\n      <td>0.000064</td>\n      <td>5</td>\n      <td>4.094935</td>\n      <td>2.130034</td>\n    </tr>\n    <tr>\n      <th>tmax_72681</th>\n      <td>2.442742</td>\n      <td>0.266307</td>\n      <td>0.000017</td>\n      <td>5</td>\n      <td>2.991071</td>\n      <td>1.894412</td>\n    </tr>\n    <tr>\n      <th>tmax_72773</th>\n      <td>2.199818</td>\n      <td>0.280980</td>\n      <td>0.000031</td>\n      <td>5</td>\n      <td>2.778360</td>\n      <td>1.621276</td>\n    </tr>\n    <tr>\n      <th>tmax_72278</th>\n      <td>1.548230</td>\n      <td>0.150555</td>\n      <td>0.000011</td>\n      <td>5</td>\n      <td>1.858226</td>\n      <td>1.238235</td>\n    </tr>\n    <tr>\n      <th>tavg_72681</th>\n      <td>1.124985</td>\n      <td>0.155303</td>\n      <td>0.000042</td>\n      <td>5</td>\n      <td>1.444757</td>\n      <td>0.805214</td>\n    </tr>\n    <tr>\n      <th>pres_72278</th>\n      <td>1.116491</td>\n      <td>0.272670</td>\n      <td>0.000395</td>\n      <td>5</td>\n      <td>1.677922</td>\n      <td>0.555061</td>\n    </tr>\n    <tr>\n      <th>tmin_72278</th>\n      <td>1.103012</td>\n      <td>0.185832</td>\n      <td>0.000093</td>\n      <td>5</td>\n      <td>1.485642</td>\n      <td>0.720383</td>\n    </tr>\n    <tr>\n      <th>tavg_72644</th>\n      <td>0.917157</td>\n      <td>0.119303</td>\n      <td>0.000034</td>\n      <td>5</td>\n      <td>1.162804</td>\n      <td>0.671510</td>\n    </tr>\n    <tr>\n      <th>tavg_72773</th>\n      <td>0.621653</td>\n      <td>0.101464</td>\n      <td>0.000082</td>\n      <td>5</td>\n      <td>0.830568</td>\n      <td>0.412737</td>\n    </tr>\n    <tr>\n      <th>tavg_72206</th>\n      <td>0.615980</td>\n      <td>0.195559</td>\n      <td>0.001071</td>\n      <td>5</td>\n      <td>1.018638</td>\n      <td>0.213322</td>\n    </tr>\n    <tr>\n      <th>tmax_72606</th>\n      <td>0.613305</td>\n      <td>0.148220</td>\n      <td>0.000379</td>\n      <td>5</td>\n      <td>0.918493</td>\n      <td>0.308118</td>\n    </tr>\n    <tr>\n      <th>tavg_72606</th>\n      <td>0.607169</td>\n      <td>0.194535</td>\n      <td>0.001108</td>\n      <td>5</td>\n      <td>1.007720</td>\n      <td>0.206618</td>\n    </tr>\n    <tr>\n      <th>tmax_72546</th>\n      <td>0.586093</td>\n      <td>0.065920</td>\n      <td>0.000019</td>\n      <td>5</td>\n      <td>0.721823</td>\n      <td>0.450363</td>\n    </tr>\n    <tr>\n      <th>pres_72773</th>\n      <td>0.476761</td>\n      <td>0.154545</td>\n      <td>0.001158</td>\n      <td>5</td>\n      <td>0.794971</td>\n      <td>0.158551</td>\n    </tr>\n    <tr>\n      <th>tmax_72644</th>\n      <td>0.463849</td>\n      <td>0.102765</td>\n      <td>0.000271</td>\n      <td>5</td>\n      <td>0.675443</td>\n      <td>0.252254</td>\n    </tr>\n    <tr>\n      <th>tmin_72606</th>\n      <td>0.415303</td>\n      <td>0.100839</td>\n      <td>0.000386</td>\n      <td>5</td>\n      <td>0.622932</td>\n      <td>0.207674</td>\n    </tr>\n    <tr>\n      <th>tmax_72451</th>\n      <td>0.412689</td>\n      <td>0.051594</td>\n      <td>0.000029</td>\n      <td>5</td>\n      <td>0.518922</td>\n      <td>0.306456</td>\n    </tr>\n    <tr>\n      <th>tmax_KFTY0</th>\n      <td>0.384791</td>\n      <td>0.182834</td>\n      <td>0.004633</td>\n      <td>5</td>\n      <td>0.761248</td>\n      <td>0.008334</td>\n    </tr>\n    <tr>\n      <th>tmax_72405</th>\n      <td>0.356315</td>\n      <td>0.085811</td>\n      <td>0.000374</td>\n      <td>5</td>\n      <td>0.533001</td>\n      <td>0.179628</td>\n    </tr>\n    <tr>\n      <th>tmin_72546</th>\n      <td>0.318019</td>\n      <td>0.071334</td>\n      <td>0.000284</td>\n      <td>5</td>\n      <td>0.464896</td>\n      <td>0.171142</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(fi.head(20))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:40:18.759762Z",
     "end_time": "2023-07-12T14:40:18.770626Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1507.386\n",
      "RMSE: 38.825\n",
      "MAE: 29.193\n",
      "MAPE: 0.239\n",
      "R2: 0.498\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolabel)\n",
    "display_errors(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:40:18.770325Z",
     "end_time": "2023-07-12T14:40:18.835180Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 80.855\n",
      "RMSE: 8.992\n",
      "MAE: 5.612\n",
      "MAPE: 6741567304427.611\n",
      "R2: 0.983\n"
     ]
    }
   ],
   "source": [
    "#train errors\n",
    "display_errors(train_data[label], predictor.predict(train_data.drop(columns=[label])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:40:18.829882Z",
     "end_time": "2023-07-12T14:40:18.944398Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m linreg \u001B[38;5;241m=\u001B[39m \u001B[43mLinReg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[3], line 8\u001B[0m, in \u001B[0;36mLinReg.__init__\u001B[0;34m(self, train_data, test_data, target_col)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_test \u001B[38;5;241m=\u001B[39m test_data[target_col]\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_col \u001B[38;5;241m=\u001B[39m target_col\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mLinearRegression\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mpredict(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_test)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate()\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/sklearn/linear_model/_base.py:648\u001B[0m, in \u001B[0;36mLinearRegression.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    644\u001B[0m n_jobs_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs\n\u001B[1;32m    646\u001B[0m accept_sparse \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpositive \u001B[38;5;28;01melse\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoo\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m--> 648\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_numeric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m    650\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    652\u001B[0m sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(\n\u001B[1;32m    653\u001B[0m     sample_weight, X, dtype\u001B[38;5;241m=\u001B[39mX\u001B[38;5;241m.\u001B[39mdtype, only_non_negative\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    654\u001B[0m )\n\u001B[1;32m    656\u001B[0m X, y, X_offset, y_offset, X_scale \u001B[38;5;241m=\u001B[39m _preprocess_data(\n\u001B[1;32m    657\u001B[0m     X,\n\u001B[1;32m    658\u001B[0m     y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    661\u001B[0m     sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[1;32m    662\u001B[0m )\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/sklearn/base.py:584\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    582\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 584\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    585\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    587\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/sklearn/utils/validation.py:1106\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1101\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[1;32m   1102\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1103\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1104\u001B[0m     )\n\u001B[0;32m-> 1106\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1108\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1109\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1113\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1118\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1119\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1120\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1122\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[1;32m   1124\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    915\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    916\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    917\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    918\u001B[0m         )\n\u001B[1;32m    920\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m--> 921\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    929\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    147\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    149\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    160\u001B[0m     )\n\u001B[0;32m--> 161\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[0;31mValueError\u001B[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "linreg = LinReg(train_data, test_data, label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:11:57.284060Z",
     "end_time": "2023-07-12T10:11:57.291362Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T11:44:32.332054Z",
     "end_time": "2023-07-12T11:44:32.348288Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T15:38:10.070735Z",
     "end_time": "2023-07-06T15:38:10.083660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T15:38:10.589271Z",
     "end_time": "2023-07-06T15:38:10.598372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# weather data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:30:35.164426Z",
     "end_time": "2023-07-12T14:30:35.187428Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T14:30:41.457254Z",
     "end_time": "2023-07-12T14:30:41.472283Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "stations = pd.read_csv('StormVistaData/station_df.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:12:30.987955Z",
     "end_time": "2023-07-12T10:12:31.014502Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "stations.rename(columns={'Unnamed: 0': 'id'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:12:31.186921Z",
     "end_time": "2023-07-12T10:12:31.203763Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "station_ids = stations['id'].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:12:31.386579Z",
     "end_time": "2023-07-12T10:12:31.404948Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "start = datetime(2018, 7, 11)\n",
    "end = datetime(2023, 6, 16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:12:31.603484Z",
     "end_time": "2023-07-12T10:12:31.623326Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "        id  icao  latitude  longitude  elevation  \\\n53   72772  KHLN   46.6000  -111.9667     1180.0   \n68   72768  KGGW   48.2167  -106.6167      699.0   \n168  72779  KGPI   48.3000  -114.2667      906.0   \n210  72775  KGTF   47.4667  -111.3833     1120.0   \n226  72777  KHVR   48.5500  -109.7667      789.0   \n234  72677  KBIL   45.8167  -108.5500     1112.0   \n245  74230  KMLS   46.4333  -105.8833      801.0   \n295  KBZN0  KBZN   45.7776  -111.1520     1363.0   \n491  72773  KMSO   46.9167  -114.1000      976.0   \n\n                                            name region        timezone  \n53                       Helena Regional Airport     MT  America/Denver  \n68                 Glasgow International Airport     MT  America/Denver  \n168          Glacier Park International  Airport     MT  America/Denver  \n210                    Great Falls International     MT  America/Denver  \n226                    Havre City-County Airport     MT  America/Denver  \n234                  Logan International Airport     MT  America/Denver  \n245                                   Miles City     MT  America/Denver  \n295  Bozeman / Belgrade Village Mobile Home Park     MT  America/Denver  \n491               Missoula International Airport     MT  America/Denver  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>icao</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>elevation</th>\n      <th>name</th>\n      <th>region</th>\n      <th>timezone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>53</th>\n      <td>72772</td>\n      <td>KHLN</td>\n      <td>46.6000</td>\n      <td>-111.9667</td>\n      <td>1180.0</td>\n      <td>Helena Regional Airport</td>\n      <td>MT</td>\n      <td>America/Denver</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>72768</td>\n      <td>KGGW</td>\n      <td>48.2167</td>\n      <td>-106.6167</td>\n      <td>699.0</td>\n      <td>Glasgow International Airport</td>\n      <td>MT</td>\n      <td>America/Denver</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>72779</td>\n      <td>KGPI</td>\n      <td>48.3000</td>\n      <td>-114.2667</td>\n      <td>906.0</td>\n      <td>Glacier Park International  Airport</td>\n      <td>MT</td>\n      <td>America/Denver</td>\n    </tr>\n    <tr>\n      <th>210</th>\n      <td>72775</td>\n      <td>KGTF</td>\n      <td>47.4667</td>\n      <td>-111.3833</td>\n      <td>1120.0</td>\n      <td>Great Falls International</td>\n      <td>MT</td>\n      <td>America/Denver</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>72777</td>\n      <td>KHVR</td>\n      <td>48.5500</td>\n      <td>-109.7667</td>\n      <td>789.0</td>\n      <td>Havre City-County Airport</td>\n      <td>MT</td>\n      <td>America/Denver</td>\n    </tr>\n    <tr>\n      <th>234</th>\n      <td>72677</td>\n      <td>KBIL</td>\n      <td>45.8167</td>\n      <td>-108.5500</td>\n      <td>1112.0</td>\n      <td>Logan International Airport</td>\n      <td>MT</td>\n      <td>America/Denver</td>\n    </tr>\n    <tr>\n      <th>245</th>\n      <td>74230</td>\n      <td>KMLS</td>\n      <td>46.4333</td>\n      <td>-105.8833</td>\n      <td>801.0</td>\n      <td>Miles City</td>\n      <td>MT</td>\n      <td>America/Denver</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>KBZN0</td>\n      <td>KBZN</td>\n      <td>45.7776</td>\n      <td>-111.1520</td>\n      <td>1363.0</td>\n      <td>Bozeman / Belgrade Village Mobile Home Park</td>\n      <td>MT</td>\n      <td>America/Denver</td>\n    </tr>\n    <tr>\n      <th>491</th>\n      <td>72773</td>\n      <td>KMSO</td>\n      <td>46.9167</td>\n      <td>-114.1000</td>\n      <td>976.0</td>\n      <td>Missoula International Airport</td>\n      <td>MT</td>\n      <td>America/Denver</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(stations[stations['region']=='MT'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:12:31.817389Z",
     "end_time": "2023-07-12T10:12:31.856569Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "citys = ['72278', '72295', '72565', '72508', 'H3GG0',\n",
    "         '72405', '72206', 'KFTY0', '72681', '72530', '72438',\n",
    "         '72546', '72451', '72435', '74754', '72606', '72406',\n",
    "         '72509', '72635', '72644', '72235', '72446', '72773']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:12:32.538579Z",
     "end_time": "2023-07-12T10:12:32.558325Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "            tavg  tmin  tmax  prcp  snow   wdir  wspd  wpgt    pres  tsun\ntime                                                                     \n2018-07-11  30.4  26.1  38.3   0.0   0.0  141.0  13.7   NaN     NaN   NaN\n2018-07-12  30.7  25.6  38.9   0.0   0.0    NaN   9.7   NaN  1010.9   NaN\n2018-07-13  34.1  30.0  41.1   0.0   0.0   93.0  12.6   NaN  1010.8   NaN\n2018-07-14  34.6  30.6  39.4   0.0   0.0    NaN  13.3   NaN  1010.1   NaN\n2018-07-15  33.2  31.1  37.8   0.0   0.0    NaN  13.7   NaN  1010.1   NaN\n...          ...   ...   ...   ...   ...    ...   ...   ...     ...   ...\n2023-06-12  27.7  21.7  33.9   0.0   0.0  131.0  11.2   NaN  1009.4   NaN\n2023-06-13  28.9  23.3  35.6   0.0   0.0  288.0   9.7   NaN  1009.2   NaN\n2023-06-14  30.4  23.3  38.3   0.0   0.0  254.0  11.2   NaN  1005.9   NaN\n2023-06-15  31.4  25.0  38.3   0.0   0.0  258.0  11.5   NaN  1006.0   NaN\n2023-06-16  32.4  24.4  40.0   0.0   0.0  295.0  11.9   NaN  1007.5   NaN\n\n[1802 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tavg</th>\n      <th>tmin</th>\n      <th>tmax</th>\n      <th>prcp</th>\n      <th>snow</th>\n      <th>wdir</th>\n      <th>wspd</th>\n      <th>wpgt</th>\n      <th>pres</th>\n      <th>tsun</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-07-11</th>\n      <td>30.4</td>\n      <td>26.1</td>\n      <td>38.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>141.0</td>\n      <td>13.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-07-12</th>\n      <td>30.7</td>\n      <td>25.6</td>\n      <td>38.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>9.7</td>\n      <td>NaN</td>\n      <td>1010.9</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-07-13</th>\n      <td>34.1</td>\n      <td>30.0</td>\n      <td>41.1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>93.0</td>\n      <td>12.6</td>\n      <td>NaN</td>\n      <td>1010.8</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-07-14</th>\n      <td>34.6</td>\n      <td>30.6</td>\n      <td>39.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>13.3</td>\n      <td>NaN</td>\n      <td>1010.1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-07-15</th>\n      <td>33.2</td>\n      <td>31.1</td>\n      <td>37.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>13.7</td>\n      <td>NaN</td>\n      <td>1010.1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-06-12</th>\n      <td>27.7</td>\n      <td>21.7</td>\n      <td>33.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>131.0</td>\n      <td>11.2</td>\n      <td>NaN</td>\n      <td>1009.4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2023-06-13</th>\n      <td>28.9</td>\n      <td>23.3</td>\n      <td>35.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>288.0</td>\n      <td>9.7</td>\n      <td>NaN</td>\n      <td>1009.2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2023-06-14</th>\n      <td>30.4</td>\n      <td>23.3</td>\n      <td>38.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>254.0</td>\n      <td>11.2</td>\n      <td>NaN</td>\n      <td>1005.9</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2023-06-15</th>\n      <td>31.4</td>\n      <td>25.0</td>\n      <td>38.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>258.0</td>\n      <td>11.5</td>\n      <td>NaN</td>\n      <td>1006.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2023-06-16</th>\n      <td>32.4</td>\n      <td>24.4</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>295.0</td>\n      <td>11.9</td>\n      <td>NaN</td>\n      <td>1007.5</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1802 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wd = Daily('72278', start, end).fetch()\n",
    "display(wd)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T11:42:12.159301Z",
     "end_time": "2023-07-12T11:42:12.197222Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 113.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get daily data\n",
    "weather_df = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(citys):\n",
    "    weather_data = Daily(i, start, end)\n",
    "    weather_data = weather_data.fetch()\n",
    "    weather_data = weather_data[['tavg', 'tmin', 'tmax', 'prcp', 'pres']]\n",
    "    weather_data = weather_data.add_suffix(f'_{i}')\n",
    "    weather_df = pd.concat([weather_df, weather_data], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:27:33.613915Z",
     "end_time": "2023-07-12T10:27:33.819799Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "            tavg_72278  tmin_72278  tmax_72278  prcp_72278  pres_72278  \\\ntime                                                                     \n2018-07-11        30.4        26.1        38.3         0.0         NaN   \n2018-07-12        30.7        25.6        38.9         0.0      1010.9   \n2018-07-13        34.1        30.0        41.1         0.0      1010.8   \n2018-07-14        34.6        30.6        39.4         0.0      1010.1   \n2018-07-15        33.2        31.1        37.8         0.0      1010.1   \n...                ...         ...         ...         ...         ...   \n2023-06-12        27.7        21.7        33.9         0.0      1009.4   \n2023-06-13        28.9        23.3        35.6         0.0      1009.2   \n2023-06-14        30.4        23.3        38.3         0.0      1005.9   \n2023-06-15        31.4        25.0        38.3         0.0      1006.0   \n2023-06-16        32.4        24.4        40.0         0.0      1007.5   \n\n            tavg_72295  tmin_72295  tmax_72295  prcp_72295  pres_72295  ...  \\\ntime                                                                    ...   \n2018-07-11        23.8        21.7        26.7         0.0      1012.1  ...   \n2018-07-12        23.3        21.1        26.1         0.0      1013.8  ...   \n2018-07-13        22.2        20.6        24.4         0.0      1015.6  ...   \n2018-07-14        22.1        20.0        25.6         0.0      1014.5  ...   \n2018-07-15        22.7        20.6        25.6         0.0      1013.6  ...   \n...                ...         ...         ...         ...         ...  ...   \n2023-06-12        17.5        15.6        21.1         0.0      1016.6  ...   \n2023-06-13        17.4        15.6        20.6         0.0      1016.4  ...   \n2023-06-14        16.6        15.0        18.3         0.0      1013.9  ...   \n2023-06-15        17.2        16.1        19.4         0.0      1013.3  ...   \n2023-06-16        17.7        16.1        21.1         0.0      1014.7  ...   \n\n            tavg_72446  tmin_72446  tmax_72446  prcp_72446  pres_72446  \\\ntime                                                                     \n2018-07-11        30.3        24.4        37.2         0.0      1016.2   \n2018-07-12        30.6        24.4        37.8         0.0      1016.2   \n2018-07-13        30.3        22.8        37.2         0.0      1015.4   \n2018-07-14        26.8        22.2        31.7         0.5      1015.1   \n2018-07-15        27.3        20.6        34.4         0.0      1014.5   \n...                ...         ...         ...         ...         ...   \n2023-06-12        17.6        10.6        23.3         0.0      1014.4   \n2023-06-13        19.1        10.0        26.7         0.0      1010.8   \n2023-06-14        21.9        13.3        29.4         0.0      1006.4   \n2023-06-15        23.1        14.4        30.0         0.0      1007.8   \n2023-06-16        25.3        16.7        31.1         0.0      1010.7   \n\n            tavg_72773  tmin_72773  tmax_72773  prcp_72773  pres_72773  \ntime                                                                    \n2018-07-11        19.2         8.9        27.8         0.0      1018.6  \n2018-07-12        20.1         9.4        31.1         0.0      1017.7  \n2018-07-13        22.1        11.1        33.3         0.0      1016.3  \n2018-07-14        23.2        12.2        32.8         0.0      1015.7  \n2018-07-15        22.8        12.8        32.2         0.0      1016.9  \n...                ...         ...         ...         ...         ...  \n2023-06-12        18.1        14.4        27.2         3.6      1014.0  \n2023-06-13        19.9        11.7        30.0         1.5      1010.3  \n2023-06-14        18.7        12.2        21.7         0.0      1009.2  \n2023-06-15        14.5        10.0        18.9         0.0      1016.6  \n2023-06-16        14.7         6.1        25.0         0.0      1019.1  \n\n[1802 rows x 115 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tavg_72278</th>\n      <th>tmin_72278</th>\n      <th>tmax_72278</th>\n      <th>prcp_72278</th>\n      <th>pres_72278</th>\n      <th>tavg_72295</th>\n      <th>tmin_72295</th>\n      <th>tmax_72295</th>\n      <th>prcp_72295</th>\n      <th>pres_72295</th>\n      <th>...</th>\n      <th>tavg_72446</th>\n      <th>tmin_72446</th>\n      <th>tmax_72446</th>\n      <th>prcp_72446</th>\n      <th>pres_72446</th>\n      <th>tavg_72773</th>\n      <th>tmin_72773</th>\n      <th>tmax_72773</th>\n      <th>prcp_72773</th>\n      <th>pres_72773</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-07-11</th>\n      <td>30.4</td>\n      <td>26.1</td>\n      <td>38.3</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>23.8</td>\n      <td>21.7</td>\n      <td>26.7</td>\n      <td>0.0</td>\n      <td>1012.1</td>\n      <td>...</td>\n      <td>30.3</td>\n      <td>24.4</td>\n      <td>37.2</td>\n      <td>0.0</td>\n      <td>1016.2</td>\n      <td>19.2</td>\n      <td>8.9</td>\n      <td>27.8</td>\n      <td>0.0</td>\n      <td>1018.6</td>\n    </tr>\n    <tr>\n      <th>2018-07-12</th>\n      <td>30.7</td>\n      <td>25.6</td>\n      <td>38.9</td>\n      <td>0.0</td>\n      <td>1010.9</td>\n      <td>23.3</td>\n      <td>21.1</td>\n      <td>26.1</td>\n      <td>0.0</td>\n      <td>1013.8</td>\n      <td>...</td>\n      <td>30.6</td>\n      <td>24.4</td>\n      <td>37.8</td>\n      <td>0.0</td>\n      <td>1016.2</td>\n      <td>20.1</td>\n      <td>9.4</td>\n      <td>31.1</td>\n      <td>0.0</td>\n      <td>1017.7</td>\n    </tr>\n    <tr>\n      <th>2018-07-13</th>\n      <td>34.1</td>\n      <td>30.0</td>\n      <td>41.1</td>\n      <td>0.0</td>\n      <td>1010.8</td>\n      <td>22.2</td>\n      <td>20.6</td>\n      <td>24.4</td>\n      <td>0.0</td>\n      <td>1015.6</td>\n      <td>...</td>\n      <td>30.3</td>\n      <td>22.8</td>\n      <td>37.2</td>\n      <td>0.0</td>\n      <td>1015.4</td>\n      <td>22.1</td>\n      <td>11.1</td>\n      <td>33.3</td>\n      <td>0.0</td>\n      <td>1016.3</td>\n    </tr>\n    <tr>\n      <th>2018-07-14</th>\n      <td>34.6</td>\n      <td>30.6</td>\n      <td>39.4</td>\n      <td>0.0</td>\n      <td>1010.1</td>\n      <td>22.1</td>\n      <td>20.0</td>\n      <td>25.6</td>\n      <td>0.0</td>\n      <td>1014.5</td>\n      <td>...</td>\n      <td>26.8</td>\n      <td>22.2</td>\n      <td>31.7</td>\n      <td>0.5</td>\n      <td>1015.1</td>\n      <td>23.2</td>\n      <td>12.2</td>\n      <td>32.8</td>\n      <td>0.0</td>\n      <td>1015.7</td>\n    </tr>\n    <tr>\n      <th>2018-07-15</th>\n      <td>33.2</td>\n      <td>31.1</td>\n      <td>37.8</td>\n      <td>0.0</td>\n      <td>1010.1</td>\n      <td>22.7</td>\n      <td>20.6</td>\n      <td>25.6</td>\n      <td>0.0</td>\n      <td>1013.6</td>\n      <td>...</td>\n      <td>27.3</td>\n      <td>20.6</td>\n      <td>34.4</td>\n      <td>0.0</td>\n      <td>1014.5</td>\n      <td>22.8</td>\n      <td>12.8</td>\n      <td>32.2</td>\n      <td>0.0</td>\n      <td>1016.9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-06-12</th>\n      <td>27.7</td>\n      <td>21.7</td>\n      <td>33.9</td>\n      <td>0.0</td>\n      <td>1009.4</td>\n      <td>17.5</td>\n      <td>15.6</td>\n      <td>21.1</td>\n      <td>0.0</td>\n      <td>1016.6</td>\n      <td>...</td>\n      <td>17.6</td>\n      <td>10.6</td>\n      <td>23.3</td>\n      <td>0.0</td>\n      <td>1014.4</td>\n      <td>18.1</td>\n      <td>14.4</td>\n      <td>27.2</td>\n      <td>3.6</td>\n      <td>1014.0</td>\n    </tr>\n    <tr>\n      <th>2023-06-13</th>\n      <td>28.9</td>\n      <td>23.3</td>\n      <td>35.6</td>\n      <td>0.0</td>\n      <td>1009.2</td>\n      <td>17.4</td>\n      <td>15.6</td>\n      <td>20.6</td>\n      <td>0.0</td>\n      <td>1016.4</td>\n      <td>...</td>\n      <td>19.1</td>\n      <td>10.0</td>\n      <td>26.7</td>\n      <td>0.0</td>\n      <td>1010.8</td>\n      <td>19.9</td>\n      <td>11.7</td>\n      <td>30.0</td>\n      <td>1.5</td>\n      <td>1010.3</td>\n    </tr>\n    <tr>\n      <th>2023-06-14</th>\n      <td>30.4</td>\n      <td>23.3</td>\n      <td>38.3</td>\n      <td>0.0</td>\n      <td>1005.9</td>\n      <td>16.6</td>\n      <td>15.0</td>\n      <td>18.3</td>\n      <td>0.0</td>\n      <td>1013.9</td>\n      <td>...</td>\n      <td>21.9</td>\n      <td>13.3</td>\n      <td>29.4</td>\n      <td>0.0</td>\n      <td>1006.4</td>\n      <td>18.7</td>\n      <td>12.2</td>\n      <td>21.7</td>\n      <td>0.0</td>\n      <td>1009.2</td>\n    </tr>\n    <tr>\n      <th>2023-06-15</th>\n      <td>31.4</td>\n      <td>25.0</td>\n      <td>38.3</td>\n      <td>0.0</td>\n      <td>1006.0</td>\n      <td>17.2</td>\n      <td>16.1</td>\n      <td>19.4</td>\n      <td>0.0</td>\n      <td>1013.3</td>\n      <td>...</td>\n      <td>23.1</td>\n      <td>14.4</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>1007.8</td>\n      <td>14.5</td>\n      <td>10.0</td>\n      <td>18.9</td>\n      <td>0.0</td>\n      <td>1016.6</td>\n    </tr>\n    <tr>\n      <th>2023-06-16</th>\n      <td>32.4</td>\n      <td>24.4</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>1007.5</td>\n      <td>17.7</td>\n      <td>16.1</td>\n      <td>21.1</td>\n      <td>0.0</td>\n      <td>1014.7</td>\n      <td>...</td>\n      <td>25.3</td>\n      <td>16.7</td>\n      <td>31.1</td>\n      <td>0.0</td>\n      <td>1010.7</td>\n      <td>14.7</td>\n      <td>6.1</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>1019.1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1802 rows × 115 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(weather_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:27:33.912897Z",
     "end_time": "2023-07-12T10:27:33.937595Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "weather_df.reset_index(inplace=True)\n",
    "weather_df['Date'] = pd.to_datetime(weather_df['time']).dt.strftime('%Y-%m-%d 12:00:00')\n",
    "weather_df.drop(columns=['time'], inplace=True)\n",
    "weather_df.set_index('Date', inplace=True)\n",
    "weather_df.rename_axis('', inplace=True)\n",
    "weather_df.index = pd.to_datetime(weather_df.index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:27:34.785652Z",
     "end_time": "2023-07-12T10:27:34.815621Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "common_dates = master_data.index.intersection(weather_df.index)\n",
    "master_data = pd.concat([master_data.loc[common_dates], weather_df.loc[common_dates]], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:27:35.924941Z",
     "end_time": "2023-07-12T10:27:35.955452Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "                     ens(8)  ecmwf(9)  gfs(10,14)  cmc(9,14)  ens(9,14)  \\\n2018-07-11 12:00:00   0.003     0.024       0.039     -0.040      0.024   \n2018-07-12 12:00:00  -0.002     0.005       0.046     -0.053      0.023   \n2018-07-13 12:00:00   0.000     0.003       0.037     -0.048      0.029   \n2018-07-14 12:00:00  -0.001    -0.001       0.046     -0.053      0.027   \n2018-07-15 12:00:00   0.000     0.006       0.034     -0.039      0.033   \n...                     ...       ...         ...        ...        ...   \n2023-05-12 12:00:00  -1.098    -1.852       0.549     -2.337     14.607   \n2023-05-13 12:00:00  -0.563    -0.920       1.340      0.595     10.157   \n2023-05-14 12:00:00   0.210    -0.419       1.168     -2.417     10.311   \n2023-05-15 12:00:00  -0.080     1.089       1.291     -2.618      9.604   \n2023-05-16 12:00:00  -0.264    -0.769      -0.019     -1.419      8.413   \n\n                     tavg_72278  tmin_72278  tmax_72278  prcp_72278  \\\n2018-07-11 12:00:00        30.4        26.1        38.3         0.0   \n2018-07-12 12:00:00        30.7        25.6        38.9         0.0   \n2018-07-13 12:00:00        34.1        30.0        41.1         0.0   \n2018-07-14 12:00:00        34.6        30.6        39.4         0.0   \n2018-07-15 12:00:00        33.2        31.1        37.8         0.0   \n...                         ...         ...         ...         ...   \n2023-05-12 12:00:00        27.0        18.9        36.1         0.0   \n2023-05-13 12:00:00        29.3        21.7        37.8         0.0   \n2023-05-14 12:00:00        30.8        22.8        38.3         0.0   \n2023-05-15 12:00:00        32.2        25.6        39.4         0.0   \n2023-05-16 12:00:00        34.2        27.8        40.6         0.0   \n\n                     pres_72278  ...  tavg_72446  tmin_72446  tmax_72446  \\\n2018-07-11 12:00:00         NaN  ...        30.3        24.4        37.2   \n2018-07-12 12:00:00      1010.9  ...        30.6        24.4        37.8   \n2018-07-13 12:00:00      1010.8  ...        30.3        22.8        37.2   \n2018-07-14 12:00:00      1010.1  ...        26.8        22.2        31.7   \n2018-07-15 12:00:00      1010.1  ...        27.3        20.6        34.4   \n...                         ...  ...         ...         ...         ...   \n2023-05-12 12:00:00      1006.9  ...        21.9        18.9        27.8   \n2023-05-13 12:00:00      1005.1  ...        24.1        18.3        28.3   \n2023-05-14 12:00:00      1009.4  ...        23.7        16.7        30.6   \n2023-05-15 12:00:00      1012.6  ...        17.7        13.9        20.0   \n2023-05-16 12:00:00      1010.4  ...        15.4        13.3        21.7   \n\n                     prcp_72446  pres_72446  tavg_72773  tmin_72773  \\\n2018-07-11 12:00:00         0.0      1016.2        19.2         8.9   \n2018-07-12 12:00:00         0.0      1016.2        20.1         9.4   \n2018-07-13 12:00:00         0.0      1015.4        22.1        11.1   \n2018-07-14 12:00:00         0.5      1015.1        23.2        12.2   \n2018-07-15 12:00:00         0.0      1014.5        22.8        12.8   \n...                         ...         ...         ...         ...   \n2023-05-12 12:00:00         0.0      1010.6        13.6         4.4   \n2023-05-13 12:00:00         0.0      1014.5        16.0         6.1   \n2023-05-14 12:00:00         3.8      1019.9        17.9        12.2   \n2023-05-15 12:00:00        22.1      1022.3        20.2        12.2   \n2023-05-16 12:00:00         0.8      1016.4        17.9         8.9   \n\n                     tmax_72773  prcp_72773  pres_72773  \n2018-07-11 12:00:00        27.8         0.0      1018.6  \n2018-07-12 12:00:00        31.1         0.0      1017.7  \n2018-07-13 12:00:00        33.3         0.0      1016.3  \n2018-07-14 12:00:00        32.8         0.0      1015.7  \n2018-07-15 12:00:00        32.2         0.0      1016.9  \n...                         ...         ...         ...  \n2023-05-12 12:00:00        24.4         0.0      1025.1  \n2023-05-13 12:00:00        22.2         0.0      1029.3  \n2023-05-14 12:00:00        23.9         0.0      1026.5  \n2023-05-15 12:00:00        28.9         0.0      1020.7  \n2023-05-16 12:00:00        26.1         0.0      1019.1  \n\n[1749 rows x 120 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ens(8)</th>\n      <th>ecmwf(9)</th>\n      <th>gfs(10,14)</th>\n      <th>cmc(9,14)</th>\n      <th>ens(9,14)</th>\n      <th>tavg_72278</th>\n      <th>tmin_72278</th>\n      <th>tmax_72278</th>\n      <th>prcp_72278</th>\n      <th>pres_72278</th>\n      <th>...</th>\n      <th>tavg_72446</th>\n      <th>tmin_72446</th>\n      <th>tmax_72446</th>\n      <th>prcp_72446</th>\n      <th>pres_72446</th>\n      <th>tavg_72773</th>\n      <th>tmin_72773</th>\n      <th>tmax_72773</th>\n      <th>prcp_72773</th>\n      <th>pres_72773</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-07-11 12:00:00</th>\n      <td>0.003</td>\n      <td>0.024</td>\n      <td>0.039</td>\n      <td>-0.040</td>\n      <td>0.024</td>\n      <td>30.4</td>\n      <td>26.1</td>\n      <td>38.3</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>30.3</td>\n      <td>24.4</td>\n      <td>37.2</td>\n      <td>0.0</td>\n      <td>1016.2</td>\n      <td>19.2</td>\n      <td>8.9</td>\n      <td>27.8</td>\n      <td>0.0</td>\n      <td>1018.6</td>\n    </tr>\n    <tr>\n      <th>2018-07-12 12:00:00</th>\n      <td>-0.002</td>\n      <td>0.005</td>\n      <td>0.046</td>\n      <td>-0.053</td>\n      <td>0.023</td>\n      <td>30.7</td>\n      <td>25.6</td>\n      <td>38.9</td>\n      <td>0.0</td>\n      <td>1010.9</td>\n      <td>...</td>\n      <td>30.6</td>\n      <td>24.4</td>\n      <td>37.8</td>\n      <td>0.0</td>\n      <td>1016.2</td>\n      <td>20.1</td>\n      <td>9.4</td>\n      <td>31.1</td>\n      <td>0.0</td>\n      <td>1017.7</td>\n    </tr>\n    <tr>\n      <th>2018-07-13 12:00:00</th>\n      <td>0.000</td>\n      <td>0.003</td>\n      <td>0.037</td>\n      <td>-0.048</td>\n      <td>0.029</td>\n      <td>34.1</td>\n      <td>30.0</td>\n      <td>41.1</td>\n      <td>0.0</td>\n      <td>1010.8</td>\n      <td>...</td>\n      <td>30.3</td>\n      <td>22.8</td>\n      <td>37.2</td>\n      <td>0.0</td>\n      <td>1015.4</td>\n      <td>22.1</td>\n      <td>11.1</td>\n      <td>33.3</td>\n      <td>0.0</td>\n      <td>1016.3</td>\n    </tr>\n    <tr>\n      <th>2018-07-14 12:00:00</th>\n      <td>-0.001</td>\n      <td>-0.001</td>\n      <td>0.046</td>\n      <td>-0.053</td>\n      <td>0.027</td>\n      <td>34.6</td>\n      <td>30.6</td>\n      <td>39.4</td>\n      <td>0.0</td>\n      <td>1010.1</td>\n      <td>...</td>\n      <td>26.8</td>\n      <td>22.2</td>\n      <td>31.7</td>\n      <td>0.5</td>\n      <td>1015.1</td>\n      <td>23.2</td>\n      <td>12.2</td>\n      <td>32.8</td>\n      <td>0.0</td>\n      <td>1015.7</td>\n    </tr>\n    <tr>\n      <th>2018-07-15 12:00:00</th>\n      <td>0.000</td>\n      <td>0.006</td>\n      <td>0.034</td>\n      <td>-0.039</td>\n      <td>0.033</td>\n      <td>33.2</td>\n      <td>31.1</td>\n      <td>37.8</td>\n      <td>0.0</td>\n      <td>1010.1</td>\n      <td>...</td>\n      <td>27.3</td>\n      <td>20.6</td>\n      <td>34.4</td>\n      <td>0.0</td>\n      <td>1014.5</td>\n      <td>22.8</td>\n      <td>12.8</td>\n      <td>32.2</td>\n      <td>0.0</td>\n      <td>1016.9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-05-12 12:00:00</th>\n      <td>-1.098</td>\n      <td>-1.852</td>\n      <td>0.549</td>\n      <td>-2.337</td>\n      <td>14.607</td>\n      <td>27.0</td>\n      <td>18.9</td>\n      <td>36.1</td>\n      <td>0.0</td>\n      <td>1006.9</td>\n      <td>...</td>\n      <td>21.9</td>\n      <td>18.9</td>\n      <td>27.8</td>\n      <td>0.0</td>\n      <td>1010.6</td>\n      <td>13.6</td>\n      <td>4.4</td>\n      <td>24.4</td>\n      <td>0.0</td>\n      <td>1025.1</td>\n    </tr>\n    <tr>\n      <th>2023-05-13 12:00:00</th>\n      <td>-0.563</td>\n      <td>-0.920</td>\n      <td>1.340</td>\n      <td>0.595</td>\n      <td>10.157</td>\n      <td>29.3</td>\n      <td>21.7</td>\n      <td>37.8</td>\n      <td>0.0</td>\n      <td>1005.1</td>\n      <td>...</td>\n      <td>24.1</td>\n      <td>18.3</td>\n      <td>28.3</td>\n      <td>0.0</td>\n      <td>1014.5</td>\n      <td>16.0</td>\n      <td>6.1</td>\n      <td>22.2</td>\n      <td>0.0</td>\n      <td>1029.3</td>\n    </tr>\n    <tr>\n      <th>2023-05-14 12:00:00</th>\n      <td>0.210</td>\n      <td>-0.419</td>\n      <td>1.168</td>\n      <td>-2.417</td>\n      <td>10.311</td>\n      <td>30.8</td>\n      <td>22.8</td>\n      <td>38.3</td>\n      <td>0.0</td>\n      <td>1009.4</td>\n      <td>...</td>\n      <td>23.7</td>\n      <td>16.7</td>\n      <td>30.6</td>\n      <td>3.8</td>\n      <td>1019.9</td>\n      <td>17.9</td>\n      <td>12.2</td>\n      <td>23.9</td>\n      <td>0.0</td>\n      <td>1026.5</td>\n    </tr>\n    <tr>\n      <th>2023-05-15 12:00:00</th>\n      <td>-0.080</td>\n      <td>1.089</td>\n      <td>1.291</td>\n      <td>-2.618</td>\n      <td>9.604</td>\n      <td>32.2</td>\n      <td>25.6</td>\n      <td>39.4</td>\n      <td>0.0</td>\n      <td>1012.6</td>\n      <td>...</td>\n      <td>17.7</td>\n      <td>13.9</td>\n      <td>20.0</td>\n      <td>22.1</td>\n      <td>1022.3</td>\n      <td>20.2</td>\n      <td>12.2</td>\n      <td>28.9</td>\n      <td>0.0</td>\n      <td>1020.7</td>\n    </tr>\n    <tr>\n      <th>2023-05-16 12:00:00</th>\n      <td>-0.264</td>\n      <td>-0.769</td>\n      <td>-0.019</td>\n      <td>-1.419</td>\n      <td>8.413</td>\n      <td>34.2</td>\n      <td>27.8</td>\n      <td>40.6</td>\n      <td>0.0</td>\n      <td>1010.4</td>\n      <td>...</td>\n      <td>15.4</td>\n      <td>13.3</td>\n      <td>21.7</td>\n      <td>0.8</td>\n      <td>1016.4</td>\n      <td>17.9</td>\n      <td>8.9</td>\n      <td>26.1</td>\n      <td>0.0</td>\n      <td>1019.1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1749 rows × 120 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(master_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:27:38.008041Z",
     "end_time": "2023-07-12T10:27:38.018700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T13:19:56.937073Z",
     "end_time": "2023-07-11T13:19:56.945736Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T13:20:59.336658Z",
     "end_time": "2023-07-11T13:20:59.346966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T12:59:06.989965Z",
     "end_time": "2023-07-11T12:59:07.013626Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
