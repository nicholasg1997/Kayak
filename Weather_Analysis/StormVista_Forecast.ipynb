{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-07-06T15:31:33.403016Z",
     "end_time": "2023-07-06T15:31:33.418765Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from datetime import datetime, time\n",
    "import glob\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def display_errors(y_true, y_pred, return_vals=False):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    print(f\"MSE: {round(mse, 3)}\")\n",
    "    rmse = mse ** 0.5\n",
    "    print(f\"RMSE: {round(rmse, 3)}\")\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"MAE: {round(mae, 3)}\")\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    print(f\"MAPE: {round(mape, 3)}\")\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"R2: {round(r2, 3)}\")\n",
    "\n",
    "    if return_vals:\n",
    "        return [mse, rmse, mae, mape, r2]\n",
    "\n",
    "def plot_errors(y_true, y_pred, name='N/A'):\n",
    "    plt.scatter(y_true, y_pred, color='blue', marker='o', label=f'error adjusted predictions ({name}) vs actual degree days')\n",
    "    plt.xlabel('actual degree days')\n",
    "    plt.ylabel('predicted degree days')\n",
    "    plt.title(f'Prediction vs Actual ({name})')\n",
    "\n",
    "    max_value = max(max(y_true[-225:]), max(y_true[-225:]))\n",
    "    min_value = min(min(y_true[-225:]), min(y_true[-225:]))\n",
    "    plt.plot([min_value, max_value], [min_value, max_value], color='red', linestyle='--', label='Line of Equality')\n",
    "\n",
    "    plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T13:24:12.883345Z",
     "end_time": "2023-07-06T13:24:12.884846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "class LinReg:\n",
    "    def __init__(self, train_data, test_data, target_col):\n",
    "        self.X_train = train_data.drop(columns=[target_col])\n",
    "        self.y_train = train_data[target_col]\n",
    "        self.X_test = test_data.drop(columns=[target_col])\n",
    "        self.y_test = test_data[target_col]\n",
    "        self.target_col = target_col\n",
    "        self.model = LinearRegression().fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "        self.evaluate()\n",
    "\n",
    "    def evaluate(self):\n",
    "        display_errors(self.y_test, self.y_pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T15:37:07.305879Z",
     "end_time": "2023-07-06T15:37:07.318424Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def extract_date_time(filename):\n",
    "    \"\"\"\n",
    "    extract the date and time from the filename\n",
    "    :param filename:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    parts = filename.split('.')\n",
    "    extracted_date = parts[1]\n",
    "    extracted_time = parts[2]\n",
    "    return extracted_date, extracted_time\n",
    "\n",
    "def get_date(file):\n",
    "        \"\"\"get the date from the dataframe and the time from the filename and combine them into a datetime object\n",
    "        :param file: filename containing the time\n",
    "        :return: datetime object\n",
    "        \"\"\"\n",
    "\n",
    "        date_str = str(file.split('.')[1])\n",
    "        time_str = str(file.split('.')[2])\n",
    "        date_value = datetime.strptime(date_str, '%Y%m%d')\n",
    "        time_value = time(int(time_str), 0)\n",
    "        combined_datetime = datetime.combine(date_value.date(), time_value)\n",
    "        return combined_datetime\n",
    "#give type hint on start_date that it should be a string\n",
    "def seasonal_train_test(data, start_date: str, end_date: str):\n",
    "    \"\"\"\n",
    "    split the data into train and test sets based on dates\n",
    "    :param data: dataframe containing the data\n",
    "    :param start_date: start date of the test set\n",
    "    :param end_date: end date of the test set\n",
    "    :return: train and test sets\n",
    "    \"\"\"\n",
    "\n",
    "    test_start = start_date\n",
    "    test_end = end_date\n",
    "    test_data = data.loc[test_start: test_end]\n",
    "\n",
    "    #remove X_test from dataframe to get X_train\n",
    "    mask = (data.index >= test_start) & (data.index <= test_end)\n",
    "    train_data = data.loc[~mask]\n",
    "\n",
    "    return train_data, test_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T14:48:56.864799Z",
     "end_time": "2023-07-06T14:48:56.871448Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class RawDataProcess:\n",
    "    def __init__(self, degree_days='gw_hdd', path='RawData', time=None):\n",
    "        self.degree_days = degree_days\n",
    "        self.path = path\n",
    "        self.sort_files()\n",
    "        self.get_master_model()\n",
    "        if time is not None:\n",
    "            self.filter_time(time)\n",
    "\n",
    "\n",
    "    def filter_time(self, time):\n",
    "        data = self.master_data\n",
    "        data['hour'] = data.index.hour\n",
    "        data = data[data['hour'] == time]\n",
    "        data.drop('hour', axis=1, inplace=True)\n",
    "        self.master_data = data\n",
    "\n",
    "    def sort_files(self):\n",
    "        \"\"\"\n",
    "        sort the files in the directory by date and time\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        degree_days = self.degree_days\n",
    "        path = self.path\n",
    "\n",
    "        degree_days = degree_days\n",
    "        ecmwf_files = glob.glob(path + f'/ecmwf.*.[01][02].{degree_days}.csv')\n",
    "        ecmwf_sorted_files = sorted(ecmwf_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[3:]\n",
    "\n",
    "        ecmwf_ens_files = glob.glob(path + f'/ecmwf-eps.*.[01][02].{degree_days}.csv')\n",
    "        ecmwf_ens_sorted_files = sorted(ecmwf_ens_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "\n",
    "        gfs_ens_bc_files = glob.glob(path + f'/gfs-ens-bc.*.[01][02].{degree_days}.csv')\n",
    "        gfs_ens_bc_sorted_files = sorted(gfs_ens_bc_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "\n",
    "        cmc_ens_files = glob.glob(path + f'/cmc-ens.*.[01][02].{degree_days}.csv')\n",
    "        cmc_ens_sorted_files = sorted(cmc_ens_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "        for _ in range(2):\n",
    "            set1 = set((extract_date_time(filename) for filename in ecmwf_sorted_files))\n",
    "            set2 = set((extract_date_time(filename) for filename in ecmwf_ens_sorted_files))\n",
    "\n",
    "            ecmwf_sorted_files = [filename for filename in ecmwf_sorted_files if extract_date_time(filename) in set2]\n",
    "            ecmwf_ens_sorted_files = [filename for filename in ecmwf_ens_sorted_files if\n",
    "                                      extract_date_time(filename) in set1]\n",
    "            cmc_ens_sorted_files = [filename for filename in cmc_ens_sorted_files if extract_date_time(filename) in set1]\n",
    "\n",
    "            master_set = set((extract_date_time(filename) for filename in cmc_ens_sorted_files))\n",
    "            gfs_ens_bc_sorted_files = [filename for filename in gfs_ens_bc_sorted_files if\n",
    "                                       extract_date_time(filename) in master_set]\n",
    "\n",
    "            master_set = set((extract_date_time(filename) for filename in gfs_ens_bc_sorted_files))\n",
    "\n",
    "            ecmwf_sorted_files = [filename for filename in ecmwf_sorted_files if extract_date_time(filename) in master_set]\n",
    "            ecmwf_ens_sorted_files = [filename for filename in ecmwf_ens_sorted_files if\n",
    "                                      extract_date_time(filename) in master_set]\n",
    "            gfs_ens_bc_sorted_files = [filename for filename in gfs_ens_bc_sorted_files if\n",
    "                                       extract_date_time(filename) in master_set]\n",
    "            cmc_ens_sorted_files = [filename for filename in cmc_ens_sorted_files if\n",
    "                                    extract_date_time(filename) in master_set]\n",
    "\n",
    "        self.ecmwf_sorted_files = ecmwf_sorted_files\n",
    "        self.ecmwf_ens_sorted_files = ecmwf_ens_sorted_files\n",
    "        self.gfs_ens_bc_sorted_files = gfs_ens_bc_sorted_files\n",
    "        self.cmc_ens_sorted_files = cmc_ens_sorted_files\n",
    "\n",
    "    def y_value(self, start=8, end=14):\n",
    "        ecmwf_ens_9_14 = pd.DataFrame(columns=[f'ens({start+1},{end})'])\n",
    "\n",
    "        ecmwf_ens_sorted_files = self.ecmwf_ens_sorted_files\n",
    "\n",
    "        for i in range(1, len(ecmwf_ens_sorted_files)):\n",
    "            ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i])\n",
    "            ecmwf_ens_df = ecmwf_ens_df[ecmwf_ens_df[ecmwf_ens_df.columns[2]] >= 1]\n",
    "            prev_ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i - 1])\n",
    "            prev_ecmwf_ens_df = prev_ecmwf_ens_df[prev_ecmwf_ens_df[prev_ecmwf_ens_df.columns[2]] >= 1]\n",
    "\n",
    "            date = get_date(ecmwf_ens_sorted_files[i])\n",
    "            prev_date = get_date(ecmwf_ens_sorted_files[i - 1])\n",
    "            d2 = str(date)[:10]\n",
    "            d1 = str(prev_date)[:10]\n",
    "\n",
    "            if d2 == d1:\n",
    "                offset = 1\n",
    "            else:\n",
    "                offset = 0\n",
    "\n",
    "            cur = ecmwf_ens_df['Value'].iloc[start:end].sum()\n",
    "            prev = prev_ecmwf_ens_df['Value'].iloc[(start+offset):(end+offset)].sum()\n",
    "            change = cur - prev\n",
    "\n",
    "            new_row = pd.DataFrame(change, columns=ecmwf_ens_9_14.columns, index=[date])\n",
    "            ecmwf_ens_9_14 = pd.concat([ecmwf_ens_9_14, new_row])\n",
    "\n",
    "        self.y_values = ecmwf_ens_9_14\n",
    "\n",
    "    def ecmwf_ens(self, start=7, end=8):\n",
    "        ecmwf_ens_8 = pd.DataFrame(columns=[f'ens({end})'])\n",
    "        ecmwf_ens_sorted_files = self.ecmwf_ens_sorted_files\n",
    "\n",
    "        for i in range(1, len(ecmwf_ens_sorted_files)):\n",
    "            ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i])\n",
    "            ecmwf_ens_df = ecmwf_ens_df[ecmwf_ens_df[ecmwf_ens_df.columns[2]] >= 1]\n",
    "            prev_ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i - 1])\n",
    "            prev_ecmwf_ens_df = prev_ecmwf_ens_df[prev_ecmwf_ens_df[prev_ecmwf_ens_df.columns[2]] >= 1]\n",
    "\n",
    "            date = get_date(ecmwf_ens_sorted_files[i])\n",
    "            prev_date = get_date(ecmwf_ens_sorted_files[i - 1])\n",
    "            d2 = str(date)[:10]\n",
    "            d1 = str(prev_date)[:10]\n",
    "\n",
    "            if d2 == d1:\n",
    "                offset = 1\n",
    "            else:\n",
    "                offset = 0\n",
    "\n",
    "            cur = ecmwf_ens_df['Value'].iloc[start:end].sum() #7-8 benchmark, 7-8 best results\n",
    "            prev = prev_ecmwf_ens_df['Value'].iloc[(start+offset):(end+offset)].sum() #7-8 benchmark, 7-8 best results\n",
    "            change = cur - prev\n",
    "\n",
    "            new_row = pd.DataFrame(change, columns=ecmwf_ens_8.columns, index=[date])\n",
    "            ecmwf_ens_8 = pd.concat([ecmwf_ens_8, new_row])\n",
    "\n",
    "        self.ecmwf_ens_data = ecmwf_ens_8\n",
    "\n",
    "    def ecmwf(self, start=8, end=9):\n",
    "\n",
    "        ecmwf_9_10 = pd.DataFrame(columns=[f'ecmwf({end})'])\n",
    "\n",
    "        ecmwf_sorted_files = self.ecmwf_sorted_files\n",
    "        ecmwf_ens_sorted_files = self.ecmwf_ens_sorted_files\n",
    "\n",
    "\n",
    "        for i in range(1, len(ecmwf_sorted_files)):\n",
    "            ecmwf_df = pd.read_csv(ecmwf_sorted_files[i])\n",
    "            ecmwf_df = ecmwf_df[ecmwf_df[ecmwf_df.columns[2]] >= 1]\n",
    "            prev_ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i-1])\n",
    "            prev_ecmwf_ens_df = prev_ecmwf_ens_df[prev_ecmwf_ens_df[prev_ecmwf_ens_df.columns[2]] >= 1]\n",
    "\n",
    "            date = get_date(ecmwf_sorted_files[i])\n",
    "            prev_date = get_date(ecmwf_sorted_files[i - 1])\n",
    "            d2 = str(date)[:10]\n",
    "            d1 = str(prev_date)[:10]\n",
    "\n",
    "            if d2 == d1:\n",
    "                offset = 1\n",
    "            else:\n",
    "                offset = 0\n",
    "\n",
    "            cur = ecmwf_df['Value'].iloc[start:end].sum() #8-9 benchmark, 4-9 best results\n",
    "            prev = prev_ecmwf_ens_df['Value'].iloc[(start+offset):(end+offset)].sum() #8-9 benchmark, 4-9 best results\n",
    "\n",
    "            change = cur - prev\n",
    "\n",
    "            new_row = pd.DataFrame(change, columns=ecmwf_9_10.columns, index=[date])\n",
    "            ecmwf_9_10 = pd.concat([ecmwf_9_10, new_row])\n",
    "\n",
    "        self.ecmwf_data = ecmwf_9_10\n",
    "\n",
    "    def gfs(self, start=9, end=14):\n",
    "        gfs_11_14 = pd.DataFrame(columns=[f'gfs({start+1},{end})'])\n",
    "\n",
    "        ecmwf_ens_sorted_files = self.ecmwf_ens_sorted_files\n",
    "        gfs_ens_bc_sorted_files = self.gfs_ens_bc_sorted_files\n",
    "\n",
    "        for i in range(1, len(gfs_ens_bc_sorted_files)):\n",
    "            gfs_df = pd.read_csv(gfs_ens_bc_sorted_files[i])\n",
    "            gfs_df = gfs_df[gfs_df[gfs_df.columns[2]] >= 1]\n",
    "            prev_ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i-1])\n",
    "            prev_ecmwf_ens_df = prev_ecmwf_ens_df[prev_ecmwf_ens_df[prev_ecmwf_ens_df.columns[2]] >= 1]\n",
    "\n",
    "            date = get_date(gfs_ens_bc_sorted_files[i])\n",
    "            prev_date = get_date(ecmwf_ens_sorted_files[i - 1])\n",
    "            d2 = str(date)[:10]\n",
    "            d1 = str(prev_date)[:10]\n",
    "\n",
    "            if d2 == d1:\n",
    "                offset = 1\n",
    "            else:\n",
    "                offset = 0\n",
    "\n",
    "            cur = gfs_df['Value'].iloc[start:end].sum() # 9-14 benchmark, 9-16 best results\n",
    "            prev = prev_ecmwf_ens_df['Value'].iloc[(start+offset):(end+offset)].sum() # 9-14 benchmark, 9-16 best results\n",
    "\n",
    "            change = cur - prev\n",
    "\n",
    "            new_row = pd.DataFrame(change, columns=gfs_11_14.columns, index=[date])\n",
    "            gfs_11_14 = pd.concat([gfs_11_14, new_row])\n",
    "\n",
    "        self.gfs_data = gfs_11_14\n",
    "\n",
    "    def cmc(self, start=8, end=14):\n",
    "        cmc_9_14 = pd.DataFrame(columns=[f'cmc({start+1},{end})'])\n",
    "\n",
    "        cmc_ens_sorted_files = self.cmc_ens_sorted_files\n",
    "        gfs_ens_bc_sorted_files = self.gfs_ens_bc_sorted_files\n",
    "\n",
    "        for i in range(1, len(cmc_ens_sorted_files)):\n",
    "            cmc_df = pd.read_csv(cmc_ens_sorted_files[i])\n",
    "            cmc_df = cmc_df[cmc_df[cmc_df.columns[2]] >= 1]\n",
    "            gfs_df = pd.read_csv(gfs_ens_bc_sorted_files[i])\n",
    "            gfs_df = gfs_df[gfs_df[gfs_df.columns[2]] >= 1]\n",
    "\n",
    "            date = get_date(cmc_ens_sorted_files[i])\n",
    "\n",
    "            cmc = cmc_df['Value'].iloc[start:end].sum() #8-14 benchmark, 8-14 best results\n",
    "            gfs = gfs_df['Value'].iloc[start:end].sum() #8-14 benchmark, 8-14 best results\n",
    "            change = cmc - gfs\n",
    "\n",
    "            new_row = pd.DataFrame(change, columns=cmc_9_14.columns, index=[date])\n",
    "            cmc_9_14 = pd.concat([cmc_9_14, new_row])\n",
    "\n",
    "        self.cmc_data = cmc_9_14\n",
    "\n",
    "    def norm(self):\n",
    "        norms = pd.DataFrame(columns=['Date', 'Value'])\n",
    "        ecmwf_ens_sorted_files = self.ecmwf_ens_sorted_files\n",
    "\n",
    "        for i in range(1, len(ecmwf_ens_sorted_files), 2):\n",
    "            ecmwf_ens_df = pd.read_csv(ecmwf_ens_sorted_files[i])\n",
    "            v1 = ecmwf_ens_df[ecmwf_ens_df[ecmwf_ens_df.columns[2]] == 2].iloc[:, :2]\n",
    "            norms = pd.concat([norms, v1]).drop_duplicates('Date')\n",
    "\n",
    "        norms.reset_index(inplace=True)\n",
    "        norms.drop(columns=['index'], inplace=True)\n",
    "        norms['Date'] = pd.to_datetime(norms['Date']).dt.strftime('%Y-%m-%d 12:00:00')\n",
    "        norms.set_index('Date', inplace=True)\n",
    "        norms.rename_axis('', inplace=True)\n",
    "        norms.rename(columns={'Value': 'norm'}, inplace=True)\n",
    "\n",
    "        self.norms_data = norms\n",
    "\n",
    "    def run_all_models(self):\n",
    "        self.y_value()\n",
    "        self.ecmwf_ens()\n",
    "        self.ecmwf()\n",
    "        self.gfs()\n",
    "        self.cmc()\n",
    "        self.norm()\n",
    "\n",
    "    def get_master_model(self):\n",
    "        self.run_all_models()\n",
    "        master_data = pd.concat([self.ecmwf_ens_data, self.ecmwf_data,\n",
    "                                 self.gfs_data, self.cmc_data, self.y_values], axis=1)\n",
    "\n",
    "        self.master_data = master_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T14:00:06.509173Z",
     "end_time": "2023-07-06T14:00:06.512703Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3y/4qthl0m139n7983g0dhsq1n00000gn/T/ipykernel_12233/2837814191.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop('hour', axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data = RawDataProcess(degree_days='gw_hdd', path='RawData', time=12)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T14:04:31.138949Z",
     "end_time": "2023-07-06T14:05:09.523865Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "master_data = data.master_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T14:06:33.937969Z",
     "end_time": "2023-07-06T14:06:33.946250Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "train_data, test_data = seasonal_train_test(master_data, '2021-10-04 12:00:00', '2022-5-16 12:00:00')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T14:49:44.571733Z",
     "end_time": "2023-07-06T14:49:44.581114Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "train_data = TabularDataset(train_data)\n",
    "test_data = TabularDataset(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T14:51:02.282048Z",
     "end_time": "2023-07-06T14:51:02.297413Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "label = 'ens(9,14)'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T14:52:39.084628Z",
     "end_time": "2023-07-06T14:52:39.101335Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "y_test = test_data[label]\n",
    "test_data_nolabel = test_data.drop(columns=[label])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T14:53:29.753606Z",
     "end_time": "2023-07-06T14:53:29.774864Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230706_205434/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230706_205434/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:19 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T8103\n",
      "Train Data Rows:    1524\n",
      "Train Data Columns: 4\n",
      "Label Column: ens(9,14)\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (18.34899999999999, -21.283999999999992, 0.35771, 3.84261)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1265.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['ens(8)', 'ecmwf(9)', 'gfs(10,14)', 'cmc(9,14)']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['ens(8)', 'ecmwf(9)', 'gfs(10,14)', 'cmc(9,14)']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-3.7739\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-3.7763\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tWill use sequential fold fitting strategy because Darwin OS does not yet support parallel folding.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-3.6164\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3.4258\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.17s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-3.5631\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "\t-3.3503\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.06s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3.5554\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3.3295\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.18s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-3.3082\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-3.3693\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3.3343\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-3.342\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "\t-3.2689\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.21s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3.4043\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.82s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-3.277\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.34s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/nickgault/opt/miniconda3/envs/Kayak/lib/python3.10/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-3.2305\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 58.07s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230706_205434/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data, presets='best_quality')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T14:54:34.867222Z",
     "end_time": "2023-07-06T14:55:32.962084Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 20.752\n",
      "RMSE: 4.555\n",
      "MAE: 3.472\n",
      "MAPE: 1.55\n",
      "R2: 0.259\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolabel)\n",
    "display_errors(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T14:57:15.802681Z",
     "end_time": "2023-07-06T14:57:16.467184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 20.279\n",
      "RMSE: 4.503\n",
      "MAE: 3.483\n",
      "MAPE: 1.355\n",
      "R2: 0.276\n"
     ]
    }
   ],
   "source": [
    "linreg = LinReg(train_data, test_data, label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T15:37:16.448277Z",
     "end_time": "2023-07-06T15:37:16.461632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T15:38:09.881801Z",
     "end_time": "2023-07-06T15:38:09.893167Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T15:38:10.070735Z",
     "end_time": "2023-07-06T15:38:10.083660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T15:38:10.589271Z",
     "end_time": "2023-07-06T15:38:10.598372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
