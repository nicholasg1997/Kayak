{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    " use neural network to predict the change in the ecmwf-eps from the previous cycle run 12 hours ago for days 9-14\n",
    " ### current model features\n",
    "- the difference between the new ecmwf forecast for day 9 and the previous emcwf-eps forecast for day 9[x]\n",
    "- the difference between the new emcwf-eps forecast for day 8 and the previous emcwf-eps forecast for day 8[x]\n",
    "- the difference between the new gfs-ens-bc forecast for days 9-14 and the previous emcwf-eps forecast for days 9-14[x]\n",
    "- the difference between the new cmc-ens forecast for days 9-14 and the new gfs-ens-bc  forecast for days 9-14[x]\n",
    "\n",
    "### new feature ideas\n",
    "- rain data\n",
    "- wind data\n",
    "- past errors\n",
    "- ???"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "from meteostat import Stations, Daily"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:12.149884Z",
     "end_time": "2023-06-01T12:29:12.168234Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:13.374708Z",
     "end_time": "2023-06-01T12:29:13.386441Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"RawData\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:16.806513Z",
     "end_time": "2023-06-01T12:29:16.817787Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_date_time(filename):\n",
    "    \"\"\"\n",
    "    extract the date and time from the filename\n",
    "    :param filename:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    parts = filename.split('.')\n",
    "    date = parts[1]\n",
    "    time = parts[2]\n",
    "    return date, time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:16.961040Z",
     "end_time": "2023-06-01T12:29:16.970916Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_date(df, file):\n",
    "    \"\"\"get the date from the dataframe and the time from the filename and combine them into a datetime object\n",
    "    :param df: dataframe containing the date\n",
    "    :param file: filename containing the time\n",
    "    :return: datetime object\n",
    "    \"\"\"\n",
    "    #date_str = df[df.iloc[:, 2] == 1].iloc[0]['Date']\n",
    "    date_str = str(file.split('.')[1])\n",
    "    time_str = str(file.split('.')[2])\n",
    "    #date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    date = datetime.strptime(date_str, '%Y%m%d')\n",
    "    time_value = time(int(time_str), 0)\n",
    "    combined_datetime = datetime.combine(date.date(), time_value)\n",
    "    return combined_datetime"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:17.206244Z",
     "end_time": "2023-06-01T12:29:17.215011Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "degree_days = 'gw_hdd'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:17.581539Z",
     "end_time": "2023-06-01T12:29:17.593153Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ecmwf_files = glob.glob(path + f'/ecmwf.*.[01][02].{degree_days}.csv')\n",
    "ecmwf_sorted_files = sorted(ecmwf_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[3:]\n",
    "\n",
    "ecmwf_eps_files = glob.glob(path + f'/ecmwf-eps.*.[01][02].{degree_days}.csv')\n",
    "ecmwf_eps_sorted_files = sorted(ecmwf_eps_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "\n",
    "gfs_ens_bc_files = glob.glob(path + f'/gfs-ens-bc.*.[01][02].{degree_days}.csv')\n",
    "gfs_ens_bc_sorted_files = sorted(gfs_ens_bc_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]\n",
    "\n",
    "cmc_ens_files = glob.glob(path + f'/cmc-ens.*.[01][02].{degree_days}.csv')\n",
    "cmc_ens_sorted_files = sorted(cmc_ens_files, key=lambda x: (x.split('.')[1], x.split('.')[2]))[2:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:17.954114Z",
     "end_time": "2023-06-01T12:29:18.392367Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    set1 = set((extract_date_time(filename) for filename in ecmwf_sorted_files))\n",
    "    set2 = set((extract_date_time(filename) for filename in ecmwf_eps_sorted_files))\n",
    "\n",
    "    ecmwf_sorted_files = [filename for filename in ecmwf_sorted_files if extract_date_time(filename) in set2]\n",
    "    ecmwf_eps_sorted_files = [filename for filename in ecmwf_eps_sorted_files if extract_date_time(filename) in set1]\n",
    "    cmc_ens_sorted_files = [filename for filename in cmc_ens_sorted_files if extract_date_time(filename) in set1]\n",
    "\n",
    "    master_set = set((extract_date_time(filename) for filename in cmc_ens_sorted_files))\n",
    "    gfs_ens_bc_sorted_files = [filename for filename in gfs_ens_bc_sorted_files if extract_date_time(filename) in master_set]\n",
    "\n",
    "    master_set = set((extract_date_time(filename) for filename in gfs_ens_bc_sorted_files))\n",
    "\n",
    "    ecmwf_sorted_files = [filename for filename in ecmwf_sorted_files if extract_date_time(filename) in master_set]\n",
    "    ecmwf_eps_sorted_files = [filename for filename in ecmwf_eps_sorted_files if extract_date_time(filename) in master_set]\n",
    "    gfs_ens_bc_sorted_files = [filename for filename in gfs_ens_bc_sorted_files if extract_date_time(filename) in master_set]\n",
    "    cmc_ens_sorted_files = [filename for filename in cmc_ens_sorted_files if extract_date_time(filename) in master_set]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:18.433790Z",
     "end_time": "2023-06-01T12:29:18.435427Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:18.559928Z",
     "end_time": "2023-06-01T12:29:18.570475Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:18.812285Z",
     "end_time": "2023-06-01T12:29:18.822947Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(ecmwf_sorted_files))\n",
    "print(len(ecmwf_eps_sorted_files))\n",
    "print(len(gfs_ens_bc_sorted_files))\n",
    "print(len(cmc_ens_sorted_files))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:19.074160Z",
     "end_time": "2023-06-01T12:29:19.083479Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:19.286314Z",
     "end_time": "2023-06-01T12:29:19.303600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### step 1 get changes in ecmwf-eps compared to 12 hours ago for days 9-14"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:19.619886Z",
     "end_time": "2023-06-01T12:29:19.633043Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ecmwf_eps_change_df = pd.DataFrame(columns=['ecmwf-eps_9', 'ecmwf-eps_10', 'ecmwf-eps_11', 'ecmwf-eps_12',\n",
    "                                  'ecmwf-eps_13', 'ecmwf-eps_14'])\n",
    "\n",
    "for i in range(1, len(ecmwf_eps_sorted_files)):\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i])\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "    date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i])\n",
    "    prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    changes = []\n",
    "    for day in range(8, 14):\n",
    "        changes.append(ecmwf_eps_df.iloc[day - offset]['Value'] - prev_ecmwf_eps_df.iloc[day]['Value'])\n",
    "    new_row = pd.DataFrame([changes], columns=ecmwf_eps_change_df.columns, index=[date])\n",
    "    ecmwf_eps_change_df = pd.concat([ecmwf_eps_change_df, new_row])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:19.849357Z",
     "end_time": "2023-06-01T12:29:27.641885Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:27.642664Z",
     "end_time": "2023-06-01T12:29:27.644528Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:27.645019Z",
     "end_time": "2023-06-01T12:29:27.646908Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## step 2 recreate model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### step 2.1 get difference between the new ecmwf forecast for day 9 and the previous ecmwf-eps forecast for day 9"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### problems:\n",
    "- not all dates are in both sets of data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ecmwf_change_df = pd.DataFrame(columns=['ecmwf_diff_8', 'ecmwf_diff_9',])\n",
    "for i in range(1, len(ecmwf_sorted_files)):\n",
    "    ecmwf_df = pd.read_csv(ecmwf_sorted_files[i])\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1]) #one day behind\n",
    "\n",
    "    ecmwf = ecmwf_df.iloc[8]\n",
    "    ecmwf_eps = ecmwf_eps_df.iloc[9]\n",
    "\n",
    "    date = get_date(ecmwf_df, ecmwf_sorted_files[i])\n",
    "    prev_date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    changes = []\n",
    "    for day in range(8,10):\n",
    "        changes.append(ecmwf_df.iloc[day - offset]['Value'] - ecmwf_eps_df.iloc[day]['Value'])\n",
    "    new_row = pd.DataFrame([changes], columns=ecmwf_change_df.columns, index=[date])\n",
    "    ecmwf_change_df = pd.concat([ecmwf_change_df, new_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:27.651894Z",
     "end_time": "2023-06-01T12:29:33.574478Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#ecmwf_change_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:33.575443Z",
     "end_time": "2023-06-01T12:29:33.577398Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### step 2.2 the difference between the new emcwf-eps forecast for day 8 and the previous emcwf-eps forecast for day 8 (not possible as the new ecmwf-eps forecast is not available because it will not be released yet???)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T09:12:57.677758Z",
     "end_time": "2023-05-25T09:12:57.679902Z"
    }
   },
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "### step 2.3 the difference between the new gfs-ens-bc forecast for days 9-14 and the previous emcwf-eps forecast for days 9-14"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T09:13:18.790030Z",
     "end_time": "2023-05-25T09:13:18.796732Z"
    }
   },
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gfs_ens_bc_change_df = pd.DataFrame(columns=['gfs-ens-bc_9', 'gfs-ens-bc_10', 'gfs-ens-bc_11', 'gfs-ens-bc_12',\n",
    "                                  'gfs-ens-bc_13', 'gfs-ens-bc_14'])\n",
    "\n",
    "for i in range(1, len(gfs_ens_bc_sorted_files)):\n",
    "    gfs_ens_bc_df = pd.read_csv(gfs_ens_bc_sorted_files[i])\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "\n",
    "    date = get_date(gfs_ens_bc_df, gfs_ens_bc_sorted_files[i])\n",
    "    prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    changes = []\n",
    "    for day in range(8, 14):\n",
    "        changes.append(gfs_ens_bc_df.iloc[day - offset]['Value'] - prev_ecmwf_eps_df.iloc[day]['Value'])\n",
    "    new_row = pd.DataFrame([changes], columns=gfs_ens_bc_change_df.columns, index=[date])\n",
    "    gfs_ens_bc_change_df = pd.concat([gfs_ens_bc_change_df, new_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:33.581467Z",
     "end_time": "2023-06-01T12:29:41.026516Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#gfs_ens_bc_change_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:41.027564Z",
     "end_time": "2023-06-01T12:29:41.029307Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### step 2.4 the difference between the new cmc-ens forecast for days 9-14 and the new gfs-ens-bc  forecast for days 9-14"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T09:15:09.712351Z",
     "end_time": "2023-05-25T09:15:16.855969Z"
    }
   },
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cmc_ens_change_df = pd.DataFrame(columns=['cmc-ens_9', 'cmc-ens_10', 'cmc-ens_11', 'cmc-ens_12',\n",
    "                                  'cmc-ens_13', 'cmc-ens_14'])\n",
    "\n",
    "for i in range(1, len(cmc_ens_sorted_files)):\n",
    "    cmc_ens_df = pd.read_csv(cmc_ens_sorted_files[i])\n",
    "    gfs_ens_bc_df = pd.read_csv(gfs_ens_bc_sorted_files[i])\n",
    "    date = get_date(cmc_ens_df, cmc_ens_sorted_files[i])\n",
    "\n",
    "    changes = []\n",
    "    for day in range(8, 14):\n",
    "        changes.append(cmc_ens_df.iloc[day]['Value'] - gfs_ens_bc_df.iloc[day]['Value'])\n",
    "    new_row = pd.DataFrame([changes], columns=cmc_ens_change_df.columns, index=[date])\n",
    "    cmc_ens_change_df = pd.concat([cmc_ens_change_df, new_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:41.033376Z",
     "end_time": "2023-06-01T12:29:49.316144Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "the difference between the new emcwf-eps forecast for day 8 and the previous emcwf-eps forecast for day 8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "day_8_error = pd.DataFrame(columns=['day_8_error'])\n",
    "for i in range(1, len(ecmwf_eps_sorted_files)):\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i])\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "    date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i])\n",
    "    prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "    day = 7\n",
    "    changes = []\n",
    "    changes.append(ecmwf_eps_df.iloc[day]['Value'] - prev_ecmwf_eps_df.iloc[day + offset]['Value'])\n",
    "    new_row = pd.DataFrame([changes], columns=day_8_error.columns, index=[date])\n",
    "    day_8_error = pd.concat([day_8_error, new_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:36:08.388449Z",
     "end_time": "2023-06-01T12:36:14.222548Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:37:19.096104Z",
     "end_time": "2023-06-01T12:37:19.106333Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:37:15.088044Z",
     "end_time": "2023-06-01T12:37:15.102672Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:37:15.293865Z",
     "end_time": "2023-06-01T12:37:15.328486Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:37:15.484752Z",
     "end_time": "2023-06-01T12:37:15.495985Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### new features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#past errors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:49.318152Z",
     "end_time": "2023-06-01T12:29:49.319660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "errors_df = pd.DataFrame(columns=['error_9', 'error_10', 'error_11', 'error_12', 'error_13', 'error_14'])\n",
    "\n",
    "for i in range(2, len(ecmwf_eps_sorted_files)):\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-2])\n",
    "    date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i])\n",
    "    prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    errors = []\n",
    "    for day in range(8, 14):\n",
    "        errors.append(ecmwf_eps_df.iloc[day - offset]['Value'] - prev_ecmwf_eps_df.iloc[day]['Value'])\n",
    "    new_row = pd.DataFrame([errors], columns=errors_df.columns, index=[date])\n",
    "    errors_df = pd.concat([errors_df, new_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:49.324705Z",
     "end_time": "2023-06-01T12:29:56.005211Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-01T12:29:56.005312Z",
     "end_time": "2023-06-01T12:29:56.007154Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# add month data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:48:28.488795Z",
     "end_time": "2023-05-30T09:48:28.490577Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cmc_ens_change_df['month'] = cmc_ens_change_df.index.month"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:48:28.491938Z",
     "end_time": "2023-05-30T09:48:28.494601Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def f(i):\n",
    "    x = 6\n",
    "    y = 1-(1 * (abs(x-i)/x))\n",
    "    return y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:48:28.495961Z",
     "end_time": "2023-05-30T09:48:28.497699Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:48:28.498624Z",
     "end_time": "2023-05-30T09:48:28.500183Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cmc_ens_change_df['month'] = cmc_ens_change_df['month'].apply(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:48:28.503263Z",
     "end_time": "2023-05-30T09:48:28.504622Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#add weather data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:48:28.507046Z",
     "end_time": "2023-05-30T09:48:28.521786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_day = gfs_ens_bc_change_df.index[0]\n",
    "end_day = gfs_ens_bc_change_df.index[-1]\n",
    "\n",
    "# Set time period\n",
    "start = datetime(int(str(start_day)[:4]), int(str(start_day)[5:7]), int(str(start_day)[8:10]))\n",
    "end = datetime(int(str(end_day)[:4]), int(str(end_day)[5:7]), int(str(end_day)[8:10]))\n",
    "\n",
    "# Get daily data\n",
    "data = Daily('03779', start, end) #london\n",
    "data2 = Daily('07149', start, end) #paris\n",
    "data3 = Daily('10384', start, end) #berlin\n",
    "data = data.fetch()\n",
    "data2 = data2.fetch()\n",
    "data3 = data3.fetch()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:48:28.511523Z",
     "end_time": "2023-05-30T09:48:28.526800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_data = data[['tavg', 'tmin', 'tmax', 'pres']]\n",
    "temp_data2 = data2[['tavg', 'tmin', 'tmax', 'pres']]\n",
    "temp_data3 = data3[['tavg', 'tmin', 'tmax', 'pres']]\n",
    "df_concat = pd.concat([temp_data, temp_data2, temp_data3])\n",
    "temp_data = df_concat.groupby(df_concat.index).mean()\n",
    "temp_data = temp_data.diff(1)\n",
    "temp_data.fillna(0, inplace=True)\n",
    "temp_data['date'] = temp_data.index.date"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:48:28.526224Z",
     "end_time": "2023-05-30T09:48:28.529524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gfs_ens_bc_change_df['date'] = gfs_ens_bc_change_df.index.date\n",
    "merged_df = pd.merge(gfs_ens_bc_change_df, temp_data, on='date', how='left')\n",
    "merged_df.index = gfs_ens_bc_change_df.index\n",
    "merged_df.drop(columns=['date'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:48:28.533351Z",
     "end_time": "2023-05-30T09:48:28.536481Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gfs_ens_bc_change_df = merged_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:48:28.537616Z",
     "end_time": "2023-05-30T09:48:28.539267Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:48:28.540056Z",
     "end_time": "2023-05-30T09:48:28.541729Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "master_df = pd.concat([gfs_ens_bc_change_df, cmc_ens_change_df, ecmwf_change_df, errors_df, ecmwf_eps_change_df], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:59:24.918228Z",
     "end_time": "2023-05-30T09:59:24.924546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "master_df.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:59:25.324270Z",
     "end_time": "2023-05-30T09:59:25.334092Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(master_df[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:59:25.706601Z",
     "end_time": "2023-05-30T09:59:25.729361Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### random forest - mse=0.1674"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T16:39:36.720773Z",
     "end_time": "2023-05-25T16:39:36.735978Z"
    }
   },
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = master_df.iloc[:, :-6]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:59:26.955988Z",
     "end_time": "2023-05-30T09:59:26.963570Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = master_df.iloc[:, -6:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:59:27.242598Z",
     "end_time": "2023-05-30T09:59:27.262560Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(y['ecmwf-eps_9'][600:1000])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:59:27.418440Z",
     "end_time": "2023-05-30T09:59:27.544207Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:59:27.606289Z",
     "end_time": "2023-05-30T09:59:27.631369Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:59:28.074631Z",
     "end_time": "2023-05-30T09:59:28.080844Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:59:28.425207Z",
     "end_time": "2023-05-30T09:59:28.434999Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=1000, max_depth=100, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:59:28.629609Z",
     "end_time": "2023-05-30T09:59:28.636946Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:59:28.817441Z",
     "end_time": "2023-05-30T10:00:40.018555Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T10:00:40.020852Z",
     "end_time": "2023-05-30T10:00:40.215744Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T10:00:40.217816Z",
     "end_time": "2023-05-30T10:00:40.220829Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RNN (MSE): 0.16733"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T10:52:48.671842Z",
     "end_time": "2023-05-25T10:52:48.682232Z"
    }
   },
   "outputs": [],
   "execution_count": 213
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "master_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T10:00:54.436319Z",
     "end_time": "2023-05-30T10:00:54.445343Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T10:28:11.727169Z",
     "end_time": "2023-05-30T10:28:11.738139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_features = master_df.iloc[:, :-6].values ** 2\n",
    "target_variables = master_df.iloc[:, -6:].values\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input_features, target_variables, test_size=0.2, shuffle=False)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Scale the input features based on the training data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the validation and test data based on the training data\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert the scaled data to PyTorch tensors\n",
    "\n",
    "X_train_tensor = torch.Tensor(X_train_scaled)\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "X_val_tensor = torch.Tensor(X_val_scaled)\n",
    "y_val_tensor = torch.Tensor(y_val)\n",
    "X_test_tensor = torch.Tensor(X_test_scaled)\n",
    "y_test_tensor = torch.Tensor(y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T10:00:54.959032Z",
     "end_time": "2023-05-30T10:00:54.969376Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)  # Update the hidden state dimensions\n",
    "\n",
    "        out, _ = self.rnn(x, h0)  # Remove unsqueeze(0) since x already has a batch dimension\n",
    "        out = self.fc(out[:, -1, :])  # Select the last time step's output for each sequence\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T10:00:55.184649Z",
     "end_time": "2023-05-30T10:00:55.192729Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ComplexRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout):\n",
    "        super(ComplexRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, 64)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T10:00:55.379479Z",
     "end_time": "2023-05-30T10:00:55.386831Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ImprovedRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout):\n",
    "        super(ImprovedRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, 64)  # Dense layer with 64 units\n",
    "        self.fc2 = nn.Linear(64, output_size)  # Final output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = F.relu(out)  # Apply ReLU activation between LSTM and first dense layer\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = F.relu(out)  # Apply ReLU activation to the output of the first dense layer\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T10:28:18.558711Z",
     "end_time": "2023-05-30T10:28:18.565550Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_size = X_train_tensor.shape[1]\n",
    "output_size = y_train_tensor.shape[1]\n",
    "hidden_size = 256\n",
    "num_layers = 3\n",
    "dropout = 0.3\n",
    "lr = 0.01\n",
    "\n",
    "\n",
    "\n",
    "#model = RNN(input_size, hidden_size, output_size)\n",
    "model = ImprovedRNN(input_size, hidden_size, output_size, num_layers, dropout)\n",
    "#model = ComplexRNN(input_size, hidden_size, output_size, num_layers, dropout)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "sequence_length = 5  # Number of previous days to consider\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    # Loop through each sequence in the training data\n",
    "    for i in range(sequence_length, X_train_tensor.shape[0]):\n",
    "        # Extract the current sequence and target\n",
    "        input_seq = X_train_tensor[i - sequence_length:i].view(1, sequence_length, -1)\n",
    "        target_seq = y_train_tensor[i]\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output, target_seq.unsqueeze(0))\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / (X_train_tensor.shape[0] - sequence_length)\n",
    "    train_losses.append(average_loss)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {average_loss}')\n",
    "\n",
    "    # Validation stage\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "\n",
    "        for i in range(sequence_length, X_val_tensor.shape[0]):\n",
    "            input_seq = X_val_tensor[i - sequence_length:i].view(1, sequence_length, -1)\n",
    "            target_seq = y_val_tensor[i]\n",
    "\n",
    "            output = model(input_seq)\n",
    "            val_loss = criterion(output, target_seq.unsqueeze(0))\n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "        average_val_loss = total_val_loss / (X_val_tensor.shape[0] - sequence_length)\n",
    "        val_losses.append(average_val_loss)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {average_val_loss}')\n",
    "\n",
    "        # Check if current model is the best based on validation loss\n",
    "        if average_val_loss < best_loss:\n",
    "            best_loss = average_val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "# After training, use the best model for testing\n",
    "model = best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T10:12:24.737017Z",
     "end_time": "2023-05-30T10:23:46.254304Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(train_losses, label='Training Loss')\n",
    "    ax.plot(val_losses, label='Validation Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "plot_losses(train_losses, val_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T11:53:12.393533Z",
     "end_time": "2023-05-30T11:53:12.538455Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#benchmark error\n",
    "total_mse = 0\n",
    "c = 0\n",
    "for i in range(1, len(y_test_tensor)):\n",
    "    #mse = mean_squared_error(y_test_tensor[i], y_test_tensor[i-1])\n",
    "    mse = mean_squared_error(y_test_tensor[i], [0,0,0,0,0,0])\n",
    "    total_mse += mse\n",
    "    c += 1\n",
    "\n",
    "total_mse/c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T11:53:21.306228Z",
     "end_time": "2023-05-30T11:53:21.385042Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T11:53:21.518066Z",
     "end_time": "2023-05-30T11:53:21.539210Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T11:53:21.966370Z",
     "end_time": "2023-05-30T11:53:21.973307Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(sequence_length, X_test_tensor.shape[0]):\n",
    "        input_seq = X_test_tensor[i - sequence_length:i].view(1, sequence_length, -1)\n",
    "        target_seq = y_test_tensor[i]\n",
    "\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output, target_seq.unsqueeze(0))\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Extract the scalar value from the tensor and append it to predictions\n",
    "        predictions.append(output.squeeze().tolist())\n",
    "\n",
    "    average_test_loss = test_loss / (X_test_tensor.shape[0] - sequence_length)\n",
    "    print(f'Test Loss: {average_test_loss}')\n",
    "\n",
    "    # Convert the predictions and target values to numpy arrays\n",
    "    predictions = np.array(predictions)\n",
    "    targets = y_test_tensor[sequence_length:].numpy()\n",
    "\n",
    "    # Evaluate the performance using appropriate metrics\n",
    "    # For example, calculate mean squared error (MSE)\n",
    "    mse = mean_squared_error(targets, predictions)\n",
    "    print(f'Mean Squared Error (MSE): {mse}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T11:53:22.733755Z",
     "end_time": "2023-05-30T11:53:25.227478Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prediction(input):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_seq = torch.tensor(input).view(1, sequence_length, -1)\n",
    "        output = model(input_seq)\n",
    "        return output.squeeze().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T11:53:25.215942Z",
     "end_time": "2023-05-30T11:53:25.228118Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = prediction(X_test_tensor[-5:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T11:53:25.220060Z",
     "end_time": "2023-05-30T11:53:25.228261Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T11:53:25.230747Z",
     "end_time": "2023-05-30T11:53:25.238503Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test_tensor[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T11:53:25.236464Z",
     "end_time": "2023-05-30T11:53:25.242212Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### testing ideas\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T16:39:59.395964Z",
     "end_time": "2023-05-25T16:39:59.403015Z"
    }
   },
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#get weather data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T16:39:59.628495Z",
     "end_time": "2023-05-25T16:39:59.636985Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from meteostat import Stations, Daily\n",
    "\n",
    "start_day = gfs_ens_bc_change_df.index[0]\n",
    "end_day = gfs_ens_bc_change_df.index[-1]\n",
    "\n",
    "# Set time period\n",
    "start = datetime(int(str(start_day)[:4]), int(str(start_day)[5:7]), int(str(start_day)[8:10]))\n",
    "end = datetime(int(str(end_day)[:4]), int(str(end_day)[5:7]), int(str(end_day)[8:10]))\n",
    "\n",
    "# Get daily data\n",
    "#\n",
    "# 03779 is London\n",
    "data = Daily('03779', start, end) #london\n",
    "data2 = Daily('07149', start, end) #paris\n",
    "data3 = Daily('10384', start, end) #berlin\n",
    "data = data.fetch()\n",
    "data2 = data2.fetch()\n",
    "data3 = data3.fetch()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:46:19.533163Z",
     "end_time": "2023-05-30T09:46:19.551573Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wind_data = data[['wdir', 'wspd']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:46:19.706492Z",
     "end_time": "2023-05-30T09:46:19.713841Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:46:19.886203Z",
     "end_time": "2023-05-30T09:46:19.895307Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_data = data[['tavg', 'tmin', 'tmax', 'pres']]\n",
    "temp_data2 = data2[['tavg', 'tmin', 'tmax', 'pres']]\n",
    "temp_data3 = data3[['tavg', 'tmin', 'tmax', 'pres']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:46:20.056694Z",
     "end_time": "2023-05-30T09:46:20.062125Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_concat = pd.concat([temp_data, temp_data2, temp_data3])\n",
    "averages_df = df_concat.groupby(df_concat.index).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:46:20.284407Z",
     "end_time": "2023-05-30T09:46:20.293483Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "averages_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:46:29.159942Z",
     "end_time": "2023-05-30T09:46:29.179855Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_data = temp_data.diff(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:33:04.108951Z",
     "end_time": "2023-05-30T09:33:04.120905Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_data.fillna(0, inplace=True)\n",
    "temp_data['date'] = temp_data.index.date"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:33:05.565030Z",
     "end_time": "2023-05-30T09:33:05.575849Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_concat = pd.concat([temp_data, temp_data2, temp_data3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:33:50.560091Z",
     "end_time": "2023-05-30T09:33:50.573227Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stations = Stations()\n",
    "stations = stations.nearby(52.514903, 13.403915)\n",
    "station = stations.fetch(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:30:57.308313Z",
     "end_time": "2023-05-30T09:30:57.346700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "station"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:30:57.526196Z",
     "end_time": "2023-05-30T09:30:57.537838Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:16:59.146190Z",
     "end_time": "2023-05-30T09:16:59.160482Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gfs_ens_bc_change_df['date'] = gfs_ens_bc_change_df.index.date"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:17:05.120302Z",
     "end_time": "2023-05-30T09:17:05.129714Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df = pd.merge(gfs_ens_bc_change_df, temp_data, on='date', how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:17:05.336089Z",
     "end_time": "2023-05-30T09:17:05.341749Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df.index = gfs_ens_bc_change_df.index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:17:05.540063Z",
     "end_time": "2023-05-30T09:17:05.549193Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df.drop(columns=['date'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:17:05.863918Z",
     "end_time": "2023-05-30T09:17:05.874307Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T09:17:17.374638Z",
     "end_time": "2023-05-30T09:17:17.397944Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get data from EIA short term energy outlook (STEO), such as average heating days"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T16:33:35.888764Z",
     "end_time": "2023-05-25T16:33:35.901821Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#use prophet to forecast ecmwf-eps data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T16:38:21.753531Z",
     "end_time": "2023-05-25T16:38:35.449130Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from prophet import Prophet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T11:54:29.968447Z",
     "end_time": "2023-05-30T11:54:29.974121Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['ds', 'day_9', 'day_10', 'day_11', 'day_12', 'day_13', 'day_14'])\n",
    "\n",
    "for i in range(0, len(ecmwf_eps_sorted_files)):\n",
    "    data = pd.read_csv(ecmwf_eps_sorted_files[i])\n",
    "    date = get_date(data, ecmwf_eps_sorted_files[i])\n",
    "\n",
    "    changes = [date]\n",
    "    for day in range(8, 14):\n",
    "        changes.append(data.iloc[day]['Value'])\n",
    "    new_row = pd.DataFrame([changes], columns=df.columns)\n",
    "    df = pd.concat([df, new_row])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:51:15.711227Z",
     "end_time": "2023-05-30T12:51:20.759086Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ecmwf_eps_change_df = pd.DataFrame(columns=['ds', 'day_9', 'day_10', 'day_11', 'day_12', 'day_13', 'day_14'])\n",
    "\n",
    "for i in range(1, len(ecmwf_eps_sorted_files)):\n",
    "    ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i])\n",
    "    prev_ecmwf_eps_df = pd.read_csv(ecmwf_eps_sorted_files[i-1])\n",
    "    date = get_date(ecmwf_eps_df, ecmwf_eps_sorted_files[i])\n",
    "    prev_date = get_date(prev_ecmwf_eps_df, ecmwf_eps_sorted_files[i-1])\n",
    "    d2 = str(date)[:10]\n",
    "    d1 = str(prev_date)[:10]\n",
    "\n",
    "    if d2 != d1:\n",
    "        offset = 1\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "    changes = [date]\n",
    "    for day in range(8, 14):\n",
    "        changes.append(ecmwf_eps_df.iloc[day - offset]['Value'] - prev_ecmwf_eps_df.iloc[day]['Value'])\n",
    "    new_row = pd.DataFrame([changes], columns=ecmwf_eps_change_df.columns)\n",
    "    ecmwf_eps_change_df = pd.concat([ecmwf_eps_change_df, new_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:50:01.674052Z",
     "end_time": "2023-05-30T12:50:09.300056Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df = ecmwf_eps_change_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:50:09.295153Z",
     "end_time": "2023-05-30T12:50:09.300246Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(9,15):\n",
    "    forecasting_data = df[['ds', 'day_' + str(i)]]\n",
    "    forecasting_data.rename(columns={forecasting_data.columns[1]: 'y'}, inplace=True)\n",
    "\n",
    "    m = Prophet()\n",
    "    m.fit(forecasting_data)\n",
    "\n",
    "    future = m.make_future_dataframe(periods=365)\n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    forecast = forecast[['ds','yhat', 'trend', 'daily' ,'weekly', 'yearly']]\n",
    "    print(f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T13:10:01.274232Z",
     "end_time": "2023-05-30T13:10:01.292463Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forecasting_data = df[['ds', 'day_12']]\n",
    "forecasting_data.rename(columns={forecasting_data.columns[1]: 'y'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T13:08:49.326526Z",
     "end_time": "2023-05-30T13:08:49.341204Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T13:08:57.599192Z",
     "end_time": "2023-05-30T13:08:57.612009Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:51:20.768323Z",
     "end_time": "2023-05-30T12:51:20.769976Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "m.fit(forecasting_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:51:20.771379Z",
     "end_time": "2023-05-30T12:51:21.252881Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(periods=365)\n",
    "future.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:51:21.253293Z",
     "end_time": "2023-05-30T12:51:21.261095Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forecast = m.predict(future)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].iloc[3484]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:51:21.266137Z",
     "end_time": "2023-05-30T12:51:21.913165Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig1 = m.plot(forecast)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:51:21.915127Z",
     "end_time": "2023-05-30T12:51:22.164530Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig2 = m.plot_components(forecast)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:51:22.164472Z",
     "end_time": "2023-05-30T12:51:22.921752Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:51:22.922813Z",
     "end_time": "2023-05-30T12:51:22.924694Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forecast[['ds','yhat', 'trend', 'daily' ,'weekly', 'yearly']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:51:22.931485Z",
     "end_time": "2023-05-30T12:51:22.934510Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#crossvalidation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:51:42.636204Z",
     "end_time": "2023-05-30T12:51:42.653922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from prophet.diagnostics import cross_validation\n",
    "df_cv = cross_validation(m, horizon = '30 days')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:51:42.959079Z",
     "end_time": "2023-05-30T12:52:11.976770Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cv.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:52:11.983773Z",
     "end_time": "2023-05-30T12:52:11.986155Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:52:19.870901Z",
     "end_time": "2023-05-30T12:52:19.895076Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-30T12:52:53.611807Z",
     "end_time": "2023-05-30T12:52:53.652054Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
